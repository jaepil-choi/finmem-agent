{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2b29a4b",
   "metadata": {},
   "source": "# 멀티 에이전트 협업 네트워크\n\n이 튜토리얼에서는 **멀티 에이전트 네트워크**를 LangGraph를 활용하여 구현하는 방법을 다룹니다. 멀티 에이전트 네트워크는 복잡한 작업을 여러 개의 전문화된 에이전트들로 나누어 처리하는 \"분할 정복\" 접근 방식을 사용하는 아키텍처입니다. \n\n이를 통해 단일 에이전트가 많은 도구를 비효율적으로 사용하는 문제를 해결하고, 각 에이전트가 자신의 전문 분야에서 효과적으로 문제를 해결하도록 합니다.\n\n> **참고 문서**: [LangChain Multi-Agent](https://docs.langchain.com/oss/python/langchain/multi-agent/)\n\n본 튜토리얼은 AutoGen 논문에서 영감을 받아, LangGraph를 활용하여 이러한 멀티 에이전트 네트워크를 구축하는 방법을 단계별로 살펴봅니다.\n\n---\n\n## 왜 멀티 에이전트 네트워크인가?\n\n단일 에이전트는 특정 도메인 내에서 일정 수의 도구를 사용할 때 효율적일 수 있습니다. 그러나 한 에이전트가 너무 많은 도구를 다루면 다음과 같은 문제가 발생합니다.\n\n1. 도구 사용 로직이 복잡해집니다.\n2. 에이전트가 한 번에 처리해야 할 정보 양이 증가하여 비효율적입니다.\n\n\"분할 정복\" 접근을 사용하면 각 에이전트는 특정 업무나 전문성 영역에 집중할 수 있고, 전체 작업이 네트워크 형태로 나뉘어 처리됩니다. 각 에이전트는 자신이 잘하는 일을 처리하고, 필요 시 해당 업무를 다른 전문 에이전트에게 위임하거나 도구를 적절히 활용합니다.\n\n---\n\n## 주요 내용\n\n이 튜토리얼에서는 다음 내용을 학습합니다.\n\n- **에이전트 생성**: 에이전트를 정의하고, 이를 LangGraph 그래프의 노드로 설정하는 방법\n- **도구 정의**: 에이전트가 사용할 도구를 정의하고 노드로 추가하는 방법\n- **그래프 생성**: 에이전트와 도구를 연결하여 멀티 에이전트 네트워크 그래프를 구성하는 방법\n- **상태 정의**: 그래프 상태를 정의하고, 각 에이전트의 동작에 필요한 상태 정보를 관리하는 방법\n- **엣지 로직 정의**: 에이전트 결과에 따라 다른 에이전트나 도구로 분기하는 로직을 설정하는 방법\n- **그래프 실행**: 구성된 그래프를 호출하고 실제 작업을 수행하는 방법"
  },
  {
   "cell_type": "markdown",
   "id": "1d3a2e7e",
   "metadata": {},
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7862a931",
   "metadata": {},
   "outputs": [],
   "source": "# API 키를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API 키 정보 로드\nload_dotenv(override=True)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2785cf",
   "metadata": {},
   "outputs": [],
   "source": "# LangSmith 추적을 설정합니다.\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"LangGraph-Tutorial\")"
  },
  {
   "cell_type": "markdown",
   "id": "4f756407",
   "metadata": {},
   "source": "## 모델 설정\n\n이번 에이전트에 사용할 모델명을 지정합니다. `langchain_teddynote` 패키지의 `get_model_name` 함수를 사용하여 최신 모델명을 가져옵니다.\n\n아래 코드는 GPT-4o 모델을 사용하도록 설정합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aa2e6c",
   "metadata": {},
   "outputs": [],
   "source": "from langchain_teddynote.models import get_model_name, LLMs\n\n# 최신 모델 이름 가져오기\nMODEL_NAME = get_model_name(LLMs.GPT4o)\n\nprint(f\"사용 모델: {MODEL_NAME}\")"
  },
  {
   "cell_type": "markdown",
   "id": "99e92c04",
   "metadata": {},
   "source": "## 상태 정의\n\n멀티 에이전트 시스템에서 에이전트들이 정보를 공유하기 위한 상태(State)를 정의합니다. `messages`는 에이전트 간 공유하는 메시지 목록이며, `sender`는 마지막 메시지의 발신자를 나타냅니다.\n\n`operator.add`를 사용하면 새 메시지가 기존 메시지 목록에 추가되는 방식으로 상태가 업데이트됩니다. 아래 코드는 에이전트 상태 스키마를 정의합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abc0450",
   "metadata": {},
   "outputs": [],
   "source": "import operator\nfrom typing import Annotated, Sequence\nfrom typing_extensions import TypedDict\nfrom langchain_core.messages import BaseMessage\n\n\n# 상태 정의\nclass AgentState(TypedDict):\n    # 에이전트 간 공유하는 메시지 목록 (새 메시지가 기존 목록에 추가됨)\n    messages: Annotated[Sequence[BaseMessage], operator.add]\n    # 마지막 메시지의 발신자\n    sender: Annotated[str, \"The sender of the last message\"]"
  },
  {
   "cell_type": "markdown",
   "id": "61eb7e16",
   "metadata": {},
   "source": "## 도구 정의\n\n에이전트가 사용할 도구들을 정의합니다. 이 튜토리얼에서는 두 가지 도구를 사용합니다.\n\n- **TavilySearch**: 인터넷에서 정보를 검색하는 도구입니다. Research Agent가 필요한 정보를 검색할 때 사용합니다.\n- **PythonREPL**: Python 코드를 실행하는 도구입니다. Chart Generator Agent가 차트를 생성할 때 사용합니다.\n\n아래 코드는 Tavily 검색 도구와 Python REPL 도구를 정의합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d8f6e3",
   "metadata": {},
   "outputs": [],
   "source": "from typing import Annotated\n\nfrom langchain_teddynote.tools.tavily import TavilySearch\nfrom langchain_core.tools import tool\nfrom langchain_experimental.utilities import PythonREPL\n\n# Tavily 검색 도구 정의 (최대 5개 결과 반환)\ntavily_tool = TavilySearch(max_results=5)\n\n# Python 코드를 실행하는 도구 정의\npython_repl = PythonREPL()\n\n\n@tool\ndef python_repl_tool(\n    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n):\n    \"\"\"Python 코드를 실행합니다. 값의 출력을 보려면 print(...)를 사용해야 합니다.\"\"\"\n    try:\n        # 주어진 코드를 Python REPL에서 실행하고 결과 반환\n        result = python_repl.run(code)\n    except BaseException as e:\n        return f\"Failed to execute code. Error: {repr(e)}\"\n    # 실행 성공 시 결과와 함께 성공 메시지 반환\n    result_str = f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n    return (\n        result_str + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n    )"
  },
  {
   "cell_type": "markdown",
   "id": "1ce2e2dc",
   "metadata": {},
   "source": "## 에이전트 생성\n\n### Research Agent\n\nResearch Agent는 `TavilySearch` 도구를 사용하여 웹에서 정보를 검색하는 에이전트입니다. 이 에이전트는 필요한 정보를 리서치하는 역할을 담당합니다.\n\n`create_react_agent`는 ReAct(Reasoning + Acting) 패턴을 따르는 에이전트를 생성하는 함수입니다. 에이전트는 도구를 사용하여 작업을 수행하고, 다른 에이전트와 협업할 수 있습니다.\n\n먼저 시스템 프롬프트를 생성하는 헬퍼 함수를 정의합니다. 아래 코드는 협업 에이전트를 위한 시스템 프롬프트 생성 함수를 정의합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400e5479",
   "metadata": {},
   "outputs": [],
   "source": "def make_system_prompt(suffix: str) -> str:\n    \"\"\"협업 에이전트를 위한 시스템 프롬프트를 생성합니다.\"\"\"\n    return (\n        \"You are a helpful AI assistant, collaborating with other assistants.\"\n        \" Use the provided tools to progress towards answering the question.\"\n        \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n        \" will help where you left off. Execute what you can to make progress.\"\n        \" If you or any of the other assistants have the final answer or deliverable,\"\n        \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n        f\"\\n{suffix}\"\n    )"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c72d9b",
   "metadata": {},
   "outputs": [],
   "source": "from langchain_core.messages import HumanMessage\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.prebuilt import create_react_agent\nfrom langgraph.graph import MessagesState\n\n# LLM 정의\nllm = ChatOpenAI(model=MODEL_NAME)\n\n# Research Agent 생성\nresearch_agent = create_react_agent(\n    llm,\n    tools=[tavily_tool],\n    prompt=make_system_prompt(\n        \"You can only do research. You are working with a chart generator colleague.\"\n    ),\n)\n\n\ndef research_node(state: MessagesState) -> MessagesState:\n    \"\"\"Research Agent 노드 함수입니다.\"\"\"\n    result = research_agent.invoke(state)\n\n    # 마지막 메시지를 HumanMessage로 변환\n    last_message = HumanMessage(\n        content=result[\"messages\"][-1].content, name=\"researcher\"\n    )\n    return {\n        # Research Agent의 메시지 목록 반환\n        \"messages\": [last_message],\n    }"
  },
  {
   "cell_type": "markdown",
   "id": "1d9e53f7",
   "metadata": {},
   "source": "### Chart Generator Agent\n\nChart Generator Agent는 `PythonREPL` 도구를 사용하여 차트를 생성하는 에이전트입니다. Research Agent가 수집한 데이터를 기반으로 시각화를 담당합니다.\n\n시스템 프롬프트에 한글 폰트 설정 코드를 포함하여 차트에서 한글이 올바르게 표시되도록 합니다. 아래 코드는 Chart Generator Agent를 생성합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cf3971",
   "metadata": {},
   "outputs": [],
   "source": "# 차트 생성 에이전트의 시스템 프롬프트 (한글 폰트 설정 포함)\nchart_generator_system_prompt = \"\"\"\nYou can only generate charts. You are working with a researcher colleague.\nBe sure to use the following font code in your code when generating charts.\n\n##### 폰트 설정 #####\nimport platform\n\n# OS 판단\ncurrent_os = platform.system()\n\nif current_os == \"Windows\":\n    # Windows 환경 폰트 설정\n    font_path = \"C:/Windows/Fonts/malgun.ttf\"  # 맑은 고딕 폰트 경로\n    fontprop = fm.FontProperties(fname=font_path, size=12)\n    plt.rc(\"font\", family=fontprop.get_name())\nelif current_os == \"Darwin\":  # macOS\n    # Mac 환경 폰트 설정\n    plt.rcParams[\"font.family\"] = \"AppleGothic\"\nelse:  # Linux 등 기타 OS\n    # 기본 한글 폰트 설정 시도\n    try:\n        plt.rcParams[\"font.family\"] = \"NanumGothic\"\n    except:\n        print(\"한글 폰트를 찾을 수 없습니다. 시스템 기본 폰트를 사용합니다.\")\n\n##### 마이너스 폰트 깨짐 방지 #####\nplt.rcParams[\"axes.unicode_minus\"] = False  # 마이너스 폰트 깨짐 방지\n\"\"\"\n\n# Chart Generator Agent 생성\nchart_agent = create_react_agent(\n    llm,\n    [python_repl_tool],\n    prompt=make_system_prompt(chart_generator_system_prompt),\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0ccbe8",
   "metadata": {},
   "outputs": [],
   "source": "def chart_node(state: MessagesState) -> MessagesState:\n    \"\"\"Chart Generator Agent 노드 함수입니다.\"\"\"\n    result = chart_agent.invoke(state)\n\n    # 마지막 메시지를 HumanMessage로 변환\n    last_message = HumanMessage(\n        content=result[\"messages\"][-1].content, name=\"chart_generator\"\n    )\n    return {\n        # Chart Agent의 메시지 목록 반환\n        \"messages\": [last_message],\n    }"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1059c9",
   "metadata": {},
   "outputs": [],
   "source": "from langgraph.graph import END\n\n\ndef router(state: MessagesState):\n    \"\"\"라우터 함수: 에이전트 출력에 따라 다음 노드를 결정합니다.\"\"\"\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    if \"FINAL ANSWER\" in last_message.content:\n        # 작업이 완료되면 종료\n        return END\n    return \"continue\""
  },
  {
   "cell_type": "markdown",
   "id": "0143a325",
   "metadata": {},
   "source": "## 그래프 생성\n\n이제 노드를 정의하고 그래프를 구성합니다. Research Agent와 Chart Generator Agent를 노드로 추가하고, 조건부 엣지를 사용하여 에이전트 간의 흐름을 제어합니다.\n\n- **researcher**: Research Agent 노드\n- **chart_generator**: Chart Generator Agent 노드\n- **조건부 엣지**: 에이전트 출력에 따라 다음 노드를 결정합니다. \"FINAL ANSWER\"가 포함되면 종료하고, 그렇지 않으면 다른 에이전트로 전달합니다.\n\n아래 코드는 그래프를 구성하고 컴파일합니다."
  },
  {
   "cell_type": "markdown",
   "id": "dc49d497",
   "metadata": {},
   "source": "### 에이전트 노드 및 엣지 정의\n\n그래프에 노드를 추가하고 조건부 엣지를 정의합니다. 아래 코드는 완전한 멀티 에이전트 네트워크 그래프를 구성합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fc6ca0",
   "metadata": {},
   "outputs": [],
   "source": "from langchain_core.messages import HumanMessage, ToolMessage\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.checkpoint.memory import MemorySaver\n\n# 그래프 생성\nworkflow = StateGraph(MessagesState)\n\n# 노드 추가\nworkflow.add_node(\"researcher\", research_node)\nworkflow.add_node(\"chart_generator\", chart_node)\n\n# 조건부 엣지 추가 (researcher 노드에서)\nworkflow.add_conditional_edges(\n    \"researcher\",\n    router,\n    {\"continue\": \"chart_generator\", END: END},\n)\n\n# 조건부 엣지 추가 (chart_generator 노드에서)\nworkflow.add_conditional_edges(\n    \"chart_generator\",\n    router,\n    {\"continue\": \"researcher\", END: END},\n)\n\n# 시작점 설정\nworkflow.add_edge(START, \"researcher\")\n\n# 그래프 컴파일\napp = workflow.compile(checkpointer=MemorySaver())"
  },
  {
   "cell_type": "markdown",
   "id": "361a3bd1",
   "metadata": {},
   "source": "### 그래프 시각화\n\n생성한 그래프의 구조를 시각화하여 확인합니다. `xray=True` 옵션을 사용하면 내부 서브그래프 구조도 함께 표시됩니다. 아래 코드는 그래프를 시각화합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2093ac6",
   "metadata": {},
   "outputs": [],
   "source": "from langchain_teddynote.graphs import visualize_graph\n\n# 그래프 시각화\nvisualize_graph(app, xray=True)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f19ddf",
   "metadata": {},
   "outputs": [],
   "source": "from langchain_core.runnables import RunnableConfig\nfrom langchain_teddynote.messages import random_uuid, invoke_graph\n\n# config 설정 (재귀 최대 횟수, thread_id)\nconfig = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": random_uuid()})\n\n# 질문 입력\ninputs = {\n    \"messages\": [\n        HumanMessage(\n            content=\"2010년 ~ 2024년까지의 대한민국의 1인당 GDP 추이를 그래프로 시각화 해주세요.\"\n        )\n    ],\n}\n\n# 그래프 실행\ninvoke_graph(app, inputs, config, node_names=[\"researcher\", \"chart_generator\", \"agent\"])"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-CdOel15G-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}