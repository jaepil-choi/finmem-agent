{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44f9d7bd",
   "metadata": {},
   "source": "# 계층적 에이전트 팀 (Hierarchical Agent Team)\n\n이 튜토리얼에서는 **계층적 에이전트 팀**을 구성하는 방법을 살펴봅니다.\n\n단일 에이전트나 단일 수준의 감독자(Supervisor)로는 대응하기 힘든 복잡한 작업을 **계층적 구조**를 통해 분할하고, 각각의 하위 수준 감독자(Sub-Supervisor)가 해당 영역에 특화된 작업자(Worker) 에이전트를 관리하는 방식을 구현합니다.\n\n이러한 계층적 접근 방식은 작업자가 너무 많아질 경우나, 단일 작업자가 처리하기 힘든 복잡한 작업을 효율적으로 해결하는 데 도움이 됩니다.  \n\n본 예제는 [AutoGen 논문](https://arxiv.org/abs/2308.08155)의 아이디어를 LangGraph를 통해 구현한 사례로, 웹 연구와 문서 작성이라는 두 가지 하위 작업을 서로 다른 팀으로 구성하고, 상위 및 중간 수준의 감독자를 통해 전체 프로세스를 관리하는 방법을 제시합니다.\n\n![](./assets/langgraph-multi-agent-team-supervisor.png)\n\n---\n\n## 왜 계층적 에이전트 팀인가?\n\n이전 Supervisor 예제에서는 하나의 Supervisor 노드가 여러 작업자 노드에게 작업을 할당하고 결과를 취합하는 과정을 살펴보았습니다. 이 방식은 간단한 경우에 효율적입니다. 그러나 다음과 같은 상황에서는 계층적 구조가 필요할 수 있습니다.\n\n- **작업 복잡성 증가**: 단일 Supervisor로는 한 번에 처리할 수 없는 다양한 하위 영역의 전문 지식이 필요할 수 있습니다.\n- **작업자 수 증가**: 많은 수의 작업자를 관리할 때, 단일 Supervisor가 모든 작업자에게 직접 명령을 내리면 관리 부담이 커집니다.\n\n이러한 상황에서 상위 수준의 Supervisor는 하위 수준의 **Sub-Supervisor**들에게 작업을 할당하고, 각 **Sub-Supervisor**는 해당 작업을 전문화된 작업자 팀에 재할당하는 계층적 구조를 구성할 수 있습니다.\n\n---\n\n## 이 튜토리얼에서 다룰 내용\n\n1. **도구 생성**: 웹 연구(Web Research) 및 문서 작성(Documentation)을 위한 에이전트 도구 정의    \n2. **에이전트 팀 정의**: 연구 팀 및 문서 작성 팀을 계층적으로 정의하고 구성  \n3. **계층 추가**: 상위 수준 그래프와 중간 수준 감독자를 통해 전체 작업을 계층적으로 조정  \n4. **결합**: 모든 요소를 통합하여 최종적인 계층적 에이전트 팀 구축\n\n> **참고 문서**\n> - [AutoGen 논문: Enabling Next-Gen LLM Applications via Multi-Agent Conversation (Wu et al.)](https://arxiv.org/abs/2308.08155)\n> - [LangGraph Multi-Agent 개념](https://langchain-ai.github.io/langgraph/concepts/multi_agent/)"
  },
  {
   "cell_type": "markdown",
   "id": "2da4c8ca",
   "metadata": {},
   "source": "## 환경 설정\n\n필요한 패키지를 설치하고 API 키를 설정합니다. `dotenv`를 사용하여 환경 변수를 로드하고, LangSmith 추적을 활성화합니다.\n\n아래 코드는 환경 변수를 로드합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5916579d",
   "metadata": {},
   "outputs": [],
   "source": "# API 키를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API 키 정보 로드 (override=True: 기존 환경변수 덮어쓰기)\nload_dotenv(override=True)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209cb6c2",
   "metadata": {},
   "outputs": [],
   "source": "# LangSmith 추적을 설정합니다.\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"LangGraph-Tutorial\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c152a0f5",
   "metadata": {},
   "outputs": [],
   "source": "from langchain_teddynote.models import get_model_name, LLMs\n\n# 최신 버전의 모델명을 가져옵니다.\nMODEL_NAME = get_model_name(LLMs.GPT4)\nprint(f\"사용 모델: {MODEL_NAME}\")"
  },
  {
   "cell_type": "markdown",
   "id": "b0a8cb37",
   "metadata": {},
   "source": "## 도구 생성\n\n각 팀은 하나 이상의 에이전트로 구성되며, 각 에이전트는 하나 이상의 도구를 갖추게 됩니다. 아래에서는 다양한 팀에서 사용할 모든 도구를 정의합니다.\n\n### Research Team 도구\n\nResearch Team은 웹에서 정보를 찾기 위해 검색 엔진과 URL 스크래퍼를 사용할 수 있습니다. \n\n- **TavilySearch**: 웹 검색을 수행하는 도구입니다.\n- **scrape_webpages**: 특정 URL에서 상세 정보를 스크래핑하는 도구입니다.\n\n아래 코드는 Research Team에서 사용할 도구들을 정의합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca895a7",
   "metadata": {},
   "outputs": [],
   "source": "from typing import List\nfrom langchain_community.document_loaders import WebBaseLoader\nfrom langchain_teddynote.tools.tavily import TavilySearch\nfrom langchain_core.tools import tool\n\n# TavilySearch 도구 정의: 최대 5개의 검색 결과 반환\ntavily_tool = TavilySearch(max_results=5)\n\n\n@tool\ndef scrape_webpages(urls: List[str]) -> str:\n    \"\"\"웹 페이지 스크래핑 도구\n\n    주어진 URL 목록에서 웹 페이지 내용을 스크래핑합니다.\n    requests와 BeautifulSoup을 사용하여 상세 정보를 추출합니다.\n    \"\"\"\n    # 웹 페이지 로더 초기화: User-Agent 헤더 설정\n    loader = WebBaseLoader(\n        web_path=urls,\n        header_template={\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36\",\n        },\n    )\n    # 문서 로드\n    docs = loader.load()\n\n    # 로드된 문서의 제목과 내용을 XML 형식으로 변환하여 반환\n    return \"\\n\\n\".join(\n        [\n            f'<Document name=\"{doc.metadata.get(\"title\", \"\")}\">\\n{doc.page_content}\\n</Document>'\n            for doc in docs\n        ]\n    )"
  },
  {
   "cell_type": "markdown",
   "id": "403a88c4",
   "metadata": {},
   "source": "### Doc Writing Team 도구\n\n다음으로, 문서 작성 팀(Doc Writing Team)이 사용할 도구들을 정의합니다. 이 도구들은 에이전트가 파일 시스템에 접근할 수 있도록 합니다.\n\n- **create_outline**: 문서의 개요를 생성하고 파일로 저장합니다.\n- **read_document**: 저장된 문서를 읽습니다.\n- **write_document**: 새 문서를 작성하고 저장합니다.\n- **edit_document**: 기존 문서를 편집합니다.\n\n> **주의**: 파일 시스템 접근은 보안상 위험할 수 있으므로 사용에 주의가 필요합니다.\n\n아래 코드는 Doc Writing Team에서 사용할 파일 접근 도구들을 정의합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438d04b3",
   "metadata": {},
   "outputs": [],
   "source": "from pathlib import Path\nfrom typing import Dict, Optional, List\nfrom typing_extensions import Annotated\n\n# 작업 디렉토리 설정\nWORKING_DIRECTORY = Path(\"./tmp\")\nWORKING_DIRECTORY.mkdir(exist_ok=True)  # tmp 폴더가 없으면 생성\n\n\n@tool\ndef create_outline(\n    points: Annotated[List[str], \"List of main points or sections.\"],\n    file_name: Annotated[str, \"File path to save the outline.\"],\n) -> Annotated[str, \"Path of the saved outline file.\"]:\n    \"\"\"아웃라인 생성 도구\n\n    주어진 포인트 목록으로 아웃라인을 생성하고 파일로 저장합니다.\n    \"\"\"\n    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n        for i, point in enumerate(points):\n            file.write(f\"{i + 1}. {point}\\n\")\n    return f\"Outline saved to {file_name}\"\n\n\n@tool\ndef read_document(\n    file_name: Annotated[str, \"File path to read the document.\"],\n    start: Annotated[Optional[int], \"The start line. Default is 0\"] = None,\n    end: Annotated[Optional[int], \"The end line. Default is None\"] = None,\n) -> str:\n    \"\"\"문서 읽기 도구\n\n    지정된 파일에서 문서 내용을 읽어 반환합니다.\n    시작/종료 줄을 지정하여 부분 읽기도 가능합니다.\n    \"\"\"\n    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n        lines = file.readlines()\n    # 시작 줄이 지정되지 않은 경우 기본값 0 설정\n    if start is None:\n        start = 0\n    return \"\\n\".join(lines[start:end])\n\n\n@tool\ndef write_document(\n    content: Annotated[str, \"Text content to be written into the document.\"],\n    file_name: Annotated[str, \"File path to save the document.\"],\n) -> Annotated[str, \"Path of the saved document file.\"]:\n    \"\"\"문서 작성 도구\n\n    텍스트 내용을 받아 파일로 저장합니다.\n    \"\"\"\n    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n        file.write(content)\n    return f\"Document saved to {file_name}\"\n\n\n@tool\ndef edit_document(\n    file_name: Annotated[str, \"File path of the document to be edited.\"],\n    inserts: Annotated[\n        Dict[int, str],\n        \"Dictionary where key is the line number (1-indexed) and value is the text to be inserted at that line.\",\n    ],\n) -> Annotated[str, \"File path of the edited document.\"]:\n    \"\"\"문서 편집 도구\n\n    지정된 줄 번호에 텍스트를 삽입하여 문서를 편집합니다.\n    줄 번호는 1부터 시작합니다.\n    \"\"\"\n    # 문서 읽기\n    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n        lines = file.readlines()\n\n    # 삽입할 텍스트를 줄 번호 순으로 정렬하여 처리\n    sorted_inserts = sorted(inserts.items())\n\n    # 지정된 줄 번호에 텍스트 삽입\n    for line_number, text in sorted_inserts:\n        if 1 <= line_number <= len(lines) + 1:\n            lines.insert(line_number - 1, text + \"\\n\")\n        else:\n            return f\"Error: Line number {line_number} is out of range.\"\n\n    # 편집된 문서 저장\n    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n        file.writelines(lines)\n\n    return f\"Document edited and saved to {file_name}\""
  },
  {
   "cell_type": "markdown",
   "id": "248d565b",
   "metadata": {},
   "source": "### Python REPL 도구\n\n다음은 코드 실행 도구인 `PythonREPLTool`을 정의합니다. 이 도구는 에이전트가 Python 코드를 실행할 수 있게 해주며, 차트 생성이나 데이터 처리에 활용됩니다.\n\n아래 코드는 PythonREPL 도구를 초기화합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5faf77",
   "metadata": {},
   "outputs": [],
   "source": "from langchain_experimental.tools import PythonREPLTool\n\n# Python REPL 도구 초기화\npython_repl_tool = PythonREPLTool()"
  },
  {
   "cell_type": "markdown",
   "id": "64e51557",
   "metadata": {},
   "source": "## 유틸리티 함수 정의\n\n다중 에이전트 시스템을 효율적으로 구축하기 위해 유틸리티 함수와 클래스를 정의합니다. 이를 통해 에이전트 생성 및 관리 코드를 재사용할 수 있습니다.\n\n`AgentFactory` 클래스는 다음 기능을 제공합니다.\n\n1. **Worker Agent 생성**: ReAct 패턴의 에이전트를 생성합니다.\n2. **에이전트 노드 래퍼**: 에이전트를 그래프 노드 함수로 변환합니다.\n\n아래 코드는 AgentFactory 클래스를 정의합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15598e9e",
   "metadata": {},
   "outputs": [],
   "source": "from langgraph.graph import START, END\nfrom langchain_core.messages import HumanMessage\nfrom langchain_openai.chat_models import ChatOpenAI\nfrom langgraph.prebuilt import create_react_agent\n\n\nclass AgentFactory:\n    \"\"\"에이전트 팩토리 클래스\n\n    에이전트 생성 및 노드 래핑을 담당합니다.\n    동일한 LLM 설정으로 여러 에이전트를 생성할 때 유용합니다.\n    \"\"\"\n    \n    def __init__(self, model_name):\n        \"\"\"초기화\n\n        Args:\n            model_name: 사용할 LLM 모델명\n        \"\"\"\n        self.llm = ChatOpenAI(model=model_name, temperature=0)\n\n    def create_agent_node(self, agent, name: str):\n        \"\"\"에이전트를 그래프 노드 함수로 변환\n\n        Args:\n            agent: ReAct 에이전트 인스턴스\n            name: 에이전트 이름 (메시지 출처 식별용)\n\n        Returns:\n            그래프에서 사용할 수 있는 노드 함수\n        \"\"\"\n        def agent_node(state):\n            # 에이전트 실행\n            result = agent.invoke(state)\n            # 결과를 HumanMessage로 변환하여 반환\n            return {\n                \"messages\": [\n                    HumanMessage(content=result[\"messages\"][-1].content, name=name)\n                ]\n            }\n        return agent_node\n\n\n# LLM 초기화\nllm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n\n# AgentFactory 인스턴스 생성\nagent_factory = AgentFactory(MODEL_NAME)"
  },
  {
   "cell_type": "markdown",
   "id": "f4011486",
   "metadata": {},
   "source": "### AgentFactory 사용 예시\n\n`AgentFactory`를 사용하여 에이전트 노드를 생성하는 방법을 살펴보겠습니다. 아래 예시에서는 검색 에이전트를 생성합니다.\n\n아래 코드는 검색 에이전트와 해당 노드를 생성합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2f5962",
   "metadata": {},
   "outputs": [],
   "source": "# ReAct 패턴의 검색 에이전트 생성\nsearch_agent = create_react_agent(llm, tools=[tavily_tool])\n\n# 에이전트를 그래프 노드로 변환\nsearch_node = agent_factory.create_agent_node(search_agent, name=\"Searcher\")"
  },
  {
   "cell_type": "markdown",
   "id": "56d3a6dd",
   "metadata": {},
   "source": "### Team Supervisor 생성 함수\n\n다음은 팀 감독자(Team Supervisor)를 생성하는 함수입니다. 이 함수는 지정된 멤버들 중에서 다음 작업자를 선택하거나, 작업 완료 시 `FINISH`를 반환하는 Supervisor 체인을 생성합니다.\n\n아래 코드는 Team Supervisor 생성 함수를 정의합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a146aa89",
   "metadata": {},
   "outputs": [],
   "source": "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langchain_openai import ChatOpenAI\nfrom pydantic import BaseModel\nfrom typing import Literal\n\n\ndef create_team_supervisor(model_name, system_prompt, members) -> str:\n    \"\"\"Team Supervisor 생성 함수\n\n    팀 멤버를 관리하고 다음 작업자를 결정하는 Supervisor 체인을 생성합니다.\n\n    Args:\n        model_name: 사용할 LLM 모델명\n        system_prompt: Supervisor의 시스템 프롬프트\n        members: 관리할 팀 멤버 목록\n\n    Returns:\n        Supervisor 체인 (prompt | llm with structured output)\n    \"\"\"\n    # 다음 작업자 선택 옵션: FINISH + 멤버 목록\n    options_for_next = [\"FINISH\"] + members\n\n    # 라우팅 응답 모델 정의\n    class RouteResponse(BaseModel):\n        next: Literal[*options_for_next]\n\n    # 프롬프트 템플릿 생성\n    prompt = ChatPromptTemplate.from_messages(\n        [\n            (\"system\", system_prompt),\n            MessagesPlaceholder(variable_name=\"messages\"),\n            (\n                \"system\",\n                \"Given the conversation above, who should act next? \"\n                \"Or should we FINISH? Select one of: {options}\",\n            ),\n        ]\n    ).partial(options=str(options_for_next))\n\n    # LLM 초기화\n    llm = ChatOpenAI(model=model_name, temperature=0)\n\n    # Supervisor 체인 구성: 프롬프트 -> LLM (구조화된 출력)\n    supervisor_chain = prompt | llm.with_structured_output(RouteResponse)\n\n    return supervisor_chain"
  },
  {
   "cell_type": "markdown",
   "id": "45b717eb",
   "metadata": {},
   "source": "## 에이전트 팀 정의\n\n이제 Research Team과 Doc Writing Team을 정의합니다. 각 팀은 자체 Sub-Supervisor를 가지며, 해당 영역에 특화된 작업자 에이전트들로 구성됩니다.\n\n### Research Team\n\nResearch Team은 웹 검색과 스크래핑을 담당하는 두 개의 작업자 노드를 가집니다.\n\n- **Searcher**: TavilySearch를 사용하여 웹 검색을 수행합니다.\n- **WebScraper**: 특정 URL에서 상세 정보를 스크래핑합니다.\n\n아래 코드는 Research Team의 상태, 에이전트, Supervisor를 정의합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41639e16",
   "metadata": {},
   "outputs": [],
   "source": "import operator\nfrom typing import List, TypedDict\nfrom typing_extensions import Annotated\n\nfrom langchain_core.messages import BaseMessage, HumanMessage\nfrom langchain_openai.chat_models import ChatOpenAI\nfrom langgraph.prebuilt import create_react_agent\n\n\nclass ResearchState(TypedDict):\n    \"\"\"Research Team 상태 정의\n\n    Attributes:\n        messages: 에이전트 간 공유하는 메시지 목록\n        team_members: 팀 멤버 에이전트 목록\n        next: 다음으로 실행할 에이전트\n    \"\"\"\n    messages: Annotated[List[BaseMessage], operator.add]\n    team_members: List[str]\n    next: str\n\n\n# LLM 초기화\nllm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n\n# Searcher 에이전트 및 노드 생성\nsearch_agent = create_react_agent(llm, tools=[tavily_tool])\nsearch_node = agent_factory.create_agent_node(search_agent, name=\"Searcher\")\n\n# WebScraper 에이전트 및 노드 생성\nweb_scraping_agent = create_react_agent(llm, tools=[scrape_webpages])\nweb_scraping_node = agent_factory.create_agent_node(\n    web_scraping_agent, name=\"WebScraper\"\n)\n\n# Research Team Supervisor 생성\nsupervisor_agent = create_team_supervisor(\n    MODEL_NAME,\n    \"You are a supervisor tasked with managing a conversation between the\"\n    \" following workers: Search, WebScraper. Given the following user request,\"\n    \" respond with the worker to act next. Each worker will perform a\"\n    \" task and respond with their results and status. When finished,\"\n    \" respond with FINISH.\",\n    [\"Searcher\", \"WebScraper\"],\n)"
  },
  {
   "cell_type": "markdown",
   "id": "9f9a53e2",
   "metadata": {},
   "source": "### 라우팅 함수 정의\n\nSupervisor의 결정에 따라 다음 노드를 선택하는 라우팅 함수를 정의합니다. 이 함수는 상태에서 `next` 값을 추출하여 반환합니다.\n\n아래 코드는 라우팅 함수를 정의합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2630c2",
   "metadata": {},
   "outputs": [],
   "source": "def get_next_node(x):\n    \"\"\"상태에서 다음 노드를 반환하는 함수\"\"\"\n    return x[\"next\"]"
  },
  {
   "cell_type": "markdown",
   "id": "b033a91f",
   "metadata": {},
   "source": "### Research Team 그래프 생성\n\nResearch Team의 StateGraph를 생성합니다. 노드와 엣지를 연결하여 워크플로우를 구성하고, Supervisor의 결정에 따라 작업자를 동적으로 선택합니다.\n\n아래 코드는 Research Team 그래프를 생성하고 컴파일합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09fa76a",
   "metadata": {},
   "outputs": [],
   "source": "from langchain_teddynote.graphs import visualize_graph\nfrom langgraph.graph import StateGraph\nfrom langgraph.checkpoint.memory import MemorySaver\n\n# Research Team 그래프 생성\nweb_research_graph = StateGraph(ResearchState)\n\n# 노드 추가\nweb_research_graph.add_node(\"Searcher\", search_node)\nweb_research_graph.add_node(\"WebScraper\", web_scraping_node)\nweb_research_graph.add_node(\"Supervisor\", supervisor_agent)\n\n# 작업자 -> Supervisor 엣지 추가\nweb_research_graph.add_edge(\"Searcher\", \"Supervisor\")\nweb_research_graph.add_edge(\"WebScraper\", \"Supervisor\")\n\n# 조건부 엣지: Supervisor의 결정에 따라 다음 노드로 이동\nweb_research_graph.add_conditional_edges(\n    \"Supervisor\",\n    get_next_node,\n    {\"Searcher\": \"Searcher\", \"WebScraper\": \"WebScraper\", \"FINISH\": END},\n)\n\n# 시작 노드 설정\nweb_research_graph.set_entry_point(\"Supervisor\")\n\n# 그래프 컴파일\nweb_research_app = web_research_graph.compile(checkpointer=MemorySaver())\n\n# 그래프 시각화\nvisualize_graph(web_research_app, xray=True)"
  },
  {
   "cell_type": "markdown",
   "id": "21af9f6e",
   "metadata": {},
   "source": "### Research Team 실행\n\n생성된 `web_research_app`을 실행하여 Research Team의 동작을 확인합니다. 실행 결과는 팀 멤버 간의 협업 과정을 보여줍니다.\n\n아래 코드는 그래프 실행을 위한 헬퍼 함수를 정의합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f9fc0b",
   "metadata": {},
   "outputs": [],
   "source": "from langchain_core.runnables import RunnableConfig\nfrom langchain_teddynote.messages import random_uuid, invoke_graph\n\n\ndef run_graph(app, message: str, recursive_limit: int = 50):\n    \"\"\"그래프 실행 헬퍼 함수\n\n    Args:\n        app: 컴파일된 그래프 앱\n        message: 사용자 입력 메시지\n        recursive_limit: 최대 재귀 횟수\n\n    Returns:\n        그래프 실행 후 최종 상태 값\n    \"\"\"\n    # 설정: 재귀 제한과 스레드 ID 지정\n    config = RunnableConfig(\n        recursion_limit=recursive_limit, \n        configurable={\"thread_id\": random_uuid()}\n    )\n\n    # 입력 메시지 구성\n    inputs = {\n        \"messages\": [HumanMessage(content=message)],\n    }\n\n    # 그래프 실행 및 결과 스트리밍\n    invoke_graph(app, inputs, config)\n\n    # 최종 상태 반환\n    return app.get_state(config).values"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf3ea7f",
   "metadata": {},
   "outputs": [],
   "source": "# Research Team 실행: 네이버 금융 뉴스 정리 요청\noutput = run_graph(\n    web_research_app,\n    \"https://finance.naver.com/news 의 주요 뉴스 정리해서 출력해줘. 출처(URL) 도 함께 출력해줘.\",\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297ac021",
   "metadata": {},
   "outputs": [],
   "source": "# 최종 결과 출력\nprint(output[\"messages\"][-1].content)"
  },
  {
   "cell_type": "markdown",
   "id": "94d75718",
   "metadata": {},
   "source": "### Doc Writing Team\n\n이번에는 문서 작성 팀(Doc Writing Team)을 생성합니다. 이 팀은 세 개의 작업자 에이전트로 구성됩니다.\n\n- **DocWriter**: 문서를 작성하고 편집합니다.\n- **NoteTaker**: 연구 자료를 바탕으로 개요를 작성합니다.\n- **ChartGenerator**: 데이터를 시각화하는 차트를 생성합니다.\n\n각 에이전트에게는 서로 다른 파일 접근 도구가 제공됩니다. 또한, 상태 전처리 노드를 통해 각 에이전트가 현재 작업 디렉토리의 파일 목록을 인식할 수 있도록 합니다.\n\n아래 코드는 Doc Writing Team의 상태, 에이전트, Supervisor를 정의합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893e58da",
   "metadata": {},
   "outputs": [],
   "source": "import operator\nfrom typing import List, TypedDict, Annotated\nfrom pathlib import Path\n\n# 작업 디렉토리 설정\nWORKING_DIRECTORY = Path(\"./tmp\")\nWORKING_DIRECTORY.mkdir(exist_ok=True)\n\n\nclass DocWritingState(TypedDict):\n    \"\"\"Doc Writing Team 상태 정의\n\n    Attributes:\n        messages: 에이전트 간 공유하는 메시지 목록\n        team_members: 팀 멤버 목록\n        next: 다음으로 실행할 에이전트\n        current_files: 현재 작업 디렉토리의 파일 목록\n    \"\"\"\n    messages: Annotated[List[BaseMessage], operator.add]\n    team_members: str\n    next: str\n    current_files: str\n\n\ndef preprocess(state):\n    \"\"\"상태 전처리 함수\n\n    작업 디렉토리의 파일 목록을 상태에 추가하여\n    에이전트가 현재 파일 상태를 인식할 수 있도록 합니다.\n    \"\"\"\n    written_files = []\n\n    try:\n        # 작업 디렉토리 내의 모든 파일 검색\n        written_files = [\n            f.relative_to(WORKING_DIRECTORY) for f in WORKING_DIRECTORY.rglob(\"*\")\n        ]\n    except Exception:\n        pass\n\n    # 파일이 없으면 해당 메시지 반환\n    if not written_files:\n        return {**state, \"current_files\": \"No files written.\"}\n\n    # 파일 목록을 상태에 추가\n    return {\n        **state,\n        \"current_files\": \"\\nBelow are files your team has written to the directory:\\n\"\n        + \"\\n\".join([f\" - {f}\" for f in written_files]),\n    }\n\n\n# LLM 초기화\nllm = ChatOpenAI(model=MODEL_NAME)\n\n# DocWriter 에이전트 생성\ndoc_writer_agent = create_react_agent(\n    llm,\n    tools=[write_document, edit_document, read_document],\n    prompt=\"You are a arxiv researcher. Your mission is to write arxiv style paper on given topic/resources.\",\n)\ncontext_aware_doc_writer_agent = preprocess | doc_writer_agent\ndoc_writing_node = agent_factory.create_agent_node(\n    context_aware_doc_writer_agent, name=\"DocWriter\"\n)\n\n# NoteTaker 에이전트 생성\nnote_taking_agent = create_react_agent(\n    llm,\n    tools=[create_outline, read_document],\n    prompt=\"You are an expert in creating outlines for research papers. Your mission is to create an outline for a given topic/resources or documents.\",\n)\ncontext_aware_note_taking_agent = preprocess | note_taking_agent\nnote_taking_node = agent_factory.create_agent_node(\n    context_aware_note_taking_agent, name=\"NoteTaker\"\n)\n\n# ChartGenerator 에이전트 생성\nchart_generating_agent = create_react_agent(\n    llm, tools=[read_document, python_repl_tool]\n)\ncontext_aware_chart_generating_agent = preprocess | chart_generating_agent\nchart_generating_node = agent_factory.create_agent_node(\n    context_aware_chart_generating_agent, name=\"ChartGenerator\"\n)\n\n# Doc Writing Team Supervisor 생성\ndoc_writing_supervisor = create_team_supervisor(\n    MODEL_NAME,\n    \"You are a supervisor tasked with managing a conversation between the\"\n    \" following workers:  ['DocWriter', 'NoteTaker', 'ChartGenerator']. Given the following user request,\"\n    \" respond with the worker to act next. Each worker will perform a\"\n    \" task and respond with their results and status. When finished,\"\n    \" respond with FINISH.\",\n    [\"DocWriter\", \"NoteTaker\", \"ChartGenerator\"],\n)"
  },
  {
   "cell_type": "markdown",
   "id": "2310e4cc",
   "metadata": {},
   "source": "### Doc Writing Team 그래프 생성\n\nDoc Writing Team의 StateGraph를 생성합니다. Research Team과 동일한 구조로 노드와 엣지를 연결합니다.\n\n아래 코드는 Doc Writing Team 그래프를 생성하고 컴파일합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba701f6",
   "metadata": {},
   "outputs": [],
   "source": "# Doc Writing Team 그래프 생성\nauthoring_graph = StateGraph(DocWritingState)\n\n# 노드 추가\nauthoring_graph.add_node(\"DocWriter\", doc_writing_node)\nauthoring_graph.add_node(\"NoteTaker\", note_taking_node)\nauthoring_graph.add_node(\"ChartGenerator\", chart_generating_node)\nauthoring_graph.add_node(\"Supervisor\", doc_writing_supervisor)\n\n# 작업자 -> Supervisor 엣지 추가\nauthoring_graph.add_edge(\"DocWriter\", \"Supervisor\")\nauthoring_graph.add_edge(\"NoteTaker\", \"Supervisor\")\nauthoring_graph.add_edge(\"ChartGenerator\", \"Supervisor\")\n\n# 조건부 엣지: Supervisor의 결정에 따라 다음 노드로 이동\nauthoring_graph.add_conditional_edges(\n    \"Supervisor\",\n    get_next_node,\n    {\n        \"DocWriter\": \"DocWriter\",\n        \"NoteTaker\": \"NoteTaker\",\n        \"ChartGenerator\": \"ChartGenerator\",\n        \"FINISH\": END,\n    },\n)\n\n# 시작 노드 설정\nauthoring_graph.set_entry_point(\"Supervisor\")\n\n# 그래프 컴파일\nauthoring_app = authoring_graph.compile(checkpointer=MemorySaver())"
  },
  {
   "cell_type": "markdown",
   "id": "07a8259a",
   "metadata": {},
   "source": "### Doc Writing Team 시각화\n\n생성된 Doc Writing Team 그래프를 시각화합니다.\n\n아래 코드는 그래프 구조를 시각화합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f82555f",
   "metadata": {},
   "outputs": [],
   "source": "from langchain_teddynote.graphs import visualize_graph\n\n# Doc Writing Team 그래프 시각화\nvisualize_graph(authoring_app, xray=True)"
  },
  {
   "cell_type": "markdown",
   "id": "868d9c65",
   "metadata": {},
   "source": "### Doc Writing Team 실행\n\nDoc Writing Team 그래프를 실행하여 문서 작성 과정을 확인합니다. 이 예시에서는 Transformer 구조에 대한 논문 작성을 요청합니다.\n\n아래 코드는 Doc Writing Team을 실행합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc641fb1",
   "metadata": {},
   "outputs": [],
   "source": "# Doc Writing Team 실행: Transformer 구조 논문 작성 요청\noutput = run_graph(\n    authoring_app,\n    \"Transformer 의 구조에 대해서 심층 파악해서 논문의 목차를 한글로 작성해줘. \"\n    \"그 다음 각각의 목차에 대해서 5문장 이상 작성해줘. \"\n    \"상세내용 작성시 만약 chart 가 필요하면 차트를 작성해줘. \"\n    \"최종 결과를 저장해줘. \",\n)"
  },
  {
   "cell_type": "markdown",
   "id": "8f6be24f",
   "metadata": {},
   "source": "## Super-Graph 생성\n\n이 설계에서는 **상향식 계획 정책**을 적용하고 있습니다. 앞서 두 개의 팀 그래프(Research Team, Doc Writing Team)를 생성했습니다. 이제 이 두 팀을 조정하는 상위 수준의 **Super-Graph**를 정의합니다.\n\nSuper-Graph는 다음 역할을 수행합니다.\n\n- **팀 간 작업 라우팅**: 사용자 요청에 따라 적절한 팀에 작업을 할당합니다.\n- **상태 공유 관리**: 서로 다른 그래프 간에 상태가 어떻게 공유되는지 정의합니다.\n- **최종 결과 조합**: 각 팀의 결과를 취합하여 최종 응답을 생성합니다.\n\n아래 코드는 Super-Graph의 총 감독자 노드를 생성합니다."
  },
  {
   "cell_type": "markdown",
   "id": "60adddf3",
   "metadata": {},
   "source": "### 총 감독자 노드 생성\n\n먼저 두 팀(ResearchTeam, PaperWritingTeam)을 관리하는 총 감독자 노드를 생성합니다.\n\n아래 코드는 총 감독자를 정의합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dda4e3b",
   "metadata": {},
   "outputs": [],
   "source": "from langchain_core.messages import BaseMessage\nfrom langchain_openai.chat_models import ChatOpenAI\n\n# LLM 초기화\nllm = ChatOpenAI(model=MODEL_NAME)\n\n# 총 감독자 노드 생성: 두 팀을 관리\nsupervisor_node = create_team_supervisor(\n    MODEL_NAME,\n    \"You are a supervisor tasked with managing a conversation between the\"\n    \" following teams: ['ResearchTeam', 'PaperWritingTeam']. Given the following user request,\"\n    \" respond with the worker to act next. Each worker will perform a\"\n    \" task and respond with their results and status. When finished,\"\n    \" respond with FINISH.\",\n    [\"ResearchTeam\", \"PaperWritingTeam\"],\n)"
  },
  {
   "cell_type": "markdown",
   "id": "ffb93745",
   "metadata": {},
   "source": "### Super-Graph 상태 및 노드 정의\n\nSuper-Graph의 상태와 유틸리티 노드를 정의합니다. Super-Graph는 주로 팀 간 작업을 라우팅하는 역할을 수행합니다.\n\n- **get_last_message**: 마지막 메시지를 추출하여 하위 그래프에 전달합니다.\n- **join_graph**: 하위 그래프의 결과를 취합합니다.\n\n아래 코드는 Super-Graph 상태와 유틸리티 노드를 정의합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d4f4d3",
   "metadata": {},
   "outputs": [],
   "source": "from typing import TypedDict, List, Annotated\nimport operator\n\n\nclass State(TypedDict):\n    \"\"\"Super-Graph 상태 정의\n\n    Attributes:\n        messages: 메시지 목록\n        next: 다음으로 실행할 팀 또는 FINISH\n    \"\"\"\n    messages: Annotated[List[BaseMessage], operator.add]\n    next: str\n\n\ndef get_last_message(state: State) -> str:\n    \"\"\"마지막 메시지 추출 함수\n\n    상태에서 마지막 메시지를 추출하여 하위 그래프에 전달합니다.\n    \"\"\"\n    last_message = state[\"messages\"][-1]\n    if isinstance(last_message, str):\n        return {\"messages\": [HumanMessage(content=last_message)]}\n    else:\n        return {\"messages\": [last_message.content]}\n\n\ndef join_graph(response: dict):\n    \"\"\"그래프 결과 취합 함수\n\n    하위 그래프의 마지막 메시지를 추출하여 반환합니다.\n    \"\"\"\n    return {\"messages\": [response[\"messages\"][-1]]}"
  },
  {
   "cell_type": "markdown",
   "id": "61c6add6",
   "metadata": {},
   "source": "### Super-Graph 구성\n\n이제 두 팀을 연결하는 Super-Graph를 정의합니다. 각 팀은 서브그래프로 포함되며, 총 감독자가 팀 간 작업을 조정합니다.\n\n아래 코드는 Super-Graph를 생성하고 컴파일합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddacbb75",
   "metadata": {},
   "outputs": [],
   "source": "# Super-Graph 생성\nsuper_graph = StateGraph(State)\n\n# 노드 추가: 각 팀을 서브그래프로 연결\nsuper_graph.add_node(\"ResearchTeam\", get_last_message | web_research_app | join_graph)\nsuper_graph.add_node(\"PaperWritingTeam\", get_last_message | authoring_app | join_graph)\nsuper_graph.add_node(\"Supervisor\", supervisor_node)\n\n# 팀 -> Supervisor 엣지 추가\nsuper_graph.add_edge(\"ResearchTeam\", \"Supervisor\")\nsuper_graph.add_edge(\"PaperWritingTeam\", \"Supervisor\")\n\n# 조건부 엣지: Supervisor의 결정에 따라 다음 팀으로 이동\nsuper_graph.add_conditional_edges(\n    \"Supervisor\",\n    get_next_node,\n    {\n        \"PaperWritingTeam\": \"PaperWritingTeam\",\n        \"ResearchTeam\": \"ResearchTeam\",\n        \"FINISH\": END,\n    },\n)\n\n# 시작 노드: Supervisor\nsuper_graph.set_entry_point(\"Supervisor\")\n\n# 그래프 컴파일\nsuper_graph = super_graph.compile(checkpointer=MemorySaver())"
  },
  {
   "cell_type": "markdown",
   "id": "73759297",
   "metadata": {},
   "source": "### Super-Graph 시각화\n\n완성된 Super-Graph 구조를 시각화합니다. 계층적 구조가 어떻게 구성되어 있는지 확인할 수 있습니다.\n\n아래 코드는 Super-Graph를 시각화합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e39e0f",
   "metadata": {},
   "outputs": [],
   "source": "from langchain_teddynote.graphs import visualize_graph\n\n# Super-Graph 시각화\nvisualize_graph(super_graph)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5f5ef6",
   "metadata": {},
   "outputs": [],
   "source": "# Super-Graph 실행: Multi-Agent 구조에 대한 논문 작성 요청\noutput = run_graph(\n    super_graph,\n    \"\"\"주제: multi-agent 구조를 사용하여 복잡한 작업을 수행하는 방법\n\n상세 가이드라인:  \n- 주제에 대한 Arxiv 논문 형식의 리포트 생성\n- Outline 생성\n- 각각의 Outline 에 대해서 5문장 이상 작성\n- 상세내용 작성시 만약 chart 가 필요하면 차트 생성 및 추가\n- 한글로 리포트 작성\n- 출처는 APA 형식으로 작성\n- 최종 결과는 .md 파일로 저장\"\"\",\n    recursive_limit=150,\n)"
  },
  {
   "cell_type": "markdown",
   "id": "58313e30",
   "metadata": {},
   "source": "### 결과 출력\n\n마크다운 형식으로 최종 결과물을 출력합니다.\n\n아래 코드는 실행 결과를 마크다운으로 렌더링합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2c963d",
   "metadata": {},
   "outputs": [],
   "source": "from IPython.display import Markdown\n\n# 마크다운 형식으로 결과 출력\nif hasattr(output[\"messages\"][-1], \"content\"):\n    display(Markdown(output[\"messages\"][-1].content))\nelse:\n    display(Markdown(output[\"messages\"][-1]))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1279e7a7",
   "metadata": {},
   "outputs": [],
   "source": "# 원본 메시지 출력\nprint(output[\"messages\"][-1])"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-CdOel15G-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}