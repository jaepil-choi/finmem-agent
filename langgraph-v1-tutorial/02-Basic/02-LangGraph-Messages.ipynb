{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 메시지 (Messages)\n\n메시지는 LangChain에서 모델과의 대화를 나타내는 기본 단위입니다. 모든 LLM 상호작용은 메시지를 통해 이루어지며, 각 메시지는 역할(role), 콘텐츠(content), 메타데이터를 포함합니다.\n\nLangGraph 애플리케이션에서 메시지는 상태(State)의 핵심 구성 요소로 사용됩니다. 대화 이력을 관리하고, 도구 호출 결과를 전달하며, 멀티모달 콘텐츠를 처리하는 데 활용됩니다.\n\n메시지 객체는 다음을 포함합니다:\n\n- **역할(Role)**: 메시지 유형을 식별 (예: `system`, `user`, `assistant`)\n- **콘텐츠(Content)**: 메시지의 실제 내용 (텍스트, 이미지, 오디오, 문서 등)\n- **메타데이터(Metadata)**: 응답 정보, 메시지 ID, 토큰 사용량 등의 선택적 필드\n\nLangChain은 모델 제공자에 관계없이 일관된 동작을 보장하는 표준 메시지 유형을 제공합니다."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 환경 설정\n\nLangGraph 튜토리얼을 시작하기 전에 필요한 환경을 설정합니다. `dotenv`를 사용하여 API 키를 로드하고, `langchain_teddynote`의 로깅 기능을 활성화하여 LangSmith에서 실행 추적을 확인할 수 있도록 합니다.\n\nLangSmith 추적을 활성화하면 메시지 흐름을 시각적으로 디버깅할 수 있어, 대화 기반 애플리케이션 개발에 큰 도움이 됩니다.\n\n아래 코드는 환경 변수를 로드하고 LangSmith 프로젝트를 설정합니다."
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "LangChain-V1-Tutorial\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv(override=True)\n",
    "# 추적을 위한 프로젝트 이름 설정\n",
    "logging.langsmith(\"LangChain-V1-Tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 기본 사용법\n\n메시지를 사용하는 가장 간단한 방법은 메시지 객체를 생성하고 모델을 호출할 때 리스트로 전달하는 것입니다. `SystemMessage`는 모델의 행동을 지시하고, `HumanMessage`는 사용자 입력을 나타내며, `AIMessage`는 모델의 응답을 나타냅니다.\n\n메시지 리스트를 모델에 전달하면 대화 컨텍스트가 유지되며, 모델은 이전 대화 내용을 참고하여 응답을 생성합니다.\n\n아래 코드는 시스템 메시지와 사용자 메시지를 생성하고 모델을 호출하는 기본 예시입니다."
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 반갑습니다. 어떻게 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 27, 'total_tokens': 41, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-CeOaX8iMCjEQCKEUjYKwelwEYxjmh', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--42a1b4c8-9eaa-4009-92f2-5bb3f06f1d63-0', usage_metadata={'input_tokens': 27, 'output_tokens': 14, 'total_tokens': 41, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "# 모델 초기화\n",
    "model = init_chat_model(\"openai:gpt-4.1-mini\")\n",
    "\n",
    "# 메시지 객체 생성\n",
    "system_msg = SystemMessage(\"당신은 친절한 Assistant입니다.\")\n",
    "human_msg = HumanMessage(\"안녕하세요. 반갑습니다.\")\n",
    "\n",
    "# 채팅 모델과 함께 사용\n",
    "messages = [system_msg, human_msg]\n",
    "response = model.invoke(messages)  # AIMessage 반환\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 텍스트 프롬프트\n\n단순한 텍스트 문자열만으로도 모델을 호출할 수 있습니다. 이 방식은 대화 기록이 필요 없는 간단한 생성 작업에 적합합니다. 문자열을 전달하면 내부적으로 `HumanMessage`로 변환되어 처리됩니다.\n\n아래 코드는 단일 문자열로 모델을 호출하는 예시입니다."
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국의 수도는 서울특별시입니다.\n"
     ]
    }
   ],
   "source": [
    "# 단일 문자열로 간단한 요청\n",
    "response = model.invoke(\"대한민국의 수도는?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 메시지 프롬프트\n\n복잡한 대화나 멀티턴 상호작용에서는 메시지 객체 리스트를 사용합니다. 각 메시지 유형(`SystemMessage`, `HumanMessage`, `AIMessage`)을 조합하여 풍부한 대화 컨텍스트를 구성할 수 있습니다.\n\n**메시지 프롬프트를 사용하는 경우:**\n- 다중 턴 대화를 관리하는 경우\n- 멀티모달 콘텐츠(이미지, 오디오, 파일)를 작업하는 경우\n- 시스템 지침을 포함하는 경우\n- 이전 대화 맥락을 유지해야 하는 경우\n\n아래 코드는 메시지 객체 리스트로 다중 턴 대화를 구성하는 예시입니다."
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of South Korea is Seoul.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# 메시지 객체를 사용한 대화\n",
    "messages = [\n",
    "    SystemMessage(\"당신은 친절한 어시스턴트입니다.\"),\n",
    "    HumanMessage(\"대한민국의 수도는?\"),\n",
    "    AIMessage(\"대한민국의 수도는 서울입니다.\"),\n",
    "    HumanMessage(\"영어로 작성해줘.\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 딕셔너리 형식\n\n메시지 객체 대신 딕셔너리 형식으로도 메시지를 지정할 수 있습니다. `role` 키에는 역할(`system`, `user`, `assistant`)을, `content` 키에는 메시지 내용을 지정합니다. 이 방식은 JSON 직렬화가 필요한 경우나 간결한 코드 작성에 유용합니다.\n\n아래 코드는 딕셔너리 형식으로 대화를 구성하는 예시입니다."
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of South Korea is Seoul.\n"
     ]
    }
   ],
   "source": [
    "# 딕셔너리 형식으로 메시지 지정\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"당신은 친절한 어시스턴트입니다.\"},\n",
    "    {\"role\": \"user\", \"content\": \"대한민국의 수도는?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"대한민국의 수도는 서울입니다.\"},\n",
    "    {\"role\": \"user\", \"content\": \"영어로 작성해줘.\"},\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 메시지 유형\n\nLangChain은 네 가지 핵심 메시지 유형을 제공합니다. 각 유형은 대화에서 서로 다른 역할을 담당하며, 올바른 유형을 사용하는 것이 효과적인 프롬프트 엔지니어링의 기본입니다.\n\n| 메시지 유형 | 설명 | 사용 시점 |\n|:---|:---|:---|\n| **SystemMessage** | 모델의 동작 방식과 역할을 정의 | 대화 시작 시 모델 행동 지침 설정 |\n| **HumanMessage** | 사용자 입력을 나타냄 | 사용자의 질문이나 요청 전달 |\n| **AIMessage** | 모델이 생성한 응답 | 이전 응답 기록 유지, 도구 호출 정보 포함 |\n| **ToolMessage** | 도구 호출의 결과 | 도구 실행 결과를 모델에 전달 |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### SystemMessage (시스템 메시지)\n\n시스템 메시지는 모델의 동작을 준비하는 초기 지침 세트입니다. 대화의 맨 처음에 위치하며, 모델의 역할, 톤, 응답 스타일, 제약 조건 등을 정의합니다.\n\n효과적인 시스템 메시지는 일관된 모델 동작을 이끌어내며, 모델이 특정 도메인 전문가나 특정 성격의 어시스턴트처럼 행동하도록 지시할 수 있습니다.\n\n아래 코드는 시스템 메시지로 모델의 역할을 정의하고 응답을 생성하는 예시입니다."
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로또 번호 추첨 파이썬 코드를 작성해봤습니다. 일반적으로 로또는 1부터 45까지 숫자 중에서 6개를 중복 없이 무작위로 뽑는 방식입니다.\n",
      "\n",
      "아래 코드를 참고하세요:\n",
      "\n",
      "```python\n",
      "import random\n",
      "\n",
      "def generate_lotto_numbers():\n",
      "    # 1부터 45까지 숫자 리스트에서 6개를 무작위로 선택\n",
      "    numbers = random.sample(range(1, 46), 6)\n",
      "    numbers.sort()  # 정렬해서 출력하면 보기 편함\n",
      "    return numbers\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    lotto_numbers = generate_lotto_numbers()\n",
      "    print(\"이번 주 로또 번호:\", lotto_numbers)\n",
      "```\n",
      "\n",
      "코드를 실행하면 매번 새로운 6개의 로또 번호가 출력됩니다. 필요하면 보너스 번호 추가 등으로 확장할 수도 있습니다!\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# 기본 지침\n",
    "system_msg = SystemMessage(\"You are a helpful python coding assistant.\")\n",
    "\n",
    "messages = [system_msg, HumanMessage(\"로또 번호 추첨 코드를 작성해줘.\")]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### HumanMessage (사용자 메시지)\n\n사용자 메시지는 사용자의 입력과 요청을 나타냅니다. 텍스트뿐만 아니라 이미지, 오디오, 파일 등 다양한 형태의 멀티모달 콘텐츠를 포함할 수 있습니다.\n\nLangGraph 애플리케이션에서 사용자 메시지는 그래프 실행의 시작점이 되며, 상태(State)의 메시지 리스트에 추가되어 대화 이력을 형성합니다.\n\n아래 코드는 HumanMessage 객체를 생성하고 모델을 호출하는 예시입니다."
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning is a branch of artificial intelligence (AI) that focuses on developing algorithms and statistical models that enable computers to learn from and make predictions or decisions based on data, without being explicitly programmed for every specific task. Instead of following fixed instructions, machine learning systems improve their performance over time by identifying patterns and relationships within data.\n",
      "\n",
      "In essence, machine learning involves training a model on a dataset so that it can generalize and make accurate predictions or classifications on new, unseen data. Common types of machine learning include:\n",
      "\n",
      "- **Supervised learning:** The model is trained on labeled data, where the input-output pairs are known.\n",
      "- **Unsupervised learning:** The model identifies patterns or groupings in unlabeled data.\n",
      "- **Reinforcement learning:** The model learns to make decisions by receiving rewards or penalties based on its actions.\n",
      "\n",
      "Machine learning is widely used in applications such as image and speech recognition, recommendation systems, natural language processing, and autonomous vehicles.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "# 메시지 객체 사용\n",
    "response = model.invoke([HumanMessage(\"What is machine learning?\")])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 메시지 메타데이터\n\n메시지에는 `content` 외에도 다양한 메타데이터를 추가할 수 있습니다. `name`은 다중 사용자 환경에서 발신자를 식별하는 데 사용되고, `id`는 메시지를 고유하게 식별하여 추적 및 참조에 활용됩니다.\n\n메타데이터는 대화 분석, 로깅, 사용자별 응답 개인화 등 다양한 용도로 활용할 수 있습니다.\n\n아래 코드는 메타데이터가 포함된 HumanMessage를 생성하는 예시입니다."
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content='안녕하세요? 반가워요', additional_kwargs={}, response_metadata={}, name='teddy', id='abc123')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메타데이터 추가\n",
    "human_msg = HumanMessage(\n",
    "    content=\"안녕하세요? 반가워요\",\n",
    "    name=\"teddy\",  # 선택사항: 다른 사용자 식별\n",
    "    id=\"abc123\",  # 선택사항: 추적을 위한 고유 식별자\n",
    ")\n",
    "\n",
    "human_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 반가워요. 어떻게 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 16, 'total_tokens': 31, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-CeOe5ECs9cXdJpyOXITDe0ct8wLS5', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--99327fc7-e9db-4848-bf98-7503ad8545d3-0', usage_metadata={'input_tokens': 16, 'output_tokens': 15, 'total_tokens': 31, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke([human_msg])\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### AIMessage (AI 메시지)\n\nAI 메시지는 모델 호출의 출력을 나타냅니다. 텍스트 응답뿐만 아니라 도구 호출 정보(`tool_calls`), 토큰 사용량, 응답 메타데이터 등을 포함할 수 있습니다.\n\n대화 이력을 유지할 때 이전 AI 응답을 `AIMessage`로 포함시키면, 모델이 자신의 이전 발언을 인식하고 일관된 대화를 이어갈 수 있습니다.\n\n아래 코드는 모델 호출 후 반환되는 AIMessage의 구조를 확인하는 예시입니다."
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "Content: 대한민국의 수도는 서울입니다.\n"
     ]
    }
   ],
   "source": [
    "# 모델 호출 시 AIMessage 반환\n",
    "response = model.invoke(\"대한민국의 수도는?\")\n",
    "print(f\"Type: {type(response)}\")\n",
    "print(f\"Content: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ToolMessage (도구 메시지)\n\n도구 호출을 지원하는 모델에서 AI 메시지에 도구 호출(`tool_calls`)이 포함될 수 있습니다. 도구 메시지는 도구 실행 결과를 모델에 다시 전달하는 데 사용됩니다.\n\nLangGraph 에이전트에서 도구 호출 흐름은 다음과 같습니다:\n1. 사용자 질문 (HumanMessage)\n2. 모델이 도구 호출 결정 (AIMessage with tool_calls)\n3. 도구 실행 및 결과 반환 (ToolMessage)\n4. 모델이 결과를 해석하여 최종 응답 (AIMessage)\n\n![](assets/LangGraph-Messages-Tool-Message.png)\n\n아래 코드는 도구 호출 정보가 포함된 AIMessage를 생성하는 예시입니다."
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={}, response_metadata={}, tool_calls=[{'name': 'get_weather', 'args': {'location': '서울'}, 'id': 'call_123', 'type': 'tool_call'}])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.messages import AIMessage, HumanMessage, ToolMessage\n",
    "\n",
    "# 모델이 도구 호출을 수행한 후\n",
    "ai_message = AIMessage(\n",
    "    content=\"\",\n",
    "    tool_calls=[\n",
    "        {\"name\": \"get_weather\", \"args\": {\"location\": \"서울\"}, \"id\": \"call_123\"}\n",
    "    ],\n",
    ")\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ToolMessage 생성\n\n`ToolMessage`를 생성할 때 중요한 점은 `tool_call_id`가 해당 도구를 호출한 `AIMessage`의 `tool_calls` 내 `id`와 일치해야 한다는 것입니다. 이 ID를 통해 모델은 어떤 도구 호출에 대한 결과인지 정확히 파악할 수 있습니다.\n\n아래 코드는 도구 실행 결과를 담은 ToolMessage를 생성하는 예시입니다."
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='날씨 맑음. 섭씨 10도', tool_call_id='call_123')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 도구 실행 및 결과 메시지 생성\n",
    "weather_result = \"날씨 맑음. 섭씨 10도\"\n",
    "tool_message = ToolMessage(\n",
    "    content=weather_result, tool_call_id=\"call_123\"  # 호출 ID와 일치해야 함\n",
    ")\n",
    "tool_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 도구 호출 대화 흐름\n\n도구 호출이 포함된 완전한 대화 흐름은 다음과 같이 구성됩니다:\n1. `HumanMessage`: 사용자의 원래 질문\n2. `AIMessage`: 모델의 도구 호출 결정 (tool_calls 포함)\n3. `ToolMessage`: 도구 실행 결과\n\n이 세 메시지를 모델에 전달하면, 모델은 도구 실행 결과를 바탕으로 사용자에게 최종 응답을 생성합니다.\n\n아래 코드는 도구 호출이 포함된 완전한 대화 흐름의 예시입니다."
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "지금 서울은 맑고 기온은 섭씨 10도입니다. 도움이 필요하시면 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "# 대화 계속\n",
    "messages = [\n",
    "    HumanMessage(\"서울의 날씨는 어때?\"),\n",
    "    ai_message,  # 모델의 도구 호출\n",
    "    tool_message,  # 도구 실행 결과\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)  # 모델이 결과 처리\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 메시지 콘텐츠\n\n메시지의 `content` 속성은 모델로 전송되는 실제 데이터를 담습니다. 단순 문자열부터 멀티모달 콘텐츠(이미지, 오디오 등)까지 다양한 형태를 지원합니다.\n\nLangChain은 두 가지 콘텐츠 형식을 지원합니다:\n- **문자열**: 단순 텍스트 메시지\n- **콘텐츠 블록 리스트**: 텍스트, 이미지, 오디오 등을 조합한 멀티모달 메시지\n\n아래 코드는 다양한 콘텐츠 형식을 사용하는 예시입니다."
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String content: Hello, how are you?\n",
      "Provider 네이티브 형식: [{'type': 'text', 'text': '다음은 어떤 내용인지 설명해줘'}, {'type': 'image_url', 'image_url': {'url': 'https://blog.langchain.com/content/images/2023/09/image.png'}}]\n",
      "이 이미지는 데이터 처리 및 저장의 전반적인 흐름을 나타내고 있습니다. \n",
      "\n",
      "1. **Source (출처)**: 다양한 데이터 출처(예: 슬랙, 유튜브, 게임, 깃허브, 구글 드라이브, PDF, CSV, DOC, TXT, PPT, 트위터, 이메일 등)에서 데이터를 가져옵니다.\n",
      "\n",
      "2. **Load (로드)**: 출처에서 데이터를 불러와 초기 형태로 저장합니다.\n",
      "\n",
      "3. **Transform (변환)**: 데이터를 일정한 형식으로 변환하거나 전처리하는 과정입니다.\n",
      "\n",
      "4. **Embed (임베드)**: 변환된 데이터를 벡터나 숫자 형태의 임베딩 표현으로 바꿉니다. 이는 머신러닝이나 검색에 활용할 수 있는 형태입니다.\n",
      "\n",
      "5. **Store (저장)**: 임베딩된 데이터를 저장소에 저장합니다.\n",
      "\n",
      "6. **Retrieve (검색/조회)**: 저장된 데이터를 필요할 때 조회하거나 검색하는 단계입니다.\n",
      "\n",
      "요약하면, 이 그림은 다양한 원천 데이터로부터 데이터를 수집하고, 이를 정제 및 임베딩하여 저장한 후, 필요한 시점에 검색할 수 있게 하는 데이터 파이프라인 과정을 보여줍니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"openai:gpt-4.1-mini\")\n",
    "\n",
    "# 문자열 콘텐츠\n",
    "human_message = HumanMessage(\"Hello, how are you?\")\n",
    "print(\"String content:\", human_message.content)\n",
    "\n",
    "# Provider 네이티브 형식 (예: OpenAI)\n",
    "human_message = HumanMessage(\n",
    "    content=[\n",
    "        {\"type\": \"text\", \"text\": \"다음은 어떤 내용인지 설명해줘\"},\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": \"https://blog.langchain.com/content/images/2023/09/image.png\"\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "print(\"Provider 네이티브 형식:\", human_message.content)\n",
    "\n",
    "response = model.invoke([human_message])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "표준 콘텐츠 블록: [{'type': 'text', 'text': '다음은 어떤 내용인지 설명해줘'}, {'type': 'image', 'url': 'https://blog.langchain.com/content/images/2023/09/image.png'}]\n",
      "이 이미지는 데이터 처리 파이프라인의 흐름을 설명하는 다이어그램입니다. \n",
      "\n",
      "1. **Source (데이터 소스)**: 다양한 형태와 출처(예: 슬랙, 유튜브, 게임, 깃허브, PDF, 문서, CSV, 이미지, 이메일, 웹페이지 등)에서 데이터를 수집하는 단계입니다.\n",
      "\n",
      "2. **Load (로딩)**: 수집된 원본 데이터를 시스템에 로드하는 단계입니다.\n",
      "\n",
      "3. **Transform (변환)**: 로드된 데이터를 필요한 형식으로 가공하거나 정제하는 단계입니다.\n",
      "\n",
      "4. **Embed (임베딩)**: 텍스트나 데이터를 벡터 형태(숫자 배열)로 변환하는 단계입니다. 이는 머신러닝 모델이나 검색 시스템에서 활용할 수 있는 형태입니다.\n",
      "\n",
      "5. **Store (저장)**: 임베딩된 데이터를 데이터베이스나 저장소에 저장하는 단계입니다.\n",
      "\n",
      "6. **Retrieve (검색/조회)**: 저장된 데이터를 필요할 때 불러오는 단계입니다.\n",
      "\n",
      "전체적으로 다양한 소스에서 데이터를 수집하여, 이를 정제 및 변환 후 벡터 임베딩하고, 벡터 데이터를 저장하고 나중에 검색할 수 있는 데이터 처리 및 관리의 전 과정을 시각화한 것입니다.\n"
     ]
    }
   ],
   "source": [
    "# 표준 콘텐츠 블록 목록\n",
    "human_message = HumanMessage(\n",
    "    content_blocks=[\n",
    "        {\"type\": \"text\", \"text\": \"다음은 어떤 내용인지 설명해줘\"},\n",
    "        {\n",
    "            \"type\": \"image\",\n",
    "            \"url\": \"https://blog.langchain.com/content/images/2023/09/image.png\",\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "print(\"표준 콘텐츠 블록:\", human_message.content_blocks)\n",
    "\n",
    "response = model.invoke([human_message])\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}