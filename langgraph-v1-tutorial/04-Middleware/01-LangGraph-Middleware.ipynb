{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ë¯¸ë“¤ì›¨ì–´(Middleware)\n\në¯¸ë“¤ì›¨ì–´ëŠ” ì—ì´ì „íŠ¸ ì‹¤í–‰ì˜ ëª¨ë“  ë‹¨ê³„ë¥¼ ì œì–´í•˜ê³  ì»¤ìŠ¤í„°ë§ˆì´ì§•í•˜ëŠ” ê°•ë ¥í•œ ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤. í•µì‹¬ ì—ì´ì „íŠ¸ ë£¨í”„ëŠ” ëª¨ë¸ì„ í˜¸ì¶œí•˜ê³ , ëª¨ë¸ì´ ì‹¤í–‰í•  ë„êµ¬ë¥¼ ì„ íƒí•œ ë‹¤ìŒ, ë” ì´ìƒ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì§€ ì•Šìœ¼ë©´ ì¢…ë£Œí•˜ëŠ” ê³¼ì •ì„ í¬í•¨í•©ë‹ˆë‹¤. ë¯¸ë“¤ì›¨ì–´ë¥¼ ì‚¬ìš©í•˜ë©´ ì´ ê° ë‹¨ê³„ ì „í›„ì— ì»¤ìŠ¤í…€ ë¡œì§ì„ ì‚½ì…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n![](./assets/langgraph-middleware.avif)\n\në¯¸ë“¤ì›¨ì–´ëŠ” ë‹¤ìŒê³¼ ê°™ì€ í›„í¬(Hook)ë¥¼ ë…¸ì¶œí•©ë‹ˆë‹¤:\n\n- ì—ì´ì „íŠ¸ ì‹œì‘ ì „/í›„\n- ëª¨ë¸ í˜¸ì¶œ ì „/í›„\n- ë„êµ¬ ì‹¤í–‰ ì „/í›„\n\nì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ë‚´ì¥ ë¯¸ë“¤ì›¨ì–´ ì‚¬ìš©ë²•ê³¼ ì»¤ìŠ¤í…€ ë¯¸ë“¤ì›¨ì–´ êµ¬í˜„ ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ì‚¬ì „ ì¤€ë¹„\n\nLangGraph ë¯¸ë“¤ì›¨ì–´ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” ë¨¼ì € í™˜ê²½ ë³€ìˆ˜ì™€ LangSmith ì¶”ì ì„ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ì—ëŠ” OpenAI API í‚¤, Anthropic API í‚¤ ë“± LLM ì„œë¹„ìŠ¤ ì¸ì¦ ì •ë³´ê°€ í¬í•¨ë©ë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” `.env` íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•˜ê³ , LangSmith ì¶”ì ì„ í™œì„±í™”í•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "LangChain-V1-Tutorial\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "logging.langsmith(\"LangChain-V1-Tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¯¸ë“¤ì›¨ì–´ê°€ í•  ìˆ˜ ìˆëŠ” ê²ƒ\n",
    "\n",
    "ë¯¸ë“¤ì›¨ì–´ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë‹¤ì–‘í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "- **ëª¨ë‹ˆí„°ë§** - ë¡œê¹…, ë¶„ì„ ë° ë””ë²„ê¹…ìœ¼ë¡œ ì—ì´ì „íŠ¸ ë™ì‘ ì¶”ì \n",
    "- **ìˆ˜ì •** - í”„ë¡¬í”„íŠ¸, ë„êµ¬ ì„ íƒ ë° ì¶œë ¥ í˜•ì‹ ë³€í™˜\n",
    "- **ì œì–´** - ì¬ì‹œë„, í´ë°± ë° ì¡°ê¸° ì¢…ë£Œ ë¡œì§ ì¶”ê°€\n",
    "- **ê°•ì œ** - ì†ë„ ì œí•œ, ê°€ë“œë ˆì¼ ë° PII ê°ì§€ ì ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ê¸°ë³¸ ì˜ˆì œ\n\në¯¸ë“¤ì›¨ì–´ë¥¼ ì—ì´ì „íŠ¸ì— ì¶”ê°€í•˜ë ¤ë©´ `create_agent` í•¨ìˆ˜ì˜ `middleware` ë§¤ê°œë³€ìˆ˜ì— ë¯¸ë“¤ì›¨ì–´ ë¦¬ìŠ¤íŠ¸ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤. ë¯¸ë“¤ì›¨ì–´ëŠ” ì—ì´ì „íŠ¸ ì‹¤í–‰ì˜ ê° ë‹¨ê³„ì—ì„œ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ë˜ë©°, ìš”ì²­ê³¼ ì‘ë‹µì„ ê°€ë¡œì±„ì–´ ìˆ˜ì •í•˜ê±°ë‚˜ ë¡œê¹…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” ê°„ë‹¨í•œ ë‚ ì”¨ ì¡°íšŒ ë„êµ¬ë¥¼ ì •ì˜í•˜ê³ , ë¹ˆ ë¯¸ë“¤ì›¨ì–´ ë¦¬ìŠ¤íŠ¸ì™€ í•¨ê»˜ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ê¸°ë³¸ ì˜ˆì œì…ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mtools\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "It's sunny in Seoul!\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "The weather in Seoul is sunny. Is there anything else you would like to know?"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "from langchain_teddynote.messages import stream_graph\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "\n",
    "# ê°„ë‹¨í•œ ë„êµ¬ ì •ì˜\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the weather for a given city.\"\"\"\n",
    "    return f\"It's sunny in {city}!\"\n",
    "\n",
    "\n",
    "# ëª¨ë¸ ë° ì—ì´ì „íŠ¸ ìƒì„±\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    middleware=[],  # ì—¬ê¸°ì— ë¯¸ë“¤ì›¨ì–´ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤\n",
    ")\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ì‹¤í–‰\n",
    "stream_graph(\n",
    "    agent,\n",
    "    inputs={\"messages\": [{\"role\": \"user\", \"content\": \"What's the weather in Seoul?\"}]},\n",
    "    config=RunnableConfig(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ë‚´ì¥ ë¯¸ë“¤ì›¨ì–´\n\nLangChainì€ ì¼ë°˜ì ì¸ ì‚¬ìš© ì‚¬ë¡€ë¥¼ ìœ„í•œ ì‚¬ì „ êµ¬ì¶•ëœ ë¯¸ë“¤ì›¨ì–´ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë‚´ì¥ ë¯¸ë“¤ì›¨ì–´ë¥¼ ì‚¬ìš©í•˜ë©´ ë³„ë„ì˜ êµ¬í˜„ ì—†ì´ ìš”ì•½, í˜¸ì¶œ ì œí•œ, í´ë°±, PII ê°ì§€ ë“± ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì‰½ê²Œ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n### ìš”ì•½ (Summarization)\n\nëŒ€í™”ê°€ ê¸¸ì–´ì§€ë©´ í† í° ì œí•œì— ë„ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `SummarizationMiddleware`ëŠ” ëŒ€í™” ê¸°ë¡ì´ íŠ¹ì • í† í° ìˆ˜ë¥¼ ì´ˆê³¼í•  ë•Œ ìë™ìœ¼ë¡œ ìš”ì•½í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ ì°½ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê¸´ ëŒ€í™”ì—ì„œë„ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ìœ ì§€í•˜ë©´ì„œ í† í° ë¹„ìš©ì„ ì ˆê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n**ì í•©í•œ ê²½ìš°:**\n- ì»¨í…ìŠ¤íŠ¸ ì°½ì„ ì´ˆê³¼í•˜ëŠ” ì¥ê¸° ì‹¤í–‰ ëŒ€í™”\n- ê´‘ë²”ìœ„í•œ ê¸°ë¡ì´ ìˆëŠ” ë‹¤ì¤‘ í„´ ëŒ€í™”\n- ì „ì²´ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ë³´ì¡´ì´ ì¤‘ìš”í•œ ì• í”Œë¦¬ì¼€ì´ì…˜\n\nì•„ë˜ ì½”ë“œëŠ” `SummarizationMiddleware`ë¥¼ ì‚¬ìš©í•˜ì—¬ 4000 í† í° ì´ˆê³¼ ì‹œ ìë™ ìš”ì•½ì„ ìˆ˜í–‰í•˜ëŠ” ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=\"openai:gpt-4.1-mini\",\n",
    "            max_tokens_before_summary=4000,  # 4000 í† í°ì—ì„œ ìš”ì•½ íŠ¸ë¦¬ê±°\n",
    "            messages_to_keep=20,  # ìš”ì•½ í›„ ìµœê·¼ 20ê°œ ë©”ì‹œì§€ ìœ ì§€\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarization\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Hi\",\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ëª¨ë¸ í˜¸ì¶œ ì œí•œ (ModelCallLimitMiddleware)\n\nì—ì´ì „íŠ¸ê°€ ë¬´í•œ ë£¨í”„ì— ë¹ ì§€ê±°ë‚˜ ê³¼ë„í•œ API í˜¸ì¶œì„ í•˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ëª¨ë¸ í˜¸ì¶œ ìˆ˜ë¥¼ ì œí•œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `ModelCallLimitMiddleware`ëŠ” ìŠ¤ë ˆë“œ(ì „ì²´ ëŒ€í™”) ë‹¨ìœ„ì™€ ì‹¤í–‰(ë‹¨ì¼ í˜¸ì¶œ) ë‹¨ìœ„ë¡œ ëª¨ë¸ í˜¸ì¶œ íšŸìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤. ì œí•œì— ë„ë‹¬í•˜ë©´ ì—ì´ì „íŠ¸ë¥¼ ì¢…ë£Œí•˜ê±°ë‚˜ ì˜ˆì™¸ë¥¼ ë°œìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n**ì í•©í•œ ê²½ìš°:**\n- ì—ì´ì „íŠ¸ê°€ ë„ˆë¬´ ë§ì€ API í˜¸ì¶œì„ í•˜ëŠ” ê²ƒì„ ë°©ì§€\n- í”„ë¡œë•ì…˜ ë°°í¬ì— ëŒ€í•œ ë¹„ìš© ì œì–´ ì‹œí–‰\n- íŠ¹ì • í˜¸ì¶œ ì˜ˆì‚° ë‚´ì—ì„œ ì—ì´ì „íŠ¸ ë™ì‘ í…ŒìŠ¤íŠ¸\n\nì•„ë˜ ì½”ë“œëŠ” ìŠ¤ë ˆë“œë‹¹ ìµœëŒ€ 3íšŒ, ì‹¤í–‰ë‹¹ ìµœëŒ€ 2íšŒë¡œ ëª¨ë¸ í˜¸ì¶œì„ ì œí•œí•˜ëŠ” ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import ModelCallLimitMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    middleware=[\n",
    "        ModelCallLimitMiddleware(\n",
    "            thread_limit=3,  # ìŠ¤ë ˆë“œë‹¹ ìµœëŒ€ 10íšŒ í˜¸ì¶œ (ì‹¤í–‰ ì „ë°˜)\n",
    "            run_limit=2,  # ì‹¤í–‰ë‹¹ ìµœëŒ€ 5íšŒ í˜¸ì¶œ (ë‹¨ì¼ í˜¸ì¶œ)\n",
    "            exit_behavior=\"end\",  # ë˜ëŠ” \"error\"ë¡œ ì˜ˆì™¸ ë°œìƒ\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ë„êµ¬ í˜¸ì¶œ ì œí•œ (Tool Call Limit)\n\níŠ¹ì • ë„êµ¬ ë˜ëŠ” ëª¨ë“  ë„êµ¬ì— ëŒ€í•œ í˜¸ì¶œ ìˆ˜ë¥¼ ì œí•œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `ToolCallLimitMiddleware`ëŠ” ë¹„ìš©ì´ ë§ì´ ë“œëŠ” ì™¸ë¶€ API í˜¸ì¶œì´ë‚˜ ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ì— ëŒ€í•œ ì†ë„ ì œí•œì„ êµ¬í˜„í•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤. ì „ì—­ì ìœ¼ë¡œ ëª¨ë“  ë„êµ¬ì— ì ìš©í•˜ê±°ë‚˜, íŠ¹ì • ë„êµ¬ì—ë§Œ ì„ íƒì ìœ¼ë¡œ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n**ì í•©í•œ ê²½ìš°:**\n- ë¹„ìš©ì´ ë§ì´ ë“œëŠ” ì™¸ë¶€ APIì— ëŒ€í•œ ê³¼ë„í•œ í˜¸ì¶œ ë°©ì§€\n- ì›¹ ê²€ìƒ‰ ë˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ì œí•œ\n- íŠ¹ì • ë„êµ¬ ì‚¬ìš©ì— ëŒ€í•œ ì†ë„ ì œí•œ ì‹œí–‰\n\nì•„ë˜ ì½”ë“œëŠ” ì „ì—­ ë„êµ¬ í˜¸ì¶œ ì œí•œê³¼ íŠ¹ì • ë„êµ¬(`get_weather`)ì— ëŒ€í•œ ê°œë³„ ì œí•œì„ ì„¤ì •í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import ToolCallLimitMiddleware\n",
    "\n",
    "# ëª¨ë“  ë„êµ¬ í˜¸ì¶œ ì œí•œ\n",
    "global_limiter = ToolCallLimitMiddleware(thread_limit=20, run_limit=10)\n",
    "\n",
    "# íŠ¹ì • ë„êµ¬ ì œí•œ\n",
    "weather_limiter = ToolCallLimitMiddleware(\n",
    "    tool_name=\"get_weather\",\n",
    "    thread_limit=5,\n",
    "    run_limit=3,\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    middleware=[global_limiter, weather_limiter],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ëª¨ë¸ í´ë°± (Model Fallback)\n\nê¸°ë³¸ ëª¨ë¸ì´ ì‹¤íŒ¨í•  ë•Œ ëŒ€ì²´ ëª¨ë¸ë¡œ ìë™ í´ë°±í•˜ëŠ” ë³µì›ë ¥ ìˆëŠ” ì—ì´ì „íŠ¸ë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `ModelFallbackMiddleware`ëŠ” ëª¨ë¸ ì œê³µìì˜ ì¤‘ë‹¨ì´ë‚˜ ì˜¤ë¥˜ ë°œìƒ ì‹œ ë‹¤ë¥¸ ëª¨ë¸ë¡œ ìë™ ì „í™˜í•˜ì—¬ ì„œë¹„ìŠ¤ ì—°ì†ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤. OpenAI, Anthropic ë“± ì—¬ëŸ¬ ì œê³µìì— ê±¸ì¹œ ì¤‘ë³µì„±ì„ êµ¬í˜„í•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤.\n\n**ì í•©í•œ ê²½ìš°:**\n- ëª¨ë¸ ì¤‘ë‹¨ì„ ì²˜ë¦¬í•˜ëŠ” ë³µì›ë ¥ ìˆëŠ” ì—ì´ì „íŠ¸ êµ¬ì¶•\n- ë” ì €ë ´í•œ ëª¨ë¸ë¡œ í´ë°±í•˜ì—¬ ë¹„ìš© ìµœì í™”\n- OpenAI, Anthropic ë“±ì— ê±¸ì¹œ ì œê³µì ì¤‘ë³µì„±\n\nì•„ë˜ ì½”ë“œëŠ” ê¸°ë³¸ ëª¨ë¸(`gpt-4.1`) ì‹¤íŒ¨ ì‹œ ìˆœì°¨ì ìœ¼ë¡œ ëŒ€ì²´ ëª¨ë¸ë¡œ í´ë°±í•˜ëŠ” ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import ModelFallbackMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-4.1\",  # ê¸°ë³¸ ëª¨ë¸\n",
    "    tools=[get_weather],\n",
    "    middleware=[\n",
    "        ModelFallbackMiddleware(\n",
    "            \"openai:gpt-4.1-mini\",  # ì˜¤ë¥˜ ì‹œ ë¨¼ì € ì‹œë„\n",
    "            \"anthropic:claude-4-5-haiku\",  # ê·¸ ë‹¤ìŒ ì´ê²ƒ\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### PII ê°ì§€ (PII Detection)\n\nëŒ€í™”ì—ì„œ ê°œì¸ ì‹ë³„ ì •ë³´(PII)ë¥¼ ê°ì§€í•˜ê³  ì²˜ë¦¬í•˜ëŠ” ê²ƒì€ ê·œì • ì¤€ìˆ˜ì™€ ë³´ì•ˆì— í•„ìˆ˜ì ì…ë‹ˆë‹¤. `PIIMiddleware`ëŠ” ì´ë©”ì¼, ì‹ ìš©ì¹´ë“œ, ì „í™”ë²ˆí˜¸ ë“± ë‹¤ì–‘í•œ PII ìœ í˜•ì„ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³ , ìˆ˜ì •(redact), ë§ˆìŠ¤í‚¹(mask), ì°¨ë‹¨(block) ë“± ë‹¤ì–‘í•œ ì „ëµìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n**ì í•©í•œ ê²½ìš°:**\n- ê·œì • ì¤€ìˆ˜ ìš”êµ¬ ì‚¬í•­ì´ ìˆëŠ” ì˜ë£Œ ë° ê¸ˆìœµ ì• í”Œë¦¬ì¼€ì´ì…˜\n- ë¡œê·¸ë¥¼ ì •í™”í•´ì•¼ í•˜ëŠ” ê³ ê° ì„œë¹„ìŠ¤ ì—ì´ì „íŠ¸\n- ë¯¼ê°í•œ ì‚¬ìš©ì ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ëª¨ë“  ì• í”Œë¦¬ì¼€ì´ì…˜\n\nì•„ë˜ ì½”ë“œëŠ” ì´ë©”ì¼ ìˆ˜ì •, ì‹ ìš©ì¹´ë“œ ë§ˆìŠ¤í‚¹, ì»¤ìŠ¤í…€ API í‚¤ íŒ¨í„´ íƒì§€ë¥¼ ì ìš©í•˜ëŠ” ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import PIIMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    middleware=[\n",
    "        # ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì´ë©”ì¼ ìˆ˜ì •\n",
    "        PIIMiddleware(\"email\", strategy=\"redact\", apply_to_input=True),\n",
    "        # ì‹ ìš©ì¹´ë“œ ë§ˆìŠ¤í‚¹ (ë§ˆì§€ë§‰ 4ìë¦¬ í‘œì‹œ)\n",
    "        PIIMiddleware(\"credit_card\", strategy=\"mask\", apply_to_input=True),\n",
    "        # ì •ê·œì‹ì„ ì‚¬ìš©í•œ ì»¤ìŠ¤í…€ PII ìœ í˜•\n",
    "        PIIMiddleware(\n",
    "            \"api_key\",\n",
    "            detector=r\"sk-[a-zA-Z0-9]{32}\",\n",
    "            strategy=\"mask\",  # ê°ì§€ ì‹œ ì˜¤ë¥˜ ë°œìƒ\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# PII ê°ì§€ í…ŒìŠ¤íŠ¸\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"My credit card number is 1234-5678-9012-3456, and my API key is sk-12345678901234567890123456789012, My email is teddy@example.com. Can you help me?\",\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ë„êµ¬ ì¬ì‹œë„ (Tool Retry)\n\nì™¸ë¶€ API í˜¸ì¶œ ì‹œ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ë‚˜ ì¼ì‹œì ì¸ ì‹¤íŒ¨ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `ToolRetryMiddleware`ëŠ” êµ¬ì„± ê°€ëŠ¥í•œ ì§€ìˆ˜ ë°±ì˜¤í”„(exponential backoff)ë¡œ ì‹¤íŒ¨í•œ ë„êµ¬ í˜¸ì¶œì„ ìë™ìœ¼ë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì¼ì‹œì ì¸ ì˜¤ë¥˜ë¥¼ ìš°ì•„í•˜ê²Œ ì²˜ë¦¬í•˜ëŠ” ë³µì›ë ¥ ìˆëŠ” ì—ì´ì „íŠ¸ë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n**ì í•©í•œ ê²½ìš°:**\n- ì™¸ë¶€ API í˜¸ì¶œì˜ ì¼ì‹œì ì¸ ì‹¤íŒ¨ ì²˜ë¦¬\n- ë„¤íŠ¸ì›Œí¬ ì¢…ì† ë„êµ¬ì˜ ì•ˆì •ì„± í–¥ìƒ\n- ì¼ì‹œì ì¸ ì˜¤ë¥˜ë¥¼ ìš°ì•„í•˜ê²Œ ì²˜ë¦¬í•˜ëŠ” ë³µì›ë ¥ ìˆëŠ” ì—ì´ì „íŠ¸ êµ¬ì¶•\n\nì•„ë˜ ì½”ë“œëŠ” ìµœëŒ€ 3íšŒ ì¬ì‹œë„, ì§€ìˆ˜ ë°±ì˜¤í”„, ë¬´ì‘ìœ„ ì§€í„°ë¥¼ ì ìš©í•˜ëŠ” ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import ToolRetryMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    middleware=[\n",
    "        ToolRetryMiddleware(\n",
    "            max_retries=3,  # ìµœëŒ€ 3íšŒ ì¬ì‹œë„\n",
    "            backoff_factor=2.0,  # ì§€ìˆ˜ ë°±ì˜¤í”„ ìŠ¹ìˆ˜\n",
    "            initial_delay=1.0,  # 1ì´ˆ ì§€ì—°ìœ¼ë¡œ ì‹œì‘\n",
    "            max_delay=60.0,  # ì§€ì—°ì„ 60ì´ˆë¡œ ì œí•œ\n",
    "            jitter=True,  # ë¬´ì‘ìœ„ ì§€í„° ì¶”ê°€\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ì»¤ìŠ¤í…€ ë¯¸ë“¤ì›¨ì–´\n\në‚´ì¥ ë¯¸ë“¤ì›¨ì–´ ì™¸ì—ë„ ì—ì´ì „íŠ¸ ì‹¤í–‰ íë¦„ì˜ íŠ¹ì • ì§€ì ì—ì„œ ì‹¤í–‰ë˜ëŠ” ì»¤ìŠ¤í…€ ë¯¸ë“¤ì›¨ì–´ë¥¼ ì§ì ‘ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì»¤ìŠ¤í…€ ë¯¸ë“¤ì›¨ì–´ë¥¼ í†µí•´ ë¡œê¹…, ê²€ì¦, ë³€í™˜ ë“± ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\në¯¸ë“¤ì›¨ì–´ë¥¼ ë§Œë“œëŠ” ë‘ ê°€ì§€ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤:\n\n1. **ë°ì½”ë ˆì´í„° ê¸°ë°˜** - ë‹¨ì¼ í›„í¬ ë¯¸ë“¤ì›¨ì–´ì— ë¹ ë¥´ê³  ê°„ë‹¨\n2. **í´ë˜ìŠ¤ ê¸°ë°˜** - ì—¬ëŸ¬ í›„í¬ê°€ ìˆëŠ” ë³µì¡í•œ ë¯¸ë“¤ì›¨ì–´ì— ë” ê°•ë ¥"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ë°ì½”ë ˆì´í„° ê¸°ë°˜ ë¯¸ë“¤ì›¨ì–´\n\në‹¨ì¼ í›„í¬ë§Œ í•„ìš”í•œ ê°„ë‹¨í•œ ë¯¸ë“¤ì›¨ì–´ì˜ ê²½ìš° ë°ì½”ë ˆì´í„°ê°€ ê°€ì¥ ë¹ ë¥´ê³  ì§ê´€ì ì¸ ë°©ë²•ì…ë‹ˆë‹¤. `@before_agent`, `@before_model`, `@after_model`, `@after_agent`, `@wrap_model_call`, `@wrap_tool_call`, `@dynamic_prompt` ë“± ë‹¤ì–‘í•œ ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê° ë°ì½”ë ˆì´í„°ëŠ” ì—ì´ì „íŠ¸ ì‹¤í–‰ì˜ íŠ¹ì • ë‹¨ê³„ì—ì„œ ë™ì‘í•©ë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” ë‹¤ì–‘í•œ ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ ì‹œì‘ ì „/í›„, ëª¨ë¸ í˜¸ì¶œ ì „/í›„ ë¡œê¹…, ì¶œë ¥ ê²€ì¦, ì¬ì‹œë„ ë¡œì§, ë™ì  í”„ë¡¬í”„íŠ¸ ë“±ì„ êµ¬í˜„í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import (\n",
    "    before_agent,\n",
    "    before_model,\n",
    "    after_model,\n",
    "    after_agent,\n",
    "    wrap_model_call,\n",
    "    wrap_tool_call,\n",
    ")\n",
    "from langchain.agents.middleware import (\n",
    "    AgentState,\n",
    "    ModelRequest,\n",
    "    ModelResponse,\n",
    "    dynamic_prompt,\n",
    ")\n",
    "from langchain.messages import AIMessage\n",
    "from langchain_teddynote.messages import invoke_graph\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any, Callable\n",
    "\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ì‹œì‘ì „\n",
    "@before_agent\n",
    "def log_before_agent(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    print(f\"ì—ì´ì „íŠ¸ë¥¼ ì‹œì‘í•˜ê¸° ì „ì— ë©”ì‹œì§€ {len(state['messages'])}ê°œê°€ ìˆìŠµë‹ˆë‹¤\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# ëª¨ë¸ í˜¸ì¶œ ì „\n",
    "@before_model\n",
    "def log_before_model(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    print(f\"ëª¨ë¸ì„ í˜¸ì¶œí•˜ê¸° ì „ì— ë©”ì‹œì§€ {len(state['messages'])}ê°œê°€ ìˆìŠµë‹ˆë‹¤\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# ëª¨ë¸ í˜¸ì¶œ í›„\n",
    "@after_model\n",
    "def validate_output(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if \"BLOCKED\" in last_message.content:\n",
    "        return {\n",
    "            \"messages\": [AIMessage(\"I cannot respond to that request.\")],\n",
    "        }\n",
    "    return None\n",
    "\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ì¢…ë£Œ í›„\n",
    "@after_agent\n",
    "def log_after_agent(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    print(f\"ì—ì´ì „íŠ¸ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ë©”ì‹œì§€ ìˆ˜: {len(state['messages'])}ê°œ\")\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# wrap_model_call ì¬ì‹œë„ ë¡œì§\n",
    "@wrap_model_call\n",
    "def retry_model(\n",
    "    request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse],\n",
    ") -> ModelResponse:\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            return handler(request)\n",
    "        except Exception as e:\n",
    "            if attempt == 2:\n",
    "                raise\n",
    "            print(f\"ì˜¤ë¥˜ ë°œìƒìœ¼ë¡œ {attempt + 1}/3 ë²ˆì§¸ ì¬ì‹œë„í•©ë‹ˆë‹¤: {e}\")\n",
    "\n",
    "\n",
    "# ë™ì  í”„ë¡¬í”„íŠ¸\n",
    "@dynamic_prompt\n",
    "def personalized_prompt(request: ModelRequest) -> str:\n",
    "    user_id = request.runtime.context.get(\"user_id\", \"guest\")\n",
    "    return f\"You are a helpful assistant for user {user_id}. Greeting with user's name. Be concise and friendly.\"\n",
    "\n",
    "\n",
    "# ì—ì´ì „íŠ¸ì—ì„œ ë°ì½”ë ˆì´í„° ì‚¬ìš©\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    middleware=[\n",
    "        log_before_model,\n",
    "        validate_output,\n",
    "        retry_model,\n",
    "        personalized_prompt,\n",
    "        log_before_agent,\n",
    "        log_after_agent,\n",
    "    ],\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "invoke_graph(\n",
    "    agent,\n",
    "    inputs={\"messages\": [{\"role\": \"user\", \"content\": \"ì„œìš¸ ë‚ ì”¨ ì•Œë ¤ì¤˜\"}]},\n",
    "    context={\"user_id\": \"teddy\"},\n",
    "    config=RunnableConfig(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### í´ë˜ìŠ¤ ê¸°ë°˜ ë¯¸ë“¤ì›¨ì–´\n\nì—¬ëŸ¬ í›„í¬ë¥¼ í•¨ê»˜ ì‚¬ìš©í•˜ê±°ë‚˜ ìƒíƒœë¥¼ ìœ ì§€í•´ì•¼ í•˜ëŠ” ë³µì¡í•œ ë¯¸ë“¤ì›¨ì–´ì˜ ê²½ìš° `AgentMiddleware` í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ êµ¬í˜„í•©ë‹ˆë‹¤. í´ë˜ìŠ¤ ê¸°ë°˜ ì ‘ê·¼ ë°©ì‹ì€ ê´€ë ¨ ë¡œì§ì„ í•˜ë‚˜ì˜ í´ë˜ìŠ¤ì— ìº¡ìŠí™”í•˜ì—¬ ì½”ë“œì˜ êµ¬ì¡°í™”ì™€ ì¬ì‚¬ìš©ì„±ì„ ë†’ì…ë‹ˆë‹¤.\n\n**ë…¸ë“œ ìŠ¤íƒ€ì¼ í›„í¬**ëŠ” ì‹¤í–‰ íë¦„ì˜ íŠ¹ì • ì§€ì ì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤:\n- `before_agent` - ì—ì´ì „íŠ¸ ì‹œì‘ ì „ (í˜¸ì¶œë‹¹ í•œ ë²ˆ)\n- `before_model` - ê° ëª¨ë¸ í˜¸ì¶œ ì „\n- `after_model` - ê° ëª¨ë¸ ì‘ë‹µ í›„\n- `after_agent` - ì—ì´ì „íŠ¸ ì™„ë£Œ í›„ (í˜¸ì¶œë‹¹ ìµœëŒ€ í•œ ë²ˆ)\n\nì•„ë˜ ì½”ë“œëŠ” ëª¨ë¸ í˜¸ì¶œ ì „/í›„ì— ë©”ì‹œì§€ ìˆ˜ë¥¼ ë¡œê¹…í•˜ëŠ” `LoggingMiddleware` í´ë˜ìŠ¤ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import AgentMiddleware, AgentState\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "# ë¡œê¹… ë¯¸ë“¤ì›¨ì–´\n",
    "class LoggingMiddleware(AgentMiddleware):\n",
    "    def before_model(\n",
    "        self, state: AgentState, runtime: Runtime\n",
    "    ) -> dict[str, Any] | None:\n",
    "        print(f\"About to call model with {len(state['messages'])} messages\")\n",
    "        return None\n",
    "\n",
    "    def after_model(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "        print(f\"Model returned: {state['messages'][-1].content[:50]}...\")\n",
    "        return None\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    middleware=[LoggingMiddleware()],\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's the weather in Tokyo?\"}]}\n",
    ")\n",
    "print(\"\\nFinal:\", result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ëŒ€í™” ê¸¸ì´ ì œí•œ ì˜ˆì œ\n\ní´ë˜ìŠ¤ ê¸°ë°˜ ë¯¸ë“¤ì›¨ì–´ì˜ ì‹¤ìš©ì ì¸ ì˜ˆì œë¡œ, ëŒ€í™” ë©”ì‹œì§€ ìˆ˜ê°€ íŠ¹ì • ì„ê³„ê°’ì„ ì´ˆê³¼í•˜ë©´ ëŒ€í™”ë¥¼ ì¢…ë£Œí•˜ëŠ” ë¯¸ë“¤ì›¨ì–´ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ë‚˜ ë¹„ìš© ì œì–´ì— ìœ ìš©í•©ë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” `before_model` í›„í¬ì—ì„œ ë©”ì‹œì§€ ìˆ˜ë¥¼ í™•ì¸í•˜ê³ , ì œí•œì„ ì´ˆê³¼í•˜ë©´ ì¢…ë£Œ ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•˜ëŠ” `MessageLimitMiddleware` í´ë˜ìŠ¤ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import AgentMiddleware, AgentState\n",
    "from langchain.messages import AIMessage\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "class MessageLimitMiddleware(AgentMiddleware):\n",
    "    def __init__(self, max_messages: int = 50):\n",
    "        super().__init__()\n",
    "        self.max_messages = max_messages\n",
    "\n",
    "    def before_model(\n",
    "        self, state: AgentState, runtime: Runtime\n",
    "    ) -> dict[str, Any] | None:\n",
    "        if len(state[\"messages\"]) >= self.max_messages:\n",
    "            return {\n",
    "                \"messages\": [AIMessage(\"Conversation limit reached.\")],\n",
    "            }\n",
    "        return None\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    middleware=[MessageLimitMiddleware(max_messages=10)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ë© ìŠ¤íƒ€ì¼ í›„í¬\n\në© ìŠ¤íƒ€ì¼ í›„í¬(`wrap_model_call`, `wrap_tool_call`)ëŠ” ì‹¤í–‰ì„ ê°€ë¡œì±„ê³  í•¸ë“¤ëŸ¬ê°€ í˜¸ì¶œë˜ëŠ” ì‹œê¸°ë¥¼ ì™„ì „íˆ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•¸ë“¤ëŸ¬ë¥¼ 0ë²ˆ(ë‹¨ë½/short-circuit), 1ë²ˆ(ì •ìƒ íë¦„), ë˜ëŠ” ì—¬ëŸ¬ ë²ˆ(ì¬ì‹œë„ ë¡œì§) í˜¸ì¶œí• ì§€ ê²°ì •í•  ìˆ˜ ìˆì–´ ì¬ì‹œë„, ìºì‹±, ì¡°ê±´ë¶€ ì‹¤í–‰ ë“± ê³ ê¸‰ íŒ¨í„´ì„ êµ¬í˜„í•˜ëŠ” ë° ì í•©í•©ë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” `wrap_model_call` í›„í¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ìµœëŒ€ 3íšŒê¹Œì§€ ì¬ì‹œë„í•˜ëŠ” `RetryMiddleware` í´ë˜ìŠ¤ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import AgentMiddleware, ModelRequest, ModelResponse\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class RetryMiddleware(AgentMiddleware):\n",
    "    def __init__(self, max_retries: int = 3):\n",
    "        super().__init__()\n",
    "        self.max_retries = max_retries\n",
    "\n",
    "    def wrap_model_call(\n",
    "        self,\n",
    "        request: ModelRequest,\n",
    "        handler: Callable[[ModelRequest], ModelResponse],\n",
    "    ) -> ModelResponse:\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                return handler(request)\n",
    "            except Exception as e:\n",
    "                if attempt == self.max_retries - 1:\n",
    "                    raise\n",
    "                print(f\"Retry {attempt + 1}/{self.max_retries} after error: {e}\")\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    middleware=[RetryMiddleware(max_retries=3)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ë™ì  ëª¨ë¸ ì„ íƒ ì˜ˆì œ\n\në© ìŠ¤íƒ€ì¼ í›„í¬ì˜ ë˜ ë‹¤ë¥¸ í™œìš© ì˜ˆì œë¡œ, ëŒ€í™” ê¸¸ì´ë‚˜ ìƒí™©ì— ë”°ë¼ ë‹¤ë¥¸ ëª¨ë¸ì„ ì„ íƒí•˜ëŠ” ë¯¸ë“¤ì›¨ì–´ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì§§ì€ ëŒ€í™”ì—ëŠ” ê°€ë²¼ìš´ ëª¨ë¸ì„, ê¸´ ëŒ€í™”ì—ëŠ” ë” í° ì»¨í…ìŠ¤íŠ¸ ì°½ì„ ê°€ì§„ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¹„ìš©ê³¼ ì„±ëŠ¥ì„ ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” ë©”ì‹œì§€ ìˆ˜ì— ë”°ë¼ `gpt-4.1` ë˜ëŠ” `gpt-4.1-nano` ëª¨ë¸ì„ ë™ì ìœ¼ë¡œ ì„ íƒí•˜ëŠ” `DynamicModelMiddleware` í´ë˜ìŠ¤ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import AgentMiddleware, ModelRequest, ModelResponse\n",
    "from langchain.chat_models import init_chat_model\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class DynamicModelMiddleware(AgentMiddleware):\n",
    "    def wrap_model_call(\n",
    "        self,\n",
    "        request: ModelRequest,\n",
    "        handler: Callable[[ModelRequest], ModelResponse],\n",
    "    ) -> ModelResponse:\n",
    "        # ëŒ€í™” ê¸¸ì´ì— ë”°ë¼ ë‹¤ë¥¸ ëª¨ë¸ ì‚¬ìš©\n",
    "        if len(request.messages) > 10:\n",
    "            request.model = init_chat_model(\"openai:gpt-4.1\")\n",
    "            print(\"Using gpt-4.1 for long conversation\")\n",
    "        else:\n",
    "            request.model = init_chat_model(\"openai:gpt-4.1-nano\")\n",
    "            print(\"Using gpt-4.1-mini for short conversation\")\n",
    "\n",
    "        return handler(request)\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    middleware=[DynamicModelMiddleware()],\n",
    ")\n",
    "\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]})\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ì‹¤í–‰ ìˆœì„œ\n\nì—¬ëŸ¬ ë¯¸ë“¤ì›¨ì–´ë¥¼ ì‚¬ìš©í•  ë•Œ ì‹¤í–‰ ìˆœì„œë¥¼ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ë¯¸ë“¤ì›¨ì–´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ëœ ìˆœì„œì— ë”°ë¼ ì‹¤í–‰ ìˆœì„œê°€ ê²°ì •ë˜ë©°, í›„í¬ íƒ€ì…ì— ë”°ë¼ ë‹¤ë¥¸ ê·œì¹™ì´ ì ìš©ë©ë‹ˆë‹¤.\n\n**ì£¼ìš” ê·œì¹™:**\n- `before_*` í›„í¬: ì²« ë²ˆì§¸ë¶€í„° ë§ˆì§€ë§‰ê¹Œì§€ ìˆœì°¨ ì‹¤í–‰\n- `after_*` í›„í¬: ë§ˆì§€ë§‰ë¶€í„° ì²« ë²ˆì§¸ê¹Œì§€ ì—­ìˆœ ì‹¤í–‰\n- `wrap_*` í›„í¬: ì¤‘ì²©ë¨ (ì²« ë²ˆì§¸ ë¯¸ë“¤ì›¨ì–´ê°€ ê°€ì¥ ë°”ê¹¥ìª½ì—ì„œ ë‹¤ë¥¸ ëª¨ë“  ê²ƒì„ ë˜í•‘)\n\nì•„ë˜ ì½”ë“œëŠ” ë‘ ê°œì˜ ë¯¸ë“¤ì›¨ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰ ìˆœì„œë¥¼ í™•ì¸í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import AgentMiddleware\n",
    "\n",
    "\n",
    "class Middleware1(AgentMiddleware):\n",
    "    def before_model(self, state, runtime):\n",
    "        print(\"1: before_model\")\n",
    "        return None\n",
    "\n",
    "    def after_model(self, state, runtime):\n",
    "        print(\"1: after_model\")\n",
    "        return None\n",
    "\n",
    "\n",
    "class Middleware2(AgentMiddleware):\n",
    "    def before_model(self, state, runtime):\n",
    "        print(\"2: before_model\")\n",
    "        return None\n",
    "\n",
    "    def after_model(self, state, runtime):\n",
    "        print(\"2: after_model\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ì‹¤í–‰ ìˆœì„œ í™•ì¸\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    middleware=[Middleware1(), Middleware2()],\n",
    ")\n",
    "\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]})\n",
    "\n",
    "# ì¶œë ¥:\n",
    "# 1: before_model\n",
    "# 2: before_model\n",
    "# (ëª¨ë¸ í˜¸ì¶œ)\n",
    "# 2: after_model\n",
    "# 1: after_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}