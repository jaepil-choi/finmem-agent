{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ë„êµ¬ (Tools)\n\në„êµ¬ëŠ” ì—ì´ì „íŠ¸ê°€ ì™¸ë¶€ ì‹œìŠ¤í…œê³¼ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” í•µì‹¬ êµ¬ì„± ìš”ì†Œì…ë‹ˆë‹¤. API í˜¸ì¶œ, ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬, íŒŒì¼ ì‹œìŠ¤í…œ ì ‘ê·¼ ë“± ë‹¤ì–‘í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìœ¼ë©°, ì˜ ì •ì˜ëœ ì…ë ¥ê³¼ ì¶œë ¥ì„ í†µí•´ ëª¨ë¸ì˜ ê¸°ëŠ¥ì„ í™•ì¥í•©ë‹ˆë‹¤.\n\në„êµ¬ëŠ” í˜¸ì¶œ ê°€ëŠ¥í•œ í•¨ìˆ˜ì™€ ì…ë ¥ ìŠ¤í‚¤ë§ˆë¥¼ ìº¡ìŠí™”í•©ë‹ˆë‹¤. í˜¸í™˜ ê°€ëŠ¥í•œ ì±„íŒ… ëª¨ë¸ì— ì „ë‹¬ë˜ë©´, ëª¨ë¸ì€ ë„êµ¬ë¥¼ í˜¸ì¶œí• ì§€ ì—¬ë¶€ì™€ ì–´ë–¤ ì¸ìˆ˜ë¡œ í˜¸ì¶œí• ì§€ë¥¼ ììœ¨ì ìœ¼ë¡œ ê²°ì •í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì—ì´ì „íŠ¸ëŠ” ë³µì¡í•œ ì‘ì—…ì„ ë‹¨ê³„ë³„ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n> ì°¸ê³  ë¬¸ì„œ: [LangChain Tools](https://docs.langchain.com/oss/python/langchain/tools.md)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## í™˜ê²½ ì„¤ì •\n\në„êµ¬ íŠœí† ë¦¬ì–¼ì„ ì‹œì‘í•˜ê¸° ì „ì— í•„ìš”í•œ í™˜ê²½ì„ ì„¤ì •í•©ë‹ˆë‹¤. `dotenv`ë¥¼ ì‚¬ìš©í•˜ì—¬ API í‚¤ë¥¼ ë¡œë“œí•˜ê³ , `langchain_teddynote`ì˜ ë¡œê¹… ê¸°ëŠ¥ì„ í™œì„±í™”í•˜ì—¬ LangSmithì—ì„œ ë„êµ¬ í˜¸ì¶œ ê³¼ì •ì„ ì¶”ì í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•˜ê³  LangSmith í”„ë¡œì íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "LangChain-V1-Tutorial\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv(override=True)\n",
    "# ì¶”ì ì„ ìœ„í•œ í”„ë¡œì íŠ¸ ì´ë¦„ ì„¤ì •\n",
    "logging.langsmith(\"LangChain-V1-Tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ë„êµ¬ ìƒì„±\n\n### ê¸°ë³¸ ë„êµ¬ ì •ì˜\n\në„êµ¬ë¥¼ ìƒì„±í•˜ëŠ” ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ì€ `@tool` ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë°ì½”ë ˆì´í„°ê°€ ì ìš©ëœ í•¨ìˆ˜ëŠ” ìë™ìœ¼ë¡œ ë„êµ¬ë¡œ ë³€í™˜ë˜ë©°, í•¨ìˆ˜ì˜ docstringì´ ë„êµ¬ ì„¤ëª…ì´ ë©ë‹ˆë‹¤.\n\n**ë„êµ¬ ì •ì˜ ê·œì¹™:**\n1. `@tool` ë°ì½”ë ˆì´í„°ë¥¼ í•¨ìˆ˜ì— ì ìš©í•©ë‹ˆë‹¤\n2. ë„êµ¬ ì´ë¦„ì€ í•¨ìˆ˜ ì´ë¦„ì—ì„œ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤\n3. ë„êµ¬ ì„¤ëª…ì€ í•¨ìˆ˜ì˜ docstringì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤\n4. ì…ë ¥ ìŠ¤í‚¤ë§ˆëŠ” í•¨ìˆ˜ì˜ ë§¤ê°œë³€ìˆ˜ì™€ íƒ€ì… íŒíŠ¸ì—ì„œ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤\n\nì•„ë˜ ì½”ë“œëŠ” ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ë„êµ¬ë¥¼ ì •ì˜í•˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool name: search_database\n",
      "Tool description: Search the customer database for records matching the query.\n",
      "\n",
      "    Args:\n",
      "        query: Search terms to look for\n",
      "        limit: Maximum number of results to return\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_database(query: str, limit: int = 10) -> str:\n",
    "    \"\"\"Search the customer database for records matching the query.\n",
    "\n",
    "    Args:\n",
    "        query: Search terms to look for\n",
    "        limit: Maximum number of results to return\n",
    "    \"\"\"\n",
    "    return f\"Found {limit} results for '{query}'\"\n",
    "\n",
    "\n",
    "# ë„êµ¬ ì •ë³´ í™•ì¸\n",
    "print(f\"Tool name: {search_database.name}\")\n",
    "print(f\"Tool description: {search_database.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### íƒ€ì… íŒíŠ¸ì˜ ì¤‘ìš”ì„±\n\níƒ€ì… íŒíŠ¸ëŠ” ë„êµ¬ì˜ ì…ë ¥ ìŠ¤í‚¤ë§ˆë¥¼ ì •ì˜í•˜ë¯€ë¡œ í•„ìˆ˜ì…ë‹ˆë‹¤. ëª¨ë¸ì€ íƒ€ì… íŒíŠ¸ë¥¼ í†µí•´ ê° ë§¤ê°œë³€ìˆ˜ì˜ íƒ€ì…ì„ ì´í•´í•˜ê³  ì˜¬ë°”ë¥¸ ê°’ì„ ì „ë‹¬í•©ë‹ˆë‹¤. docstringì€ ëª¨ë¸ì´ ë„êµ¬ì˜ ëª©ì ì„ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë˜ë¯€ë¡œ ì •ë³´ê°€ í’ë¶€í•˜ê³  ê°„ê²°í•´ì•¼ í•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ì»¤ìŠ¤í…€ ë„êµ¬ ì´ë¦„\n\nê¸°ë³¸ì ìœ¼ë¡œ ë„êµ¬ ì´ë¦„ì€ í•¨ìˆ˜ ì´ë¦„ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤. ë” ì„¤ëª…ì ì¸ ì´ë¦„ì´ í•„ìš”í•œ ê²½ìš° `@tool(\"ì»¤ìŠ¤í…€_ì´ë¦„\")` í˜•ì‹ìœ¼ë¡œ ì¬ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„êµ¬ ì´ë¦„ì€ ëª¨ë¸ì´ ì–´ë–¤ ë„êµ¬ë¥¼ í˜¸ì¶œí• ì§€ ê²°ì •í•˜ëŠ” ë° ì‚¬ìš©ë˜ë¯€ë¡œ ëª…í™•í•˜ê³  ì§ê´€ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” ì»¤ìŠ¤í…€ ë„êµ¬ ì´ë¦„ì„ ì„¤ì •í•˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool name: web_search\n"
     ]
    }
   ],
   "source": [
    "@tool(\"web_search\")  # ì»¤ìŠ¤í…€ ì´ë¦„\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search the web for information.\"\"\"\n",
    "    return f\"Results for: {query}\"\n",
    "\n",
    "\n",
    "# ë„êµ¬ ì´ë¦„ í™•ì¸\n",
    "print(f\"Tool name: {search.name}\")  # web_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ì»¤ìŠ¤í…€ ë„êµ¬ ì„¤ëª…\n\në” ëª…í™•í•œ ëª¨ë¸ ê°€ì´ë“œë¥¼ ìœ„í•´ ìë™ ìƒì„±ëœ ë„êµ¬ ì„¤ëª…ì„ ì¬ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `description` ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©´ docstringê³¼ ë³„ë„ë¡œ ëª¨ë¸ì—ê²Œ ì „ë‹¬ë˜ëŠ” ì„¤ëª…ì„ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì¢‹ì€ ë„êµ¬ ì„¤ëª…ì€ ë„êµ¬ì˜ ëª©ì , ì‚¬ìš© ì‹œì , ì˜ˆìƒ ê²°ê³¼ë¥¼ ëª…í™•íˆ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” ì»¤ìŠ¤í…€ ë„êµ¬ ì„¤ëª…ì„ ì„¤ì •í•˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool description: Performs arithmetic calculations. Use this for any math problems.\n"
     ]
    }
   ],
   "source": [
    "@tool(\n",
    "    \"calculator\",\n",
    "    description=\"Performs arithmetic calculations. Use this for any math problems.\",\n",
    ")\n",
    "def calc(expression: str) -> str:\n",
    "    \"\"\"Evaluate mathematical expressions.\"\"\"\n",
    "    return str(eval(expression))\n",
    "\n",
    "\n",
    "# ë„êµ¬ ì„¤ëª… í™•ì¸\n",
    "print(f\"Tool description: {calc.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Pydantic ëª¨ë¸ë¡œ ì…ë ¥ ìŠ¤í‚¤ë§ˆ ì •ì˜\n\në³µì¡í•œ ì…ë ¥ ê²€ì¦ì´ í•„ìš”í•œ ê²½ìš° Pydantic ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ëª…í™•í•œ ì…ë ¥ ìŠ¤í‚¤ë§ˆë¥¼ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `args_schema` ë§¤ê°œë³€ìˆ˜ì— Pydantic ëª¨ë¸ì„ ì „ë‹¬í•˜ë©´, ë„êµ¬ í˜¸ì¶œ ì‹œ ìë™ìœ¼ë¡œ ì…ë ¥ ê²€ì¦ì´ ìˆ˜í–‰ë©ë‹ˆë‹¤.\n\nPydantic ëª¨ë¸ì„ ì‚¬ìš©í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì´ì ì´ ìˆìŠµë‹ˆë‹¤:\n- íƒ€ì… ê²€ì¦ ë° ë³€í™˜ ìë™í™”\n- `Literal` íƒ€ì…ì„ í†µí•œ í—ˆìš©ê°’ ì œí•œ\n- `Field`ì˜ descriptionì„ í†µí•œ ìƒì„¸í•œ ë§¤ê°œë³€ìˆ˜ ì„¤ëª…\n\nì•„ë˜ ì½”ë“œëŠ” Pydantic ëª¨ë¸ì„ ì‚¬ìš©í•œ ë‚ ì”¨ ì¡°íšŒ ë„êµ¬ ì˜ˆì‹œì…ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "class WeatherInput(BaseModel):\n",
    "    \"\"\"Input for weather queries.\"\"\"\n",
    "\n",
    "    location: str = Field(description=\"City name or coordinates\")\n",
    "    units: Literal[\"celsius\", \"fahrenheit\"] = Field(\n",
    "        default=\"celsius\", description=\"Temperature unit preference\"\n",
    "    )\n",
    "    include_forecast: bool = Field(default=False, description=\"Include 5-day forecast\")\n",
    "\n",
    "\n",
    "@tool(args_schema=WeatherInput)\n",
    "def get_weather(\n",
    "    location: str, units: str = \"celsius\", include_forecast: bool = False\n",
    ") -> str:\n",
    "    \"\"\"Get current weather and optional forecast.\"\"\"\n",
    "    temp = 22 if units == \"celsius\" else 72\n",
    "    result = f\"í˜„ì¬ {location} ì§€ì—­ì˜ ë‚ ì”¨ëŠ” {temp} {units[0].upper()} ë„\"\n",
    "    if include_forecast:\n",
    "        result += \"\\në‹¤ìŒ 5ì¼ ë‚ ì”¨: ë§‘ìŒ\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ Seoul ì§€ì—­ì˜ ë‚ ì”¨ëŠ” 22 C ë„\n",
      "ë‹¤ìŒ 5ì¼ ë‚ ì”¨: ë§‘ìŒ\n"
     ]
    }
   ],
   "source": [
    "# ë„êµ¬ í…ŒìŠ¤íŠ¸\n",
    "print(\n",
    "    get_weather.invoke(\n",
    "        {\"location\": \"Seoul\", \"units\": \"celsius\", \"include_forecast\": True}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ì…ë ¥ ê²€ì¦ ì˜¤ë¥˜ ì˜ˆì‹œ\n\nì•„ë˜ëŠ” ì…ë ¥ ìŠ¤í‚¤ë§ˆì—ì„œ `Literal[\"celsius\", \"fahrenheit\"]` íƒ€ì…ì„ ì‚¬ìš©í–ˆì§€ë§Œ, ì‹¤ì œ ì…ë ¥ê°’ìœ¼ë¡œ ìœ íš¨í•˜ì§€ ì•Šì€ `celsiuss`ë¥¼ ì…ë ¥í–ˆì„ ë•Œì˜ ì˜¤ë¥˜ ì˜ˆì‹œì…ë‹ˆë‹¤. Pydanticì´ ìë™ìœ¼ë¡œ ì…ë ¥ì„ ê²€ì¦í•˜ê³  ì˜¤ë¥˜ë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for WeatherInput\nunits\n  Input should be 'celsius' or 'fahrenheit' [type=literal_error, input_value='celsiuss', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/literal_error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ë„êµ¬ í…ŒìŠ¤íŠ¸\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mget_weather\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlocation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSeoul\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43munits\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcelsiuss\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_forecast\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/github/00-LangGraph-Tutorial/langgraph-v1-tutorial/.venv/lib/python3.11/site-packages/langchain_core/tools/base.py:591\u001b[39m, in \u001b[36mBaseTool.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    583\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    584\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    585\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    588\u001b[39m     **kwargs: Any,\n\u001b[32m    589\u001b[39m ) -> Any:\n\u001b[32m    590\u001b[39m     tool_input, kwargs = _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m591\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/github/00-LangGraph-Tutorial/langgraph-v1-tutorial/.venv/lib/python3.11/site-packages/langchain_core/tools/base.py:856\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    854\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    855\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m856\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    857\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    858\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/github/00-LangGraph-Tutorial/langgraph-v1-tutorial/.venv/lib/python3.11/site-packages/langchain_core/tools/base.py:818\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    816\u001b[39m child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m    817\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m818\u001b[39m     tool_args, tool_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_to_args_and_kwargs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    819\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\n\u001b[32m    820\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m signature(\u001b[38;5;28mself\u001b[39m._run).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    822\u001b[39m         tool_kwargs |= {\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m: run_manager}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/github/00-LangGraph-Tutorial/langgraph-v1-tutorial/.venv/lib/python3.11/site-packages/langchain_core/tools/base.py:733\u001b[39m, in \u001b[36mBaseTool._to_args_and_kwargs\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    725\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    726\u001b[39m     \u001b[38;5;28mself\u001b[39m.args_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    727\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.args_schema, \u001b[38;5;28mtype\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m    730\u001b[39m ):\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# StructuredTool with no args\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (), {}\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m tool_input = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;66;03m# For backwards compatibility, if run_input is a string,\u001b[39;00m\n\u001b[32m    735\u001b[39m \u001b[38;5;66;03m# pass as a positional argument.\u001b[39;00m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool_input, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/github/00-LangGraph-Tutorial/langgraph-v1-tutorial/.venv/lib/python3.11/site-packages/langchain_core/tools/base.py:657\u001b[39m, in \u001b[36mBaseTool._parse_input\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    655\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    656\u001b[39m             tool_input[k] = tool_call_id\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m     result = \u001b[43minput_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m     result_dict = result.model_dump()\n\u001b[32m    659\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(input_args, BaseModelV1):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/github/00-LangGraph-Tutorial/langgraph-v1-tutorial/.venv/lib/python3.11/site-packages/pydantic/main.py:716\u001b[39m, in \u001b[36mBaseModel.model_validate\u001b[39m\u001b[34m(cls, obj, strict, extra, from_attributes, context, by_alias, by_name)\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m by_alias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    711\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    712\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mAt least one of `by_alias` or `by_name` must be set to True.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    713\u001b[39m         code=\u001b[33m'\u001b[39m\u001b[33mvalidate-by-alias-and-name-false\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    714\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m716\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextra\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m    \u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for WeatherInput\nunits\n  Input should be 'celsius' or 'fahrenheit' [type=literal_error, input_value='celsiuss', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/literal_error"
     ]
    }
   ],
   "source": [
    "# ë„êµ¬ í…ŒìŠ¤íŠ¸\n",
    "print(\n",
    "    get_weather.invoke(\n",
    "        {\"location\": \"Seoul\", \"units\": \"celsiuss\", \"include_forecast\": True}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## ì»¨í…ìŠ¤íŠ¸ ì ‘ê·¼\n\në„êµ¬ëŠ” ì—ì´ì „íŠ¸ ìƒíƒœ, ëŸ°íƒ€ì„ ì»¨í…ìŠ¤íŠ¸ ë° ì¥ê¸° ë©”ëª¨ë¦¬ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆì„ ë•Œ ê°€ì¥ ê°•ë ¥í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë„êµ¬ëŠ” ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ê²°ì •ì„ ë‚´ë¦¬ê³ , ì‘ë‹µì„ ê°œì¸í™”í•˜ë©°, ëŒ€í™” ì „ë°˜ì— ê±¸ì³ ì •ë³´ë¥¼ ìœ ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n`ToolRuntime` ë§¤ê°œë³€ìˆ˜ë¥¼ í†µí•´ ë‹¤ìŒ ëŸ°íƒ€ì„ ì •ë³´ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n\n| ì†ì„± | ì„¤ëª… |\n|:---|:---|\n| **state** | ì‹¤í–‰ì„ í†µí•´ íë¥´ëŠ” ë³€ê²½ ê°€ëŠ¥í•œ ë°ì´í„° (ë©”ì‹œì§€, ì¹´ìš´í„°, ì»¤ìŠ¤í…€ í•„ë“œ) |\n| **context** | ì‚¬ìš©ì ID, ì„¸ì…˜ ì„¸ë¶€ ì •ë³´ ë“± ë¶ˆë³€ êµ¬ì„± ì •ë³´ |\n| **store** | ëŒ€í™” ì „ë°˜ì— ê±¸ì¹œ ì˜êµ¬ ì¥ê¸° ë©”ëª¨ë¦¬ |\n| **stream_writer** | ë„êµ¬ ì‹¤í–‰ ì¤‘ ì»¤ìŠ¤í…€ ì—…ë°ì´íŠ¸ ìŠ¤íŠ¸ë¦¬ë° |\n| **config** | ì‹¤í–‰ì„ ìœ„í•œ RunnableConfig |\n| **tool_call_id** | í˜„ì¬ ë„êµ¬ í˜¸ì¶œì˜ ê³ ìœ  ID |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ToolRuntime ì‚¬ìš©\n\n`ToolRuntime`ì„ ì‚¬ìš©í•˜ë©´ ë‹¨ì¼ ë§¤ê°œë³€ìˆ˜ë¡œ ëª¨ë“  ëŸ°íƒ€ì„ ì •ë³´ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„êµ¬ ì‹œê·¸ë‹ˆì²˜ì— `runtime: ToolRuntime`ì„ ì¶”ê°€í•˜ë©´ LLMì—ëŠ” ë…¸ì¶œë˜ì§€ ì•Šê³  ìë™ìœ¼ë¡œ ì£¼ì…ë©ë‹ˆë‹¤.\n\n`runtime.state`ë¥¼ í†µí•´ í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœì— ì ‘ê·¼í•˜ê³ , `runtime.context`ë¥¼ í†µí•´ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ì— ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” ToolRuntimeì„ ì‚¬ìš©í•˜ì—¬ ìƒíƒœì™€ ì»¨í…ìŠ¤íŠ¸ì— ì ‘ê·¼í•˜ëŠ” ë„êµ¬ ì˜ˆì‹œì…ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_user_preference (call_P2lUJ30JDa0ognrMVgsHabE4)\n",
      " Call ID: call_P2lUJ30JDa0ognrMVgsHabE4\n",
      "  Args:\n",
      "    preference_name: food\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mtools\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_user_preference\n",
      "\n",
      "pizza\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teddy/Dev/github/00-LangGraph-Tutorial/langgraph-v1-tutorial/.venv/lib/python3.11/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='context', input_value=CustomContext(user_preferences={'food': 'pizza'}), input_type=CustomContext])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ë‹¹ì‹ ì´ ì¢‹ì•„í•˜ëŠ” ìŒì‹ì€ í”¼ìì…ë‹ˆë‹¤. ë‹¤ë¥¸ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal, Optional, Dict, Any, List, Annotated, TypedDict\n",
    "from pydantic import BaseModel\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_teddynote.messages import stream_graph, invoke_graph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "\n",
    "# í˜„ì¬ ëŒ€í™” ìƒíƒœ ì ‘ê·¼\n",
    "@tool\n",
    "def summarize_conversation(runtime: ToolRuntime) -> str:\n",
    "    \"\"\"Summarize the conversation so far.\"\"\"\n",
    "    # state ì—ì„œ ë©”ì‹œì§€ ì ‘ê·¼\n",
    "    messages = runtime.state.get(\"messages\", [])\n",
    "    human_msgs = sum(1 for m in messages if m.__class__.__name__ == \"HumanMessage\")\n",
    "    ai_msgs = sum(1 for m in messages if m.__class__.__name__ == \"AIMessage\")\n",
    "    tool_msgs = sum(1 for m in messages if m.__class__.__name__ == \"ToolMessage\")\n",
    "    return f\"Conversation has {human_msgs} user messages, {ai_msgs} AI responses, and {tool_msgs} tool results\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_user_preference(\n",
    "    preference_name: Literal[\"food\", \"coding\", \"sports\"],\n",
    "    runtime: ToolRuntime,  # ToolRuntime ë§¤ê°œë³€ìˆ˜ëŠ” ëª¨ë¸ì— ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤ (ìë™ ì£¼ì…)\n",
    ") -> str:\n",
    "    \"\"\"Get a user preference value.\"\"\"\n",
    "\n",
    "    # contextëŠ” stateì— ì €ì¥í•˜ì§€ ì•Šê³  ë³„ë„ì˜ context ê°ì²´ë¡œ injectë¨\n",
    "    preferences = {}\n",
    "    if getattr(runtime, \"context\", None) is not None:\n",
    "        # context dict ë‚´ user_preferences\n",
    "        preferences = runtime.context.user_preferences or {}\n",
    "    return preferences.get(preference_name, \"Have no information\")\n",
    "\n",
    "\n",
    "class CustomContext(BaseModel):\n",
    "    user_preferences: Optional[Dict[str, Any]] = None\n",
    "\n",
    "\n",
    "class CustomState(TypedDict):\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "    user_preferences: Optional[Dict[str, Any]] = None\n",
    "\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ìƒì„±\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=[summarize_conversation, get_user_preference],\n",
    "    system_prompt=\"You are a helpful assistant.\",\n",
    "    # checkpointer=InMemorySaver(),\n",
    "    context_schema=CustomContext,\n",
    "    # state_schema=CustomState,\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "inputs = {\"messages\": [{\"role\": \"user\", \"content\": \"ë‚´ê°€ ì¢‹ì•„í•˜ëŠ” ìŒì‹ ì•Œë ¤ì¤˜\"}]}\n",
    "\n",
    "invoke_graph(\n",
    "    agent,\n",
    "    inputs=inputs,\n",
    "    config=config,\n",
    "    context=CustomContext(user_preferences={\"food\": \"pizza\"}),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ìƒíƒœ ì—…ë°ì´íŠ¸\n\n`Command`ë¥¼ ì‚¬ìš©í•˜ë©´ ë„êµ¬ ë‚´ì—ì„œ ì—ì´ì „íŠ¸ì˜ ìƒíƒœë¥¼ ì§ì ‘ ì—…ë°ì´íŠ¸í•˜ê±°ë‚˜ ê·¸ë˜í”„ì˜ ì‹¤í–‰ íë¦„ì„ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `update` í•„ë“œë¡œ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•˜ê³ , `goto` í•„ë“œë¡œ ë‹¤ìŒ ë…¸ë“œë¥¼ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nìƒíƒœ ì—…ë°ì´íŠ¸ ì‹œ `ToolMessage`ë¥¼ í¬í•¨í•´ì•¼ í•˜ë©°, `tool_call_id`ëŠ” `runtime.tool_call_id`ì—ì„œ ê°€ì ¸ì™€ì•¼ í•©ë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” Commandë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì´ë¦„ì„ ì—…ë°ì´íŠ¸í•˜ëŠ” ë„êµ¬ ì˜ˆì‹œì…ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from langgraph.types import Command\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain.messages import AnyMessage, RemoveMessage, ToolMessage\n",
    "from langchain_teddynote.messages import invoke_graph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from typing import Annotated, List, Optional, Dict, Any\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class CustomContext(BaseModel):\n",
    "    user_preferences: Optional[Dict[str, Any]] = None\n",
    "\n",
    "\n",
    "class CustomState(BaseModel):\n",
    "    user_name: str = Field(default=\"\", description=\"The user's name\")\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "\n",
    "\n",
    "# User Name ì—…ë°ì´íŠ¸ ë„êµ¬\n",
    "@tool\n",
    "def update_user_name(new_name: str, runtime: ToolRuntime) -> Command:\n",
    "    \"\"\"Update the user's name.\"\"\"\n",
    "    return Command(\n",
    "        update={\n",
    "            \"user_name\": new_name,  # user_name ìƒíƒœì— ì—…ë°ì´íŠ¸\n",
    "            \"messages\": [\n",
    "                ToolMessage(\n",
    "                    content=f\"Successfully updated user name to {new_name}\",\n",
    "                    tool_call_id=runtime.tool_call_id,  # runtime ì—ì„œ ì–»ì–´ì˜¨ tool_call_id ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ì—…ë°ì´íŠ¸\n",
    "                )\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "@tool\n",
    "def clear_messages(runtime: ToolRuntime) -> Command:\n",
    "    \"\"\"Clear all messages from the conversation history except the one whose tool_call_id matches the id we don't want to delete.\"\"\"\n",
    "    from langchain.messages import AIMessage\n",
    "\n",
    "    messages = runtime.state.get(\"messages\", [])\n",
    "\n",
    "    to_remove_messages = []\n",
    "    tool_call_id = runtime.tool_call_id\n",
    "\n",
    "    for m in messages:\n",
    "        if isinstance(m, AIMessage) and getattr(m, \"tool_calls\", None):\n",
    "            # Tool Call ID ê°€ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ì‚­ì œ. Tool Call ID ê°€ ì¼ì¹˜í•˜ë©´ ìœ ì§€.\n",
    "            if not any(call.get(\"id\") == tool_call_id for call in m.tool_calls):\n",
    "                to_remove_messages.append(m)\n",
    "        else:\n",
    "            to_remove_messages.append(m)\n",
    "\n",
    "    removals = [RemoveMessage(id=m.id) for m in to_remove_messages]\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": removals\n",
    "            + [\n",
    "                ToolMessage(\n",
    "                    content=f\"Successfully cleared all previous messages. Total of {len(removals)} deleted messages.\",\n",
    "                    tool_call_id=runtime.tool_call_id,\n",
    "                )\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ìƒì„±\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=[update_user_name, clear_messages],\n",
    "    system_prompt=\"You are a helpful assistant.\",\n",
    "    state_schema=CustomState,\n",
    "    context_schema=CustomContext,  # í´ë˜ìŠ¤ ìì²´ë¥¼ ì „ë‹¬ (ì¸ìŠ¤í„´ìŠ¤ê°€ ì•„ë‹˜)\n",
    "    checkpointer=InMemorySaver(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  update_user_name (call_8IpiHsQgS9fn0boyu48tEYce)\n",
      " Call ID: call_8IpiHsQgS9fn0boyu48tEYce\n",
      "  Args:\n",
      "    new_name: í…Œë””\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mtools\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32muser_name\u001b[0m:\n",
      "í…Œë””\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_user_name\n",
      "\n",
      "Successfully updated user name to í…Œë””\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ì•ˆë…•í•˜ì„¸ìš”, í…Œë””ë‹˜! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ì—ì´ì „íŠ¸ ì‹¤í–‰\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "invoke_graph(\n",
    "    agent,\n",
    "    inputs={\"messages\": [{\"role\": \"user\", \"content\": \"ë‚´ ì´ë¦„ì€ í…Œë””ì•¼\"}]},\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  update_user_name (call_hxxyUlNbwu4vUWn16886zUaU)\n",
      " Call ID: call_hxxyUlNbwu4vUWn16886zUaU\n",
      "  Args:\n",
      "    new_name: ì…œë¦¬\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mtools\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32muser_name\u001b[0m:\n",
      "ì…œë¦¬\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_user_name\n",
      "\n",
      "Successfully updated user name to ì…œë¦¬\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ì´ë¦„ì„ ì…œë¦¬ë¡œ ë³€ê²½í–ˆì–´ìš”. ì…œë¦¬ë‹˜, ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "invoke_graph(\n",
    "    agent,\n",
    "    inputs={\"messages\": [{\"role\": \"user\", \"content\": \"ë‚´ ì´ë¦„ì€ ì‚¬ì‹¤ ì…œë¦¬ì•¼\"}]},\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='ë‚´ ì´ë¦„ì€ í…Œë””ì•¼', additional_kwargs={}, response_metadata={}, id='fba17ade-3572-47b2-a939-70b10f8c7d19'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 87, 'total_tokens': 104, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-Cb48yvwIjmuerToKynHuxqLnvXMiD', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--ced8dc04-8ee6-486d-9fa2-6187f46dc220-0', tool_calls=[{'name': 'update_user_name', 'args': {'new_name': 'í…Œë””'}, 'id': 'call_8IpiHsQgS9fn0boyu48tEYce', 'type': 'tool_call'}], usage_metadata={'input_tokens': 87, 'output_tokens': 17, 'total_tokens': 104, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='Successfully updated user name to í…Œë””', name='update_user_name', id='2272d01f-b99b-4b8f-9a23-5e15503e9dcb', tool_call_id='call_8IpiHsQgS9fn0boyu48tEYce'),\n",
       " AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”, í…Œë””ë‹˜! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 120, 'total_tokens': 135, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-Cb48zD7tQQWhCjAVcQvyA57KDU2si', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--f94ddef8-3fea-4f06-8920-a3b83f80a8d8-0', usage_metadata={'input_tokens': 120, 'output_tokens': 15, 'total_tokens': 135, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='ë‚´ ì´ë¦„ì€ ì‚¬ì‹¤ ì…œë¦¬ì•¼', additional_kwargs={}, response_metadata={}, id='fcd74c54-8120-4aca-8beb-53cc06327e7a'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 150, 'total_tokens': 167, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-Cb48zEH3toy86ZNwQH7DIwTZ3FXwr', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--eb414445-378d-430c-a834-b74c7cd2570c-0', tool_calls=[{'name': 'update_user_name', 'args': {'new_name': 'ì…œë¦¬'}, 'id': 'call_hxxyUlNbwu4vUWn16886zUaU', 'type': 'tool_call'}], usage_metadata={'input_tokens': 150, 'output_tokens': 17, 'total_tokens': 167, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='Successfully updated user name to ì…œë¦¬', name='update_user_name', id='11f94dc3-2a0d-4d4a-82cf-f572b802de54', tool_call_id='call_hxxyUlNbwu4vUWn16886zUaU'),\n",
       " AIMessage(content='ì´ë¦„ì„ ì…œë¦¬ë¡œ ë³€ê²½í–ˆì–´ìš”. ì…œë¦¬ë‹˜, ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 184, 'total_tokens': 209, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-Cb490SCAHCjZXn3IkP4eGQKxERQUQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--b48c06e3-7de0-4a6b-8a40-85c4c05f542a-0', usage_metadata={'input_tokens': 184, 'output_tokens': 25, 'total_tokens': 209, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = agent.get_state(config).values[\"messages\"]\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  clear_messages (call_oYy9f618hea7imUfwxxIdxkz)\n",
      " Call ID: call_oYy9f618hea7imUfwxxIdxkz\n",
      "  Args:\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mtools\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: clear_messages\n",
      "\n",
      "Successfully cleared all previous messages. Total of 9 deleted messages.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "All previous messages in the conversation history have been cleared, except for this one. How can I assist you further?\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "invoke_graph(\n",
    "    agent,\n",
    "    inputs={\"messages\": [{\"role\": \"user\", \"content\": \"ë©”ì‹œì§€ ì „ë¶€ ì‚­ì œí•´ì¤˜\"}]},\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ì§€ê¸ˆì€ ì‚¬ìš©ìì˜ ì´ë¦„ì„ ì•Œê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ì›í•˜ì‹œë©´ ìƒˆ ì´ë¦„ì„ ì•Œë ¤ì£¼ì‹œë©´ ê¸°ì–µí•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ì´ë¦„ì„ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "invoke_graph(\n",
    "    agent,\n",
    "    inputs={\"messages\": [{\"role\": \"user\", \"content\": \"ë‚´ ì´ë¦„ì´ ì‚¬ì‹¤ ë­ë¼ê³  í–ˆì§€?\"}]},\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n### ì»¨í…ìŠ¤íŠ¸\n\n`runtime.context`ë¥¼ í†µí•´ ì‚¬ìš©ì ID, ì„¸ì…˜ ì •ë³´, ì• í”Œë¦¬ì¼€ì´ì…˜ë³„ êµ¬ì„± ë“± ë¶ˆë³€ ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì»¨í…ìŠ¤íŠ¸ëŠ” ì—ì´ì „íŠ¸ í˜¸ì¶œ ì‹œ ì „ë‹¬ë˜ë©°, ë„êµ¬ ì‹¤í–‰ ì¤‘ì— ë³€ê²½ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ë¥¼ í™œìš©í•˜ì—¬ ê³„ì • ì •ë³´ë¥¼ ì¡°íšŒí•˜ëŠ” ë„êµ¬ ì˜ˆì‹œì…ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your current balance is $5000. Is there anything else you would like to know or do?\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "# ì‚¬ìš©ì ë°ì´í„°ë² ì´ìŠ¤ ì‹œë®¬ë ˆì´ì…˜\n",
    "USER_DATABASE = {\n",
    "    \"user123\": {\n",
    "        \"name\": \"Alice Johnson\",\n",
    "        \"account_type\": \"Premium\",\n",
    "        \"balance\": 5000,\n",
    "        \"email\": \"alice@example.com\",\n",
    "    },\n",
    "    \"user456\": {\n",
    "        \"name\": \"Bob Smith\",\n",
    "        \"account_type\": \"Standard\",\n",
    "        \"balance\": 1200,\n",
    "        \"email\": \"bob@example.com\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class UserContext:\n",
    "    user_id: str\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_account_info(runtime: ToolRuntime[UserContext]) -> str:\n",
    "    \"\"\"Get the current user's account information.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "\n",
    "    if user_id in USER_DATABASE:\n",
    "        user = USER_DATABASE[user_id]\n",
    "        return f\"Account holder: {user['name']}\\nType: {user['account_type']}\\nBalance: ${user['balance']}\"\n",
    "    return \"User not found\"\n",
    "\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ìƒì„±\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=[get_account_info],\n",
    "    context_schema=UserContext,\n",
    "    system_prompt=\"You are a financial assistant.\",\n",
    ")\n",
    "\n",
    "# ì»¨í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ ì—ì´ì „íŠ¸ ì‹¤í–‰\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my current balance?\"}]},\n",
    "    context=UserContext(user_id=\"user123\"),\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ë©”ëª¨ë¦¬ (Store)\n\n`runtime.store`ë¥¼ ì‚¬ìš©í•˜ë©´ ëŒ€í™” ì „ë°˜ì— ê±¸ì³ ì˜êµ¬ ë°ì´í„°ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. StoreëŠ” ì‚¬ìš©ìë³„ ë˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ë³„ ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ëŠ” ì¥ê¸° ë©”ëª¨ë¦¬ ì—­í• ì„ í•©ë‹ˆë‹¤.\n\nStoreëŠ” `get()`, `put()` ë©”ì„œë“œë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ì½ê³  ì“¸ ìˆ˜ ìˆìœ¼ë©°, ë„¤ì„ìŠ¤í˜ì´ìŠ¤(íŠœí”Œ)ì™€ í‚¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”í•©ë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” Storeë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì •ë³´ë¥¼ ì €ì¥í•˜ê³  ì¡°íšŒí•˜ëŠ” ë„êµ¬ ì˜ˆì‹œì…ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì ‘ê·¼\n",
    "@tool\n",
    "def get_user_info(user_id: str, runtime: ToolRuntime) -> str:\n",
    "    \"\"\"Look up user info.\"\"\"\n",
    "    store = runtime.store\n",
    "    user_info = store.get((\"users\",), user_id)\n",
    "    return str(user_info.value) if user_info else \"Unknown user\"\n",
    "\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸\n",
    "@tool\n",
    "def save_user_info(\n",
    "    user_id: str, user_info: dict[str, Any], runtime: ToolRuntime\n",
    ") -> str:\n",
    "    \"\"\"Save user info.\"\"\"\n",
    "    store = runtime.store\n",
    "    store.put((\"users\",), user_id, user_info)\n",
    "    return \"Successfully saved user info.\"\n",
    "\n",
    "\n",
    "# ìŠ¤í† ì–´ì™€ ì—ì´ì „íŠ¸ ìƒì„±\n",
    "store = InMemoryStore()\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "agent = create_agent(model, tools=[get_user_info, save_user_info], store=store)\n",
    "\n",
    "# ì²« ë²ˆì§¸ ì„¸ì…˜: ì‚¬ìš©ì ì •ë³´ ì €ì¥\n",
    "print(\"=== Saving user info ===\")\n",
    "result1 = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Save the following user: userid: abc123, name: Foo, age: 25, email: foo@langchain.dev\",\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "print(result1[\"messages\"][-1].content)\n",
    "\n",
    "# ë‘ ë²ˆì§¸ ì„¸ì…˜: ì‚¬ìš©ì ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "print(\"\\n=== Getting user info ===\")\n",
    "result2 = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"Get user info for user with id 'abc123'\"}\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "print(result2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Stream Writer\n\n`runtime.stream_writer`ë¥¼ ì‚¬ìš©í•˜ë©´ ë„êµ¬ ì‹¤í–‰ ì¤‘ ì»¤ìŠ¤í…€ ì—…ë°ì´íŠ¸ë¥¼ ìŠ¤íŠ¸ë¦¬ë°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì¥ì‹œê°„ ì‹¤í–‰ë˜ëŠ” ë„êµ¬ì—ì„œ ì‚¬ìš©ìì—ê²Œ ì§„í–‰ ìƒí™©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì•Œë ¤ì¤„ ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.\n\nìŠ¤íŠ¸ë¦¬ë°ëœ ì—…ë°ì´íŠ¸ëŠ” `stream_mode=\"custom\"`ìœ¼ë¡œ ìˆ˜ì‹ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Stream WriterëŠ” LangGraph ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ ë‚´ì—ì„œë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” Stream Writerë¥¼ ì‚¬ìš©í•˜ì—¬ ì§„í–‰ ìƒí™©ì„ ìŠ¤íŠ¸ë¦¬ë°í•˜ëŠ” ë„êµ¬ ì˜ˆì‹œì…ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather_with_updates(city: str, runtime: ToolRuntime) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    writer = runtime.stream_writer\n",
    "\n",
    "    # ë„êµ¬ê°€ ì‹¤í–‰ë  ë•Œ ì»¤ìŠ¤í…€ ì—…ë°ì´íŠ¸ ìŠ¤íŠ¸ë¦¬ë°\n",
    "    writer(f\"Looking up data for city: {city}\")\n",
    "    writer(f\"Acquired data for city: {city}\")\n",
    "\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "\n",
    "# ì°¸ê³ : runtime.stream_writerë¥¼ ë„êµ¬ ë‚´ì—ì„œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°,\n",
    "# ë„êµ¬ëŠ” LangGraph ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ ë‚´ì—ì„œ í˜¸ì¶œë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up data for city: ì„œìš¸\n",
      "Acquired data for city: ì„œìš¸\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.messages import stream_graph\n",
    "\n",
    "# ìŠ¤í† ì–´ì™€ ì—ì´ì „íŠ¸ ìƒì„±\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "agent = create_agent(model, tools=[get_weather_with_updates])\n",
    "\n",
    "inputs = {\"messages\": [{\"role\": \"user\", \"content\": \"ì„œìš¸ ë‚ ì”¨ ì•Œë ¤ì¤˜\"}]}\n",
    "\n",
    "for chunk in agent.stream(inputs, stream_mode=\"custom\"):\n",
    "    print(chunk)\n",
    "\n",
    "# stream_graph(agent, inputs=inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "---\n\n## ì •ë¦¬\n\nì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” LangGraph ì—ì´ì „íŠ¸ì—ì„œ ë„êµ¬ë¥¼ ì •ì˜í•˜ê³  í™œìš©í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.\n\n**í•µì‹¬ ê°œë… ìš”ì•½:**\n\n| ê°œë… | ì„¤ëª… |\n|:---|:---|\n| **@tool ë°ì½”ë ˆì´í„°** | í•¨ìˆ˜ë¥¼ ë„êµ¬ë¡œ ë³€í™˜í•˜ë©°, docstringì´ ë„êµ¬ ì„¤ëª…ì´ ë©ë‹ˆë‹¤ |\n| **Pydantic ìŠ¤í‚¤ë§ˆ** | `args_schema`ë¡œ ë³µì¡í•œ ì…ë ¥ ê²€ì¦ì„ ìë™í™”í•©ë‹ˆë‹¤ |\n| **ToolRuntime** | state, context, store ë“± ëŸ°íƒ€ì„ ì •ë³´ì— ì ‘ê·¼í•©ë‹ˆë‹¤ |\n| **Command** | ë„êµ¬ ë‚´ì—ì„œ ìƒíƒœ ì—…ë°ì´íŠ¸ ë° ì‹¤í–‰ íë¦„ì„ ì œì–´í•©ë‹ˆë‹¤ |\n| **Store** | ëŒ€í™” ì „ë°˜ì— ê±¸ì¹œ ì˜êµ¬ì ì¸ ì¥ê¸° ë©”ëª¨ë¦¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤ |\n| **Stream Writer** | ë„êµ¬ ì‹¤í–‰ ì¤‘ ì§„í–‰ ìƒí™©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤ |\n\n**ë‹¤ìŒ ë‹¨ê³„:**\n- ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¥¼ í™œìš©í•œ ì‹¤ì‹œê°„ ì‘ë‹µ ì²˜ë¦¬ í•™ìŠµ\n- ëŸ°íƒ€ì„ ì»¨í…ìŠ¤íŠ¸ë¥¼ í™œìš©í•œ ê³ ê¸‰ ì—ì´ì „íŠ¸ êµ¬ì¶•"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}