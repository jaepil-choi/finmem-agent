{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Runtime\n\nLangChainì˜ `create_agent`ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ LangGraphì˜ ëŸ°íƒ€ì„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. Runtimeì€ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ë„êµ¬ì™€ ë¯¸ë“¤ì›¨ì–´ì—ì„œ ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n\n**Runtime êµ¬ì„± ìš”ì†Œ:**\n\n| êµ¬ì„± ìš”ì†Œ | ì„¤ëª… |\n|:---|:---|\n| **Context** | ì‚¬ìš©ì ID, ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë“± ì •ì  ì •ë³´ |\n| **Store** | ì¥ê¸° ë©”ëª¨ë¦¬ë¥¼ ìœ„í•œ `BaseStore` ì¸ìŠ¤í„´ìŠ¤ |\n| **Stream Writer** | `\"custom\"` ìŠ¤íŠ¸ë¦¼ ëª¨ë“œë¡œ ì •ë³´ ìŠ¤íŠ¸ë¦¬ë° |\n\nëŸ°íƒ€ì„ ì •ë³´ëŠ” ë„êµ¬ì™€ ë¯¸ë“¤ì›¨ì–´ ë‚´ì—ì„œ `runtime` ë§¤ê°œë³€ìˆ˜ë¥¼ í†µí•´ ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n> ì°¸ê³  ë¬¸ì„œ: [LangGraph Persistence](https://docs.langchain.com/oss/python/langgraph/persistence.md)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## í™˜ê²½ ì„¤ì •\n\nRuntime íŠœí† ë¦¬ì–¼ì„ ì‹œì‘í•˜ê¸° ì „ì— í•„ìš”í•œ í™˜ê²½ì„ ì„¤ì •í•©ë‹ˆë‹¤. `dotenv`ë¥¼ ì‚¬ìš©í•˜ì—¬ API í‚¤ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Context ì •ì˜ ë° ì‚¬ìš©\n\n`create_agent`ë¡œ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•  ë•Œ `context_schema`ë¥¼ ì§€ì •í•˜ì—¬ ì—ì´ì „íŠ¸ `Runtime`ì— ì €ì¥ë  `context`ì˜ êµ¬ì¡°ë¥¼ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ContextëŠ” dataclass ë˜ëŠ” Pydantic ëª¨ë¸ë¡œ ì •ì˜í•˜ë©°, ì—ì´ì „íŠ¸ í˜¸ì¶œ ì‹œ `context` ë§¤ê°œë³€ìˆ˜ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.\n\nContextëŠ” ë„êµ¬ì™€ ë¯¸ë“¤ì›¨ì–´ì—ì„œ `runtime.context`ë¥¼ í†µí•´ ì ‘ê·¼í•  ìˆ˜ ìˆìœ¼ë©°, ì‚¬ìš©ìë³„ ì„¤ì •ì´ë‚˜ ì„¸ì…˜ ì •ë³´ë¥¼ ì „ë‹¬í•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” Context ìŠ¤í‚¤ë§ˆë¥¼ ì •ì˜í•˜ê³  ì—ì´ì „íŠ¸ì— ì „ë‹¬í•˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have access to your name. Could you please tell me your name?\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain.agents import create_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_name: str\n",
    "\n",
    "\n",
    "@tool\n",
    "def greet_user() -> str:\n",
    "    \"\"\"Greet the user.\"\"\"\n",
    "    return \"Hello!\"\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model, tools=[greet_user], context_schema=Context  # Context ìŠ¤í‚¤ë§ˆ ì •ì˜\n",
    ")\n",
    "\n",
    "# Contextë¥¼ ì „ë‹¬í•˜ì—¬ ì—ì´ì „íŠ¸ í˜¸ì¶œ\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my name?\"}]},\n",
    "    context=Context(user_name=\"John Smith\"),  # Context ì „ë‹¬\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## ë„êµ¬ì—ì„œ Runtime ì•¡ì„¸ìŠ¤\n\në„êµ¬ ë‚´ì—ì„œ `ToolRuntime` ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ `Runtime` ê°ì²´ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë‹¤ìŒ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n\n- **Context ì ‘ê·¼**: ì‚¬ìš©ì ì •ë³´, ì„¸ì…˜ ë°ì´í„° ë“±\n- **Store ì½ê¸°/ì“°ê¸°**: ì¥ê¸° ë©”ëª¨ë¦¬ ê´€ë¦¬\n- **Stream Writer**: ì§„í–‰ ìƒí™© ìŠ¤íŠ¸ë¦¬ë°\n\n`ToolRuntime` ë§¤ê°œë³€ìˆ˜ëŠ” ë„êµ¬ ì‹œê·¸ë‹ˆì²˜ì— ì¶”ê°€í•˜ë©´ ìë™ìœ¼ë¡œ ì£¼ì…ë˜ë©°, LLMì—ëŠ” ë…¸ì¶œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Context ì•¡ì„¸ìŠ¤\n\në„êµ¬ì—ì„œ `runtime.context`ë¥¼ í†µí•´ Context ê°ì²´ì— ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `ToolRuntime[ContextType]` í˜•íƒœë¡œ íƒ€ì… íŒíŠ¸ë¥¼ ì§€ì •í•˜ë©´ IDEì—ì„œ ìë™ ì™„ì„±ì„ ì§€ì›ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” ë„êµ¬ì—ì„œ Contextì— ì ‘ê·¼í•˜ì—¬ ì‚¬ìš©ì ì •ë³´ë¥¼ í™œìš©í•˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool, ToolRuntime\n",
    "from dataclasses import dataclass\n",
    "from langchain_teddynote.messages import invoke_graph\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class UserContext:\n",
    "    user_id: str\n",
    "    user_name: str\n",
    "    user_email: str\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_user_info(runtime: ToolRuntime[UserContext]) -> str:\n",
    "    \"\"\"Get information about the current user.\"\"\"\n",
    "    # Contextì—ì„œ ì‚¬ìš©ì ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "    user_id = runtime.context.user_id\n",
    "    user_name = runtime.context.user_name\n",
    "    user_email = runtime.context.user_email\n",
    "\n",
    "    return f\"User ID: {user_id}, Name: {user_name}, Email: {user_email}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def personalized_greeting(runtime: ToolRuntime[UserContext]) -> str:\n",
    "    \"\"\"Generate a personalized greeting for the user.\"\"\"\n",
    "    user_name = runtime.context.user_name\n",
    "    return f\"ì•ˆë…•í•˜ì„¸ìš”, {user_name}ë‹˜! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\"\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_user_info, personalized_greeting],\n",
    "    context_schema=UserContext,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_user_info (call_aCCGYgoqyD3iBVtKs0lnPdEK)\n",
      " Call ID: call_aCCGYgoqyD3iBVtKs0lnPdEK\n",
      "  Args:\n",
      "  personalized_greeting (call_9Xzn8buotGRVJAIqj406k5AB)\n",
      " Call ID: call_9Xzn8buotGRVJAIqj406k5AB\n",
      "  Args:\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mtools\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_user_info\n",
      "\n",
      "User ID: user_123, Name: ê¹€ì² ìˆ˜, Email: chulsoo@example.com\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mtools\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: personalized_greeting\n",
      "\n",
      "ì•ˆë…•í•˜ì„¸ìš”, ê¹€ì² ìˆ˜ë‹˜! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ì•ˆë…•í•˜ì„¸ìš”, ê¹€ì² ìˆ˜ë‹˜! ë°˜ê°‘ìŠµë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Contextë¥¼ ì „ë‹¬í•˜ì—¬ í˜¸ì¶œ\n",
    "invoke_graph(\n",
    "    agent,\n",
    "    inputs={\"messages\": [{\"role\": \"user\", \"content\": \"ì•ˆë…•í•˜ì„¸ìš”? ë°˜ê°‘ìŠµë‹ˆë‹¤.\"}]},\n",
    "    context=UserContext(\n",
    "        user_id=\"user_123\", user_name=\"ê¹€ì² ìˆ˜\", user_email=\"chulsoo@example.com\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Store ì•¡ì„¸ìŠ¤ (ì¥ê¸° ë©”ëª¨ë¦¬)\n\në„êµ¬ ë‚´ì—ì„œ `runtime.store`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¥ê¸° ë©”ëª¨ë¦¬ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. StoreëŠ” ëŒ€í™” ì„¸ì…˜ì„ ë„˜ì–´ì„œ ë°ì´í„°ë¥¼ ì˜êµ¬ ì €ì¥í•˜ë©°, `get()`, `put()` ë©”ì„œë“œë¡œ ë°ì´í„°ë¥¼ ì½ê³  ì”ë‹ˆë‹¤.\n\nStoreì˜ í‚¤ëŠ” ë„¤ì„ìŠ¤í˜ì´ìŠ¤(íŠœí”Œ)ì™€ í‚¤(ë¬¸ìì—´)ë¡œ êµ¬ì„±ë˜ì–´ ë°ì´í„°ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” Storeë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì„¤ì •ì„ ì €ì¥í•˜ê³  ì¡°íšŒí•˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str\n",
    "\n",
    "\n",
    "@tool\n",
    "def fetch_user_email_preferences(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Fetch the user's email preferences from the store.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "\n",
    "    # ê¸°ë³¸ ì„¤ì •\n",
    "    preferences: str = \"The user prefers you to write a brief and polite email.\"\n",
    "\n",
    "    # Storeì—ì„œ ì‚¬ìš©ì ì„¤ì • ê°€ì ¸ì˜¤ê¸°\n",
    "    if runtime.store:\n",
    "        if memory := runtime.store.get((\"users\",), user_id):\n",
    "            preferences = memory.value[\"preferences\"]\n",
    "\n",
    "    return preferences\n",
    "\n",
    "\n",
    "@tool\n",
    "def save_user_preference(preference: str, runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Save user preference to the store.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "\n",
    "    if runtime.store:\n",
    "        runtime.store.put((\"users\",), user_id, {\"preferences\": preference})\n",
    "        return f\"Saved preference: {preference}\"\n",
    "\n",
    "    return \"Store not available\"\n",
    "\n",
    "\n",
    "# Storeì™€ í•¨ê»˜ ì—ì´ì „íŠ¸ ìƒì„±\n",
    "store = InMemoryStore()\n",
    "\n",
    "# ì´ˆê¸° ë°ì´í„° ì„¤ì •\n",
    "store.put(\n",
    "    (\"users\",),\n",
    "    \"user_123\",\n",
    "    {\"preferences\": \"The user prefers detailed and technical explanations.\"},\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[fetch_user_email_preferences, save_user_preference],\n",
    "    context_schema=Context,\n",
    "    store=store,  # Store ì „ë‹¬\n",
    ")\n",
    "\n",
    "# Storeì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What are my email preferences?\"}]},\n",
    "    context=Context(user_id=\"user_123\"),\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Stream Writer ì•¡ì„¸ìŠ¤\n\në„êµ¬ ë‚´ì—ì„œ `runtime.get_stream_writer()` ë˜ëŠ” `runtime.stream_writer`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì»¤ìŠ¤í…€ ì—…ë°ì´íŠ¸ë¥¼ ìŠ¤íŠ¸ë¦¬ë°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì¥ì‹œê°„ ì‹¤í–‰ë˜ëŠ” ì‘ì—…ì—ì„œ ì‚¬ìš©ìì—ê²Œ ì§„í–‰ ìƒí™©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì•Œë ¤ì¤„ ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.\n\nìŠ¤íŠ¸ë¦¬ë°ëœ ì—…ë°ì´íŠ¸ëŠ” `stream_mode=\"custom\"`ìœ¼ë¡œ ìˆ˜ì‹ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” Stream Writerë¥¼ ì‚¬ìš©í•˜ì—¬ ì§„í–‰ ìƒí™©ì„ ìŠ¤íŠ¸ë¦¬ë°í•˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool, ToolRuntime\n",
    "import time\n",
    "\n",
    "\n",
    "@tool\n",
    "def process_large_dataset(num_items: int, runtime: ToolRuntime) -> str:\n",
    "    \"\"\"Process a large dataset and report progress.\"\"\"\n",
    "    writer = runtime.get_stream_writer()\n",
    "\n",
    "    # ì§„í–‰ ìƒí™© ìŠ¤íŠ¸ë¦¬ë°\n",
    "    for i in range(0, num_items, 10):\n",
    "        progress = min(i + 10, num_items)\n",
    "        writer({\"stage\": \"processing\", \"progress\": progress, \"total\": num_items})\n",
    "        time.sleep(0.1)  # ì‘ì—… ì‹œë®¬ë ˆì´ì…˜\n",
    "\n",
    "    writer({\"stage\": \"completed\", \"total\": num_items})\n",
    "    return f\"Successfully processed {num_items} items!\"\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[process_large_dataset],\n",
    ")\n",
    "\n",
    "# ì»¤ìŠ¤í…€ ìŠ¤íŠ¸ë¦¼ ëª¨ë“œë¡œ ì§„í–‰ ìƒí™© ì¶”ì \n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Process 50 items\"}]},\n",
    "    stream_mode=\"custom\",\n",
    "):\n",
    "    if \"progress\" in chunk:\n",
    "        percentage = (chunk[\"progress\"] / chunk[\"total\"]) * 100\n",
    "        print(f\"Progress: {percentage:.0f}%\")\n",
    "    elif \"stage\" in chunk and chunk[\"stage\"] == \"completed\":\n",
    "        print(f\"Completed processing {chunk['total']} items!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## ë¯¸ë“¤ì›¨ì–´ì—ì„œ Runtime ì•¡ì„¸ìŠ¤\n\në¯¸ë“¤ì›¨ì–´ì—ì„œ `Runtime` ê°ì²´ì— ì•¡ì„¸ìŠ¤í•˜ì—¬ ë™ì  í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ê±°ë‚˜, ë©”ì‹œì§€ë¥¼ ìˆ˜ì •í•˜ê±°ë‚˜, ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ì— ë”°ë¼ ì—ì´ì „íŠ¸ ë™ì‘ì„ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¯¸ë“¤ì›¨ì–´ í•¨ìˆ˜ì˜ `runtime` ë§¤ê°œë³€ìˆ˜ë¥¼ í†µí•´ Context, Store ë“±ì— ì ‘ê·¼í•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Dynamic Promptì—ì„œ Runtime ì‚¬ìš©\n\n`@dynamic_prompt` ë°ì½”ë ˆì´í„°ë¡œ ì •ì˜ëœ ë¯¸ë“¤ì›¨ì–´ì—ì„œ `request.runtime`ì„ í†µí•´ Contextì— ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í™œìš©í•˜ì—¬ ì‚¬ìš©ìë³„ë¡œ ë‹¤ë¥¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” ì‚¬ìš©ì ì—­í• ì— ë”°ë¼ ë‹¤ë¥¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_name: str\n",
    "    user_role: str\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the weather in a city.\"\"\"\n",
    "    return f\"The weather in {city} is sunny!\"\n",
    "\n",
    "\n",
    "@dynamic_prompt\n",
    "def dynamic_system_prompt(request: ModelRequest) -> str:\n",
    "    # Runtimeì—ì„œ Context ê°€ì ¸ì˜¤ê¸°\n",
    "    user_name = request.runtime.context.user_name\n",
    "    user_role = request.runtime.context.user_role\n",
    "\n",
    "    # ì‚¬ìš©ì ì—­í• ì— ë”°ë¼ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸\n",
    "    if user_role == \"admin\":\n",
    "        system_prompt = f\"You are a helpful assistant with full access. Address the user as {user_name}.\"\n",
    "    else:\n",
    "        system_prompt = f\"You are a helpful assistant. Address the user as {user_name}. Provide brief answers.\"\n",
    "\n",
    "    return system_prompt\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    middleware=[dynamic_system_prompt],\n",
    "    context_schema=Context,\n",
    ")\n",
    "\n",
    "# Admin ì‚¬ìš©ìë¡œ í˜¸ì¶œ\n",
    "print(\"=== Admin User ===\")\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    context=Context(user_name=\"Admin Kim\", user_role=\"admin\"),\n",
    ")\n",
    "print(result[\"messages\"][-1].content)\n",
    "\n",
    "# ì¼ë°˜ ì‚¬ìš©ìë¡œ í˜¸ì¶œ\n",
    "print(\"\\n=== Regular User ===\")\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    context=Context(user_name=\"User Lee\", user_role=\"user\"),\n",
    ")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Before/After Modelì—ì„œ Runtime ì‚¬ìš©\n\n`@before_model`ê³¼ `@after_model` ë°ì½”ë ˆì´í„°ë¡œ ì •ì˜ëœ ë¯¸ë“¤ì›¨ì–´ì—ì„œë„ `runtime` ë§¤ê°œë³€ìˆ˜ë¥¼ í†µí•´ Contextì— ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í™œìš©í•˜ì—¬ ëª¨ë¸ í˜¸ì¶œ ì „í›„ì— ë¡œê¹…, ê²€ì¦, ë³€í™˜ ë“±ì˜ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” ëª¨ë¸ í˜¸ì¶œ ì „í›„ì— ì‚¬ìš©ì ì •ë³´ë¥¼ ë¡œê¹…í•˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentState\n",
    "from langchain.agents.middleware import before_model, after_model\n",
    "from langgraph.runtime import Runtime\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_name: str\n",
    "    session_id: str\n",
    "\n",
    "\n",
    "@before_model\n",
    "def log_before_model(state: AgentState, runtime: Runtime[Context]) -> dict | None:\n",
    "    \"\"\"ëª¨ë¸ í˜¸ì¶œ ì „ ë¡œê¹…\"\"\"\n",
    "    print(\n",
    "        f\"[Before Model] User: {runtime.context.user_name}, Session: {runtime.context.session_id}\"\n",
    "    )\n",
    "    print(f\"[Before Model] Messages count: {len(state['messages'])}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "@after_model\n",
    "def log_after_model(state: AgentState, runtime: Runtime[Context]) -> dict | None:\n",
    "    \"\"\"ëª¨ë¸ í˜¸ì¶œ í›„ ë¡œê¹…\"\"\"\n",
    "    print(f\"[After Model] User: {runtime.context.user_name}\")\n",
    "    print(f\"[After Model] Response generated for session: {runtime.context.session_id}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    middleware=[log_before_model, log_after_model],\n",
    "    context_schema=Context,\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's the weather in Seoul?\"}]},\n",
    "    context=Context(user_name=\"John Smith\", session_id=\"session_456\"),\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal response: {result['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## ì¢…í•© ì˜ˆì œ: ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì—ì´ì „íŠ¸\n\nRuntimeì˜ ëª¨ë“  ê¸°ëŠ¥ì„ í™œìš©í•œ ì‹¤ìš©ì ì¸ ì˜ˆì œì…ë‹ˆë‹¤. Contextë¡œ ì‚¬ìš©ì ì •ë³´ë¥¼ ì „ë‹¬í•˜ê³ , Storeë¡œ ê²€ìƒ‰ ê¸°ë¡ì„ ê´€ë¦¬í•˜ë©°, ë¯¸ë“¤ì›¨ì–´ë¡œ ë™ì  í”„ë¡¬í”„íŠ¸ì™€ ì‚¬ìš©ëŸ‰ ì¶”ì ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” ì‚¬ìš©ì ë“±ê¸‰ì— ë”°ë¼ ë‹¤ë¥¸ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ì—ì´ì „íŠ¸ ì˜ˆì‹œì…ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest, before_model\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.runtime import Runtime\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class UserContext:\n",
    "    user_id: str\n",
    "    user_name: str\n",
    "    user_tier: str  # \"free\", \"premium\", \"enterprise\"\n",
    "    language: str  # \"ko\", \"en\"\n",
    "\n",
    "\n",
    "# ë„êµ¬ ì •ì˜\n",
    "@tool\n",
    "def search_database(query: str, runtime: ToolRuntime[UserContext]) -> str:\n",
    "    \"\"\"Search the database. Access level depends on user tier.\"\"\"\n",
    "    user_tier = runtime.context.user_tier\n",
    "\n",
    "    # ì‚¬ìš©ì ë“±ê¸‰ì— ë”°ë¼ ë‹¤ë¥¸ ê²°ê³¼ ì œê³µ\n",
    "    if user_tier == \"enterprise\":\n",
    "        return f\"Full database search results for: {query} (Enterprise access)\"\n",
    "    elif user_tier == \"premium\":\n",
    "        return f\"Premium search results for: {query}\"\n",
    "    else:\n",
    "        return f\"Basic search results for: {query} (Limited to 10 results)\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_user_history(runtime: ToolRuntime[UserContext]) -> str:\n",
    "    \"\"\"Get user's search history from store.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "\n",
    "    if runtime.store:\n",
    "        if history := runtime.store.get((\"history\",), user_id):\n",
    "            return f\"Recent searches: {history.value['searches']}\"\n",
    "\n",
    "    return \"No search history found\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def save_search(query: str, runtime: ToolRuntime[UserContext]) -> str:\n",
    "    \"\"\"Save search query to user history.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "\n",
    "    if runtime.store:\n",
    "        # ê¸°ì¡´ íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°\n",
    "        existing = runtime.store.get((\"history\",), user_id)\n",
    "        searches = existing.value[\"searches\"] if existing else []\n",
    "\n",
    "        # ìƒˆ ê²€ìƒ‰ì–´ ì¶”ê°€\n",
    "        searches.append(query)\n",
    "        runtime.store.put(\n",
    "            (\"history\",), user_id, {\"searches\": searches[-5:]}\n",
    "        )  # ìµœê·¼ 5ê°œë§Œ ìœ ì§€\n",
    "\n",
    "        return f\"Saved search: {query}\"\n",
    "\n",
    "    return \"Store not available\"\n",
    "\n",
    "\n",
    "# ë™ì  í”„ë¡¬í”„íŠ¸ - ì‚¬ìš©ì ì–¸ì–´ì— ë”°ë¼ ë³€ê²½\n",
    "@dynamic_prompt\n",
    "def multilingual_prompt(request: ModelRequest) -> str:\n",
    "    user_name = request.runtime.context.user_name\n",
    "    language = request.runtime.context.language\n",
    "    user_tier = request.runtime.context.user_tier\n",
    "\n",
    "    if language == \"ko\":\n",
    "        prompt = f\"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìë¥¼ '{user_name}'ë‹˜ìœ¼ë¡œ í˜¸ì¹­í•˜ì„¸ìš”.\"\n",
    "        if user_tier == \"enterprise\":\n",
    "            prompt += (\n",
    "                \" ì´ ì‚¬ìš©ìëŠ” ì—”í„°í”„ë¼ì´ì¦ˆ íšŒì›ì´ë¯€ë¡œ ëª¨ë“  ê¸°ëŠ¥ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
    "            )\n",
    "    else:\n",
    "        prompt = f\"You are a helpful assistant. Address the user as {user_name}.\"\n",
    "        if user_tier == \"enterprise\":\n",
    "            prompt += \" This is an enterprise user with full access.\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# ì‚¬ìš©ëŸ‰ ì¶”ì  ë¯¸ë“¤ì›¨ì–´\n",
    "@before_model\n",
    "def track_usage(state: AgentState, runtime: Runtime[UserContext]) -> dict | None:\n",
    "    \"\"\"Track API usage for billing\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    user_tier = runtime.context.user_tier\n",
    "\n",
    "    print(f\"[Usage Tracker] User: {user_id}, Tier: {user_tier}\")\n",
    "\n",
    "    # ë¬´ë£Œ ì‚¬ìš©ìì˜ ê²½ìš° ì‚¬ìš©ëŸ‰ ì œí•œ í™•ì¸\n",
    "    if user_tier == \"free\":\n",
    "        if runtime.store:\n",
    "            usage = runtime.store.get((\"usage\",), user_id)\n",
    "            count = usage.value[\"count\"] if usage else 0\n",
    "\n",
    "            if count >= 10:\n",
    "                print(\"[Usage Tracker] Free tier limit reached!\")\n",
    "                # ì‹¤ì œë¡œëŠ” ì—¬ê¸°ì„œ ì‹¤í–‰ì„ ì¤‘ë‹¨í•  ìˆ˜ ìˆìŒ\n",
    "\n",
    "            # ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸\n",
    "            runtime.store.put((\"usage\",), user_id, {\"count\": count + 1})\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# Store ìƒì„± ë° ì´ˆê¸° ë°ì´í„° ì„¤ì •\n",
    "store = InMemoryStore()\n",
    "store.put(\n",
    "    (\"history\",), \"user_001\", {\"searches\": [\"Python tutorial\", \"LangChain guide\"]}\n",
    ")\n",
    "store.put((\"usage\",), \"user_002\", {\"count\": 5})\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ìƒì„±\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[search_database, get_user_history, save_search],\n",
    "    middleware=[multilingual_prompt, track_usage],\n",
    "    context_schema=UserContext,\n",
    "    store=store,\n",
    ")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ 1: ì—”í„°í”„ë¼ì´ì¦ˆ ì‚¬ìš©ì (í•œêµ­ì–´)\n",
    "print(\"=== Test 1: Enterprise User (Korean) ===\")\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Search for 'machine learning'\"}]},\n",
    "    context=UserContext(\n",
    "        user_id=\"user_001\", user_name=\"ê¹€ì² ìˆ˜\", user_tier=\"enterprise\", language=\"ko\"\n",
    "    ),\n",
    ")\n",
    "print(result[\"messages\"][-1].content)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ 2: ë¬´ë£Œ ì‚¬ìš©ì (ì˜ì–´)\n",
    "print(\"\\n=== Test 2: Free User (English) ===\")\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Search for 'data science'\"}]},\n",
    "    context=UserContext(\n",
    "        user_id=\"user_002\", user_name=\"John Doe\", user_tier=\"free\", language=\"en\"\n",
    "    ),\n",
    ")\n",
    "print(result[\"messages\"][-1].content)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ 3: ê²€ìƒ‰ ê¸°ë¡ ì¡°íšŒ\n",
    "print(\"\\n=== Test 3: Check Search History ===\")\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my search history?\"}]},\n",
    "    context=UserContext(\n",
    "        user_id=\"user_001\", user_name=\"ê¹€ì² ìˆ˜\", user_tier=\"enterprise\", language=\"ko\"\n",
    "    ),\n",
    ")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## ì‹¤ì „ íŒ¨í„´\n\n### ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì „ë‹¬\n\nContextë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°ì²´ë¥¼ ë„êµ¬ì— ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ íŒ¨í„´ì„ ì‚¬ìš©í•˜ë©´ ë„êµ¬ì—ì„œ ì§ì ‘ ë°ì´í„°ë² ì´ìŠ¤ì— ì ‘ê·¼í•˜ì—¬ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ Contextë¡œ ì „ë‹¬í•˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DatabaseContext:\n",
    "    db_connection: Any  # ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°ì²´\n",
    "    user_id: str\n",
    "\n",
    "\n",
    "@tool\n",
    "def query_database(sql: str, runtime: ToolRuntime[DatabaseContext]) -> str:\n",
    "    \"\"\"Execute SQL query on the database.\"\"\"\n",
    "    db = runtime.context.db_connection\n",
    "    user_id = runtime.context.user_id\n",
    "\n",
    "    # ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ì‹¤í–‰\n",
    "    # result = db.execute(sql)\n",
    "\n",
    "    return f\"Query executed for user {user_id}: {sql}\"\n",
    "\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ (ì‹¤ì œ DB ì—°ê²° ëŒ€ì‹  None ì‚¬ìš©)\n",
    "# agent = create_agent(\n",
    "#     model=model,\n",
    "#     tools=[query_database],\n",
    "#     context_schema=DatabaseContext\n",
    "# )\n",
    "#\n",
    "# result = agent.invoke(\n",
    "#     {\"messages\": [{\"role\": \"user\", \"content\": \"Query user data\"}]},\n",
    "#     context=DatabaseContext(db_connection=db, user_id=\"user_123\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ì¸ì¦ ë° ê¶Œí•œ ê²€ì‚¬\n\në¯¸ë“¤ì›¨ì–´ì—ì„œ Contextë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì¸ì¦ ë° ê¶Œí•œì„ ê²€ì‚¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `@before_agent` ë¯¸ë“¤ì›¨ì–´ì—ì„œ ê¶Œí•œì´ ì—†ëŠ” ìš”ì²­ì„ ì‚¬ì „ì— ì°¨ë‹¨í•˜ë©´ ë³´ì•ˆì„ ê°•í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” ì‚¬ìš©ì ê¶Œí•œì„ ê²€ì‚¬í•˜ëŠ” ë¯¸ë“¤ì›¨ì–´ ì˜ˆì‹œì…ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import before_agent, hook_config\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AuthContext:\n",
    "    user_id: str\n",
    "    permissions: list[str]\n",
    "\n",
    "\n",
    "@before_agent(can_jump_to=[\"end\"])\n",
    "def check_permissions(\n",
    "    state: AgentState, runtime: Runtime[AuthContext]\n",
    ") -> dict[str, Any] | None:\n",
    "    \"\"\"Check if user has required permissions\"\"\"\n",
    "    permissions = runtime.context.permissions\n",
    "\n",
    "    # ë©”ì‹œì§€ì—ì„œ ìš”ì²­ëœ ì‘ì—… í™•ì¸\n",
    "    if state[\"messages\"]:\n",
    "        content = state[\"messages\"][0].content.lower()\n",
    "\n",
    "        # ê´€ë¦¬ì ì‘ì—… ìš”ì²­ ì‹œ ê¶Œí•œ í™•ì¸\n",
    "        if \"delete\" in content or \"remove\" in content:\n",
    "            if \"admin\" not in permissions:\n",
    "                return {\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"assistant\",\n",
    "                            \"content\": \"You don't have permission to perform this action.\",\n",
    "                        }\n",
    "                    ],\n",
    "                    \"jump_to\": \"end\",\n",
    "                }\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "# agent = create_agent(\n",
    "#     model=model,\n",
    "#     tools=[search_tool],\n",
    "#     middleware=[check_permissions],\n",
    "#     context_schema=AuthContext\n",
    "# )\n",
    "#\n",
    "# result = agent.invoke(\n",
    "#     {\"messages\": [{\"role\": \"user\", \"content\": \"Delete user data\"}]},\n",
    "#     context=AuthContext(user_id=\"user_123\", permissions=[\"read\", \"write\"])\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ìš”ì²­ë³„ ì„¤ì •\n\nê° ìš”ì²­ì— ëŒ€í•œ íŠ¹ì • ì„¤ì •ì„ Contextë¥¼ í†µí•´ ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íƒ€ì„ì•„ì›ƒ, í† í° ì œí•œ, ë¡œê¹… ìˆ˜ì¤€ ë“± ìš”ì²­ë§ˆë‹¤ ë‹¤ë¥¸ ì„¤ì •ì´ í•„ìš”í•œ ê²½ìš° ìœ ìš©í•©ë‹ˆë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” ìš”ì²­ë³„ ì„¤ì •ì„ Contextë¡œ ì „ë‹¬í•˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RequestContext:\n",
    "    user_id: str\n",
    "    verbose: bool\n",
    "    timeout: int\n",
    "    max_tokens: int\n",
    "\n",
    "\n",
    "@tool\n",
    "def process_request(query: str, runtime: ToolRuntime[RequestContext]) -> str:\n",
    "    \"\"\"Process request with custom settings.\"\"\"\n",
    "    verbose = runtime.context.verbose\n",
    "    timeout = runtime.context.timeout\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Processing with timeout: {timeout}s\")\n",
    "\n",
    "    # ì„¤ì •ì— ë”°ë¼ ì²˜ë¦¬\n",
    "    return f\"Processed: {query}\"\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model, tools=[process_request], context_schema=RequestContext\n",
    ")\n",
    "\n",
    "# ìš”ì²­ë³„ë¡œ ë‹¤ë¥¸ ì„¤ì • ì‚¬ìš©\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Process my request\"}]},\n",
    "    context=RequestContext(\n",
    "        user_id=\"user_123\", verbose=True, timeout=30, max_tokens=1000\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## ì •ë¦¬\n\nì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” LangGraph ì—ì´ì „íŠ¸ì˜ Runtime ê¸°ëŠ¥ì„ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.\n\n**í•µì‹¬ ê°œë… ìš”ì•½:**\n\n| ê°œë… | ì„¤ëª… | ì ‘ê·¼ ë°©ë²• |\n|:---|:---|:---|\n| **Context** | ì‚¬ìš©ì ì •ë³´, ì„¸ì…˜ ë°ì´í„° ë“± ì •ì  ì •ë³´ | `runtime.context` |\n| **Store** | ëŒ€í™” ì„¸ì…˜ì„ ë„˜ì–´ì„  ì¥ê¸° ë©”ëª¨ë¦¬ | `runtime.store.get()`, `put()` |\n| **Stream Writer** | ì»¤ìŠ¤í…€ ì§„í–‰ ìƒí™© ìŠ¤íŠ¸ë¦¬ë° | `runtime.get_stream_writer()` |\n\n**ì‹¤ì „ íŒ¨í„´:**\n- ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ Contextë¡œ ì „ë‹¬í•˜ì—¬ ë„êµ¬ì—ì„œ ì§ì ‘ ì¿¼ë¦¬ ì‹¤í–‰\n- ë¯¸ë“¤ì›¨ì–´ì—ì„œ ì‚¬ìš©ì ê¶Œí•œ ê²€ì‚¬ë¡œ ë³´ì•ˆ ê°•í™”\n- ìš”ì²­ë³„ ì„¤ì •(íƒ€ì„ì•„ì›ƒ, í† í° ì œí•œ ë“±)ì„ Contextë¡œ ì „ë‹¬\n\n**ë‹¤ìŒ ë‹¨ê³„:**\n- êµ¬ì¡°í™”ëœ ì¶œë ¥(Structured Output)ì„ ì‚¬ìš©í•œ ì—ì´ì „íŠ¸ êµ¬ì¶• í•™ìŠµ",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}