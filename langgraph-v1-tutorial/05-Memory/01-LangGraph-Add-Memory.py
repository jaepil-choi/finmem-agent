# ---
# jupyter:
#   jupytext:
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
#       jupytext_version: 1.19.0
#   kernelspec:
#     display_name: Python 3
#     language: python
#     name: python3
# ---

# %% [markdown]
# # ğŸ§  LangGraph ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì™„ë²½ ê°€ì´ë“œ
#
# ## ğŸ“š ê°œìš”
#
# AI ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì§„ì •í•œ ê°€ì¹˜ë¥¼ ì œê³µí•˜ë ¤ë©´ **ë©”ëª¨ë¦¬(Memory)**ê°€ í•„ìˆ˜ì ì…ë‹ˆë‹¤. LangGraphëŠ” ë‘ ê°€ì§€ ê°•ë ¥í•œ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì„ ì œê³µí•©ë‹ˆë‹¤:
#
# 1. **ë‹¨ê¸° ë©”ëª¨ë¦¬(Short-term Memory)**: ëŒ€í™” ì„¸ì…˜ ë‚´ì—ì„œ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€
# 2. **ì¥ê¸° ë©”ëª¨ë¦¬(Long-term Memory)**: ì„¸ì…˜ì„ ë„˜ì–´ ì‚¬ìš©ìë³„ ì •ë³´ ì €ì¥
#
# ## ğŸ¯ í•™ìŠµ ëª©í‘œ
#
# ì´ íŠœí† ë¦¬ì–¼ì„ ì™„ë£Œí•˜ë©´ ë‹¤ìŒì„ ë§ˆìŠ¤í„°í•˜ê²Œ ë©ë‹ˆë‹¤:
#
# 1. **ë‹¨ê¸° ë©”ëª¨ë¦¬** êµ¬í˜„ - Checkpointerë¥¼ í™œìš©í•œ ëŒ€í™” ì§€ì†ì„±
# 2. **ì¥ê¸° ë©”ëª¨ë¦¬** êµ¬ì¶• - Storeë¥¼ í™œìš©í•œ ì˜êµ¬ ë°ì´í„° ì €ì¥
# 3. **ë©”ëª¨ë¦¬ ê´€ë¦¬** ì „ëµ - ë©”ì‹œì§€ íŠ¸ë¦¬ë°, ìš”ì•½, ì‚­ì œ
# 4. **ì‹œë§¨í‹± ê²€ìƒ‰** - ì„ë² ë”© ê¸°ë°˜ ë©”ëª¨ë¦¬ ê²€ìƒ‰
# 5. **í”„ë¡œë•ì…˜ ë°°í¬** - PostgreSQL, Redis ë“± ì‹¤ì œ í™˜ê²½ ì ìš©
#
# ## ğŸ”‘ í•µì‹¬ ê°œë… ë¯¸ë¦¬ë³´ê¸°
#
# ```
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚                  LangGraph Memory System                  â”‚
# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
# â”‚    Short-term Memory      â”‚      Long-term Memory         â”‚
# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
# â”‚ â€¢ Thread-level            â”‚ â€¢ User-level                  â”‚
# â”‚ â€¢ Checkpointer            â”‚ â€¢ Store                       â”‚
# â”‚ â€¢ Multi-turn chats        â”‚ â€¢ Persistent data             â”‚
# â”‚ â€¢ Session context         â”‚ â€¢ Cross-session               â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
# ```
#
# ## ğŸ’¡ ì¤‘ìš” ì›ì¹™
#
# > **"ë©”ëª¨ë¦¬ëŠ” AI ì—ì´ì „íŠ¸ë¥¼ ë‹¨ìˆœí•œ ë„êµ¬ì—ì„œ ì§€ëŠ¥ì ì¸ íŒŒíŠ¸ë„ˆë¡œ ë³€í™”ì‹œí‚µë‹ˆë‹¤"**
# > 
# > _Memory transforms AI agents from simple tools to intelligent partners_

# %% [markdown]
# ## í™˜ê²½ ì„¤ì •

# %%
# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„í¬íŠ¸
import os
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# API í‚¤ ì„¤ì •
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY", "your-api-key")

print("âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ!")

# %% [markdown]
# ---
#
# # Part 1: ë‹¨ê¸° ë©”ëª¨ë¦¬ (Short-term Memory) ğŸ¯
#
# ## 1.1 ë‹¨ê¸° ë©”ëª¨ë¦¬ë€?
#
# ë‹¨ê¸° ë©”ëª¨ë¦¬ëŠ” **ëŒ€í™” ì„¸ì…˜ ë‚´ì—ì„œ** ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ ì§€í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜ì…ë‹ˆë‹¤. ì´ëŠ” ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì§•ì„ ê°€ì§‘ë‹ˆë‹¤:
#
# - **Thread ê¸°ë°˜**: ê° ëŒ€í™”ëŠ” ê³ ìœ í•œ thread_idë¡œ ì‹ë³„
# - **Checkpointer ì‚¬ìš©**: ìƒíƒœë¥¼ ì €ì¥í•˜ê³  ë³µì›
# - **Multi-turn ëŒ€í™”**: ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µ
#
# ### í•µì‹¬ ì»´í¬ë„ŒíŠ¸: Checkpointer
#
# CheckpointerëŠ” ê·¸ë˜í”„ì˜ ìƒíƒœë¥¼ ì €ì¥í•˜ê³  ë³µì›í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ê°œë°œ í™˜ê²½ì—ì„œëŠ” `InMemorySaver`ë¥¼, í”„ë¡œë•ì…˜ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜ Checkpointerë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

# %%
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.graph import StateGraph, MessagesState, START, END
from langchain_openai import ChatOpenAI

# LLM ì´ˆê¸°í™”
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# Checkpointer ìƒì„± - ë©”ëª¨ë¦¬ì— ìƒíƒœë¥¼ ì €ì¥
checkpointer = InMemorySaver()


# ê°„ë‹¨í•œ ì±—ë´‡ ê·¸ë˜í”„ ìƒì„±
def call_model(state: MessagesState):
    """Call the LLM with the current messages"""
    # í˜„ì¬ ë©”ì‹œì§€ë¡œ LLM í˜¸ì¶œ
    response = llm.invoke(state["messages"])
    # ì‘ë‹µì„ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
    return {"messages": response}


# ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(MessagesState)
builder.add_node("call_model", call_model)
builder.add_edge(START, "call_model")
builder.add_edge("call_model", END)

# Checkpointerì™€ í•¨ê»˜ ì»´íŒŒì¼ - í•µì‹¬!
graph = builder.compile(checkpointer=checkpointer)

print("âœ… ë‹¨ê¸° ë©”ëª¨ë¦¬ê°€ í™œì„±í™”ëœ ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ!")

# %% [markdown]
# ## 1.2 ë‹¨ê¸° ë©”ëª¨ë¦¬ ì‹¤ìŠµ: Multi-turn ëŒ€í™”
#
# ì´ì œ ê°™ì€ threadì—ì„œ ì—¬ëŸ¬ ë²ˆ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ë©° ë´‡ì´ ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ëŠ”ì§€ í™•ì¸í•´ë´…ì‹œë‹¤.

# %%
# Thread ID ì„¤ì • - ëŒ€í™” ì„¸ì…˜ ì‹ë³„ì
config = {"configurable": {"thread_id": "conversation_1"}}  # ê³ ìœ í•œ ëŒ€í™” ì‹ë³„ì

# ì²« ë²ˆì§¸ ë©”ì‹œì§€ - ìê¸°ì†Œê°œ
print("ğŸ‘¤ User: ì•ˆë…•! ë‚˜ëŠ” ì² ìˆ˜ì•¼")
result = graph.invoke(
    {"messages": [{"role": "user", "content": "ì•ˆë…•! ë‚˜ëŠ” ì² ìˆ˜ì•¼"}]},
    config,  # thread_id ì „ë‹¬
)
print(f"ğŸ¤– Bot: {result['messages'][-1].content}\n")

# ë‘ ë²ˆì§¸ ë©”ì‹œì§€ - ì´ë¦„ í™•ì¸
print("ğŸ‘¤ User: ë‚´ ì´ë¦„ì´ ë­ë¼ê³  í–ˆì§€?")
result = graph.invoke(
    {"messages": [{"role": "user", "content": "ë‚´ ì´ë¦„ì´ ë­ë¼ê³  í–ˆì§€?"}]},
    config,  # ê°™ì€ thread_id ì‚¬ìš©
)
print(f"ğŸ¤– Bot: {result['messages'][-1].content}\n")

# ë‹¤ë¥¸ threadë¡œ í…ŒìŠ¤íŠ¸ - ë©”ëª¨ë¦¬ ë¶„ë¦¬ í™•ì¸
config_2 = {"configurable": {"thread_id": "conversation_2"}}

print("--- ìƒˆë¡œìš´ ëŒ€í™” ì„¸ì…˜ ---")
print("ğŸ‘¤ User: ë‚´ ì´ë¦„ì´ ë­ì•¼?")
result = graph.invoke(
    {"messages": [{"role": "user", "content": "ë‚´ ì´ë¦„ì´ ë­ì•¼?"}]},
    config_2,  # ë‹¤ë¥¸ thread_id
)
print(f"ğŸ¤– Bot: {result['messages'][-1].content}")
print("\nğŸ’¡ ë‹¤ë¥¸ threadì—ì„œëŠ” ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ì§€ ëª»í•©ë‹ˆë‹¤!")

# %% [markdown]
# ## 1.3 í”„ë¡œë•ì…˜ í™˜ê²½: PostgreSQL Checkpointer
#
# ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜ Checkpointerë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” PostgreSQL ì˜ˆì œë¥¼ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤.

# %%
# PostgreSQL Checkpointer ì˜ˆì œ (ì‹¤ì œ ì‹¤í–‰ ì‹œ DB ì—°ê²° í•„ìš”)
from typing import Dict, Any


def create_production_graph():
    """Create a production-ready graph with PostgreSQL checkpointer"""

    # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ê³  ì‚¬ìš©
    from langgraph.checkpoint.postgres import PostgresSaver

    DB_URI = "postgresql://postgres:postgres@localhost:5432/mydb"

    with PostgresSaver.from_conn_string(DB_URI) as checkpointer:
        # ì²« ì‹¤í–‰ ì‹œ í…Œì´ë¸” ìƒì„±
        # checkpointer.setup()

        builder = StateGraph(MessagesState)
        builder.add_node("call_model", call_model)
        builder.add_edge(START, "call_model")
        builder.add_edge("call_model", END)

        graph = builder.compile(checkpointer=checkpointer)
        return graph

    print("ğŸ“ í”„ë¡œë•ì…˜ í™˜ê²½ ì½”ë“œ ì˜ˆì œ:")
    print(
        """
    DB_URI = "postgresql://user:pass@host:port/db"
    
    with PostgresSaver.from_conn_string(DB_URI) as checkpointer:
        graph = builder.compile(checkpointer=checkpointer)
    """
    )
    return None


create_production_graph()

# %% [markdown]
# ## 1.4 Subgraphì—ì„œì˜ ë©”ëª¨ë¦¬
#
# ì„œë¸Œê·¸ë˜í”„ë¥¼ ì‚¬ìš©í•  ë•ŒëŠ” ë¶€ëª¨ ê·¸ë˜í”„ì—ë§Œ Checkpointerë¥¼ ì„¤ì •í•˜ë©´ ìë™ìœ¼ë¡œ ì „íŒŒë©ë‹ˆë‹¤.

# %%
from typing_extensions import TypedDict


class SubgraphState(TypedDict):
    """State for subgraph example"""

    message: str
    counter: int


# ì„œë¸Œê·¸ë˜í”„ ìƒì„±
def create_subgraph():
    """Create a subgraph"""

    def subgraph_node(state: SubgraphState):
        # ì¹´ìš´í„° ì¦ê°€
        return {
            "message": state["message"] + " (ì„œë¸Œê·¸ë˜í”„ ì²˜ë¦¬)",
            "counter": state["counter"] + 1,
        }

    subgraph_builder = StateGraph(SubgraphState)
    subgraph_builder.add_node("process", subgraph_node)
    subgraph_builder.add_edge(START, "process")
    subgraph_builder.add_edge("process", END)

    # ì„œë¸Œê·¸ë˜í”„ëŠ” checkpointer ì—†ì´ ì»´íŒŒì¼
    return subgraph_builder.compile()


# ë¶€ëª¨ ê·¸ë˜í”„ ìƒì„±
def main_node(state: SubgraphState):
    """Main graph node"""
    return {
        "message": state["message"] + " (ë©”ì¸ ì²˜ë¦¬)",
        "counter": state["counter"] + 10,
    }


# ì„œë¸Œê·¸ë˜í”„ ìƒì„±
subgraph = create_subgraph()

# ë©”ì¸ ê·¸ë˜í”„ êµ¬ì„±
main_builder = StateGraph(SubgraphState)
main_builder.add_node("main", main_node)
main_builder.add_node("subgraph", subgraph)  # ì„œë¸Œê·¸ë˜í”„ë¥¼ ë…¸ë“œë¡œ ì¶”ê°€

main_builder.add_edge(START, "main")
main_builder.add_edge("main", "subgraph")
main_builder.add_edge("subgraph", END)

# ë¶€ëª¨ ê·¸ë˜í”„ë§Œ checkpointerì™€ í•¨ê»˜ ì»´íŒŒì¼
parent_checkpointer = InMemorySaver()
parent_graph = main_builder.compile(checkpointer=parent_checkpointer)

# ì‹¤í–‰
result = parent_graph.invoke(
    {"message": "ì‹œì‘", "counter": 0}, {"configurable": {"thread_id": "sub_test"}}
)

print(f"âœ… ì„œë¸Œê·¸ë˜í”„ ì‹¤í–‰ ê²°ê³¼:")
print(f"  ë©”ì‹œì§€: {result['message']}")
print(f"  ì¹´ìš´í„°: {result['counter']}")
print("\nğŸ’¡ ë¶€ëª¨ ê·¸ë˜í”„ì˜ checkpointerê°€ ì„œë¸Œê·¸ë˜í”„ì—ë„ ìë™ ì ìš©ë©ë‹ˆë‹¤!")

# %% [markdown]
# ---
#
# # Part 2: ì¥ê¸° ë©”ëª¨ë¦¬ (Long-term Memory) ğŸ’¾
#
# ## 2.1 ì¥ê¸° ë©”ëª¨ë¦¬ë€?
#
# ì¥ê¸° ë©”ëª¨ë¦¬ëŠ” **ì„¸ì…˜ì„ ë„˜ì–´ì„œ** ì‚¬ìš©ìë³„ ë˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ì˜ ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤:
#
# - **ì‚¬ìš©ì í”„ë¡œí•„**: ì„ í˜¸ë„, ì„¤ì •, ê°œì¸ ì •ë³´
# - **ëŒ€í™” íˆìŠ¤í† ë¦¬**: ê³¼ê±° ìƒí˜¸ì‘ìš© ê¸°ë¡
# - **í•™ìŠµëœ ì •ë³´**: ì‹œìŠ¤í…œì´ ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ í•™ìŠµí•œ ë‚´ìš©
#
# ### í•µì‹¬ ì»´í¬ë„ŒíŠ¸: Store
#
# StoreëŠ” key-value í˜•ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì˜êµ¬ ì €ì¥í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

# %%
from langgraph.store.memory import InMemoryStore
from langchain_core.runnables import RunnableConfig
from langgraph.store.base import BaseStore
import uuid

# ë©”ëª¨ë¦¬ ìŠ¤í† ì–´ ìƒì„±
store = InMemoryStore()


# ì‚¬ìš©ì ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” ê·¸ë˜í”„
class UserState(MessagesState):
    """State with user context"""

    user_id: str


def chat_with_memory(
    state: UserState, config: RunnableConfig, *, store: BaseStore  # store ì£¼ì…
):
    """Chat function with long-term memory"""

    # ì‚¬ìš©ì ID ê°€ì ¸ì˜¤ê¸°
    user_id = config["configurable"].get("user_id", "default_user")

    # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì •ì˜ - ì‚¬ìš©ìë³„ ë©”ëª¨ë¦¬ ë¶„ë¦¬
    namespace = ("users", user_id)

    # ë§ˆì§€ë§‰ ë©”ì‹œì§€ í™•ì¸
    last_message = state["messages"][-1]

    # "ê¸°ì–µí•´" í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì €ì¥
    if "ê¸°ì–µí•´" in last_message.content:
        # ë©”ëª¨ë¦¬ì— ì €ì¥í•  ë‚´ìš© ì¶”ì¶œ
        memory_content = last_message.content.replace("ê¸°ì–µí•´:", "").strip()
        # Storeì— ì €ì¥
        store.put(namespace, str(uuid.uuid4()), {"memory": memory_content})

        return {
            "messages": [
                {
                    "role": "assistant",
                    "content": f"ì•Œê² ìŠµë‹ˆë‹¤. '{memory_content}'ë¥¼ ê¸°ì–µí•˜ê² ìŠµë‹ˆë‹¤.",
                }
            ]
        }

    # "ë­ ê¸°ì–µí•˜ê³  ìˆì–´?" í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì¡°íšŒ
    elif "ë­ ê¸°ì–µí•˜ê³  ìˆì–´" in last_message.content:
        # ì €ì¥ëœ ë©”ëª¨ë¦¬ ê²€ìƒ‰
        memories = store.search(namespace, query="*")  # ëª¨ë“  ë©”ëª¨ë¦¬ ì¡°íšŒ

        if memories:
            memory_list = [item.value["memory"] for item in memories]
            response = "ì œê°€ ê¸°ì–µí•˜ê³  ìˆëŠ” ë‚´ìš©:\n" + "\n".join(
                f"â€¢ {m}" for m in memory_list
            )
        else:
            response = "ì•„ì§ ê¸°ì–µí•˜ê³  ìˆëŠ” ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."

        return {"messages": [{"role": "assistant", "content": response}]}

    # ì¼ë°˜ ëŒ€í™”
    else:
        # ê¸°ì¡´ ë©”ëª¨ë¦¬ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
        memories = store.search(namespace, query="*")
        context = ""
        if memories:
            context = "\n".join([item.value["memory"] for item in memories])
            system_prompt = f"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì— ëŒ€í•´ ì•Œê³  ìˆëŠ” ì •ë³´: {context}"
        else:
            system_prompt = "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."

        # LLM í˜¸ì¶œ
        messages = [{"role": "system", "content": system_prompt}] + state["messages"]
        response = llm.invoke(messages)

        return {"messages": response}


# ê·¸ë˜í”„ êµ¬ì„±
memory_builder = StateGraph(UserState)
memory_builder.add_node("chat", chat_with_memory)
memory_builder.add_edge(START, "chat")
memory_builder.add_edge("chat", END)

# Storeì™€ Checkpointer ëª¨ë‘ ì‚¬ìš©
memory_graph = memory_builder.compile(
    checkpointer=InMemorySaver(), store=store  # ë‹¨ê¸° ë©”ëª¨ë¦¬  # ì¥ê¸° ë©”ëª¨ë¦¬
)

print("âœ… ì¥ê¸° ë©”ëª¨ë¦¬ê°€ í™œì„±í™”ëœ ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ!")

# %% [markdown]
# ## 2.2 ì¥ê¸° ë©”ëª¨ë¦¬ ì‹¤ìŠµ: ì„¸ì…˜ ê°„ ì •ë³´ ìœ ì§€

# %%
# ì²« ë²ˆì§¸ ì„¸ì…˜ - ì •ë³´ ì €ì¥
config_session1 = {"configurable": {"thread_id": "session_1", "user_id": "user_123"}}

print("=== ì„¸ì…˜ 1: ì •ë³´ ì €ì¥ ===")
print("\nğŸ‘¤ User: ê¸°ì–µí•´: ë‚´ ì´ë¦„ì€ ê¹€ì² ìˆ˜ì´ê³  ê°œë°œìì•¼")
result = memory_graph.invoke(
    {
        "messages": [
            {"role": "user", "content": "ê¸°ì–µí•´: ë‚´ ì´ë¦„ì€ ê¹€ì² ìˆ˜ì´ê³  ê°œë°œìì•¼"}
        ]
    },
    config_session1,
)
print(f"ğŸ¤– Bot: {result['messages'][-1].content}")

print("\nğŸ‘¤ User: ê¸°ì–µí•´: ë‚˜ëŠ” íŒŒì´ì¬ì„ ì¢‹ì•„í•´")
result = memory_graph.invoke(
    {"messages": [{"role": "user", "content": "ê¸°ì–µí•´: ë‚˜ëŠ” íŒŒì´ì¬ì„ ì¢‹ì•„í•´"}]},
    config_session1,
)
print(f"ğŸ¤– Bot: {result['messages'][-1].content}")

# ë‘ ë²ˆì§¸ ì„¸ì…˜ - ë‹¤ë¥¸ thread_idì§€ë§Œ ê°™ì€ user_id
config_session2 = {
    "configurable": {
        "thread_id": "session_2",  # ë‹¤ë¥¸ ì„¸ì…˜
        "user_id": "user_123",  # ê°™ì€ ì‚¬ìš©ì
    }
}

print("\n=== ì„¸ì…˜ 2: ìƒˆë¡œìš´ ëŒ€í™” (ë‹¤ë¥¸ thread_id) ===")
print("\nğŸ‘¤ User: ë­ ê¸°ì–µí•˜ê³  ìˆì–´?")
result = memory_graph.invoke(
    {"messages": [{"role": "user", "content": "ë­ ê¸°ì–µí•˜ê³  ìˆì–´?"}]}, config_session2
)
print(f"ğŸ¤– Bot: {result['messages'][-1].content}")

print("\nğŸ’¡ ë‹¤ë¥¸ ì„¸ì…˜ì—ì„œë„ ì‚¬ìš©ì ì •ë³´ë¥¼ ê¸°ì–µí•©ë‹ˆë‹¤!")

# %% [markdown]
# ## 2.3 Toolì—ì„œ ë©”ëª¨ë¦¬ ì ‘ê·¼
#
# ì—ì´ì „íŠ¸ì˜ ë„êµ¬(Tool)ì—ì„œë„ ë©”ëª¨ë¦¬ì— ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

# %%
from typing import Annotated
from langgraph.prebuilt import InjectedState
from langchain_core.tools import tool


# Toolì—ì„œ State ì ‘ê·¼ ì˜ˆì œ
class AgentState(MessagesState):
    """State for agent with tools"""

    user_preference: str


@tool
def get_user_preference(
    state: Annotated[AgentState, InjectedState],  # State ì£¼ì…
) -> str:
    """Get user preference from state"""
    preference = state.get("user_preference", "ì—†ìŒ")
    return f"ì‚¬ìš©ì ì„ í˜¸ë„: {preference}"


@tool
def update_user_preference(
    new_preference: str, state: Annotated[AgentState, InjectedState]
) -> str:
    """Update user preference in state"""
    # Toolì—ì„œ state ì—…ë°ì´íŠ¸ëŠ” Commandë¥¼ í†µí•´ ìˆ˜í–‰
    return f"ì„ í˜¸ë„ë¥¼ '{new_preference}'ë¡œ ì—…ë°ì´íŠ¸í–ˆìŠµë‹ˆë‹¤."


# ë„êµ¬ ì‚¬ìš© ì˜ˆì œ
def agent_with_tools(state: AgentState):
    """Agent that can use tools"""
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì˜ˆì œë§Œ ë³´ì—¬ì¤Œ
    last_message = state["messages"][-1].content

    if "ì„ í˜¸ë„" in last_message:
        # Tool í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜
        tool_result = get_user_preference.invoke({"state": state})
        return {"messages": [{"role": "assistant", "content": tool_result}]}

    return {"messages": [{"role": "assistant", "content": "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"}]}


print("âœ… Toolì—ì„œ ë©”ëª¨ë¦¬ ì ‘ê·¼ íŒ¨í„´ ì •ì˜ ì™„ë£Œ!")
print("\nğŸ’¡ InjectedStateë¥¼ ì‚¬ìš©í•˜ì—¬ Toolì—ì„œ stateì— ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# %% [markdown]
# ---
#
# # Part 3: ë©”ëª¨ë¦¬ ê´€ë¦¬ ì „ëµ ğŸ”§
#
# ## 3.1 ë©”ì‹œì§€ íŠ¸ë¦¬ë° (Trimming)
#
# ê¸´ ëŒ€í™”ì—ì„œ LLMì˜ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ì œí•œì„ ê´€ë¦¬í•˜ê¸° ìœ„í•´ ë©”ì‹œì§€ë¥¼ íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.

# %%
from langchain_core.messages import trim_messages, HumanMessage, AIMessage


# ë©”ì‹œì§€ íŠ¸ë¦¬ë° ì˜ˆì œ
def demonstrate_trimming():
    """Demonstrate message trimming strategies"""

    # ê¸´ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì‹œë®¬ë ˆì´ì…˜
    messages = [
        HumanMessage(content="ì•ˆë…•í•˜ì„¸ìš”"),
        AIMessage(content="ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"),
        HumanMessage(content="ë‚ ì”¨ê°€ ì–´ë•Œìš”?"),
        AIMessage(content="ì˜¤ëŠ˜ì€ ë§‘ì€ ë‚ ì”¨ì…ë‹ˆë‹¤."),
        HumanMessage(content="ì¶”ì²œ ìŒì‹ì´ ìˆë‚˜ìš”?"),
        AIMessage(content="íŒŒìŠ¤íƒ€ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤."),
        HumanMessage(content="ë ˆì‹œí”¼ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”"),
        AIMessage(content="í† ë§ˆí†  íŒŒìŠ¤íƒ€ ë ˆì‹œí”¼ì…ë‹ˆë‹¤..."),
        HumanMessage(content="ê°ì‚¬í•©ë‹ˆë‹¤"),
        AIMessage(content="ì²œë§Œì—ìš”!"),
    ]

    print(f"ì›ë³¸ ë©”ì‹œì§€ ìˆ˜: {len(messages)}\n")

    # ì „ëµ 1: ìµœê·¼ Nê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€
    trimmed_last = trim_messages(
        messages,
        strategy="last",
        max_tokens=100,  # ëŒ€ëµ 100 í† í°ë§Œ ìœ ì§€
        start_on="human",  # ì‚¬ëŒ ë©”ì‹œì§€ë¡œ ì‹œì‘
        end_on=("human", "ai"),  # ì‚¬ëŒ ë˜ëŠ” AI ë©”ì‹œì§€ë¡œ ë
    )

    print("ì „ëµ 1 - ìµœê·¼ ë©”ì‹œì§€ ìœ ì§€:")
    for msg in trimmed_last:
        role = "User" if isinstance(msg, HumanMessage) else "Bot"
        print(f"  {role}: {msg.content[:30]}...")

    # ì „ëµ 2: ì²« ë©”ì‹œì§€ì™€ ìµœê·¼ ë©”ì‹œì§€ ìœ ì§€
    trimmed_mixed = trim_messages(
        messages,
        strategy="first",
        max_tokens=100,
        include_system=False,
    )

    print("\nì „ëµ 2 - ì²« ë©”ì‹œì§€ ìœ ì§€:")
    for msg in trimmed_mixed:
        role = "User" if isinstance(msg, HumanMessage) else "Bot"
        print(f"  {role}: {msg.content[:30]}...")

    return trimmed_last


trimmed = demonstrate_trimming()
print(f"\nâœ… íŠ¸ë¦¬ë° í›„ ë©”ì‹œì§€ ìˆ˜: {len(trimmed)}")


# %%
# ê·¸ë˜í”„ì—ì„œ íŠ¸ë¦¬ë° ì ìš©
class TrimmedState(MessagesState):
    """State with message trimming"""

    pass


def call_model_with_trimming(state: TrimmedState):
    """Call model with automatic message trimming"""

    # ë©”ì‹œì§€ íŠ¸ë¦¬ë° - ìµœëŒ€ 500 í† í°ë§Œ ìœ ì§€
    trimmed_messages = trim_messages(
        state["messages"],
        strategy="last",
        max_tokens=500,
        start_on="human",
        end_on=("human", "ai"),
        include_system=True,  # ì‹œìŠ¤í…œ ë©”ì‹œì§€ í¬í•¨
    )

    # íŠ¸ë¦¬ë°ëœ ë©”ì‹œì§€ë¡œ LLM í˜¸ì¶œ
    response = llm.invoke(trimmed_messages)

    return {"messages": [response]}


# íŠ¸ë¦¬ë°ì´ ì ìš©ëœ ê·¸ë˜í”„ ìƒì„±
trimming_builder = StateGraph(TrimmedState)
trimming_builder.add_node("chat", call_model_with_trimming)
trimming_builder.add_edge(START, "chat")
trimming_builder.add_edge("chat", END)

trimming_graph = trimming_builder.compile(checkpointer=InMemorySaver())

print("âœ… ìë™ íŠ¸ë¦¬ë°ì´ ì ìš©ëœ ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ!")
print("\nğŸ’¡ ê¸´ ëŒ€í™”ì—ì„œë„ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ì œí•œì„ ìë™ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.")

# %% [markdown]
# ## 3.2 ë©”ì‹œì§€ ì‚­ì œ (Deletion)
#
# íŠ¹ì • ë©”ì‹œì§€ë¥¼ ì˜êµ¬ì ìœ¼ë¡œ ì‚­ì œí•˜ì—¬ ë©”ëª¨ë¦¬ë¥¼ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

# %%
from langchain_core.messages import RemoveMessage


class DeletionState(MessagesState):
    """State for message deletion example"""

    pass


def delete_old_messages(state: DeletionState):
    """Delete messages older than threshold"""
    messages = state["messages"]

    # 5ê°œ ì´ìƒì˜ ë©”ì‹œì§€ê°€ ìˆìœ¼ë©´ ì˜¤ë˜ëœ ë©”ì‹œì§€ ì‚­ì œ
    if len(messages) > 5:
        # ì²˜ìŒ 2ê°œ ë©”ì‹œì§€ ì‚­ì œ
        messages_to_delete = [RemoveMessage(id=msg.id) for msg in messages[:2]]
        return {"messages": messages_to_delete}

    return {}


def chat_and_cleanup(state: DeletionState):
    """Chat with automatic cleanup"""
    # ë¨¼ì € ì˜¤ë˜ëœ ë©”ì‹œì§€ ì •ë¦¬
    cleanup_result = delete_old_messages(state)

    # LLM í˜¸ì¶œ
    response = llm.invoke(state["messages"])

    # ì‘ë‹µê³¼ ì •ë¦¬ ê²°ê³¼ ë³‘í•©
    messages_update = [response]
    if "messages" in cleanup_result:
        messages_update = cleanup_result["messages"] + messages_update

    return {"messages": messages_update}


# ì‚­ì œ ë¡œì§ì´ í¬í•¨ëœ ê·¸ë˜í”„
deletion_builder = StateGraph(DeletionState)
deletion_builder.add_node("chat", chat_and_cleanup)
deletion_builder.add_edge(START, "chat")
deletion_builder.add_edge("chat", END)

deletion_graph = deletion_builder.compile(checkpointer=InMemorySaver())

print("âœ… ìë™ ë©”ì‹œì§€ ì‚­ì œê°€ ì ìš©ëœ ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ!")
print("\nğŸ’¡ ì˜¤ë˜ëœ ë©”ì‹œì§€ë¥¼ ìë™ìœ¼ë¡œ ì‚­ì œí•˜ì—¬ ë©”ëª¨ë¦¬ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.")

# %% [markdown]
# ## 3.3 ë©”ì‹œì§€ ìš”ì•½ (Summarization)
#
# ì˜¤ë˜ëœ ë©”ì‹œì§€ë¥¼ ìš”ì•½í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì••ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

# %%
from langchain_core.messages import SystemMessage


class SummarizationState(MessagesState):
    """State with summarization support"""

    summary: str = ""  # ëŒ€í™” ìš”ì•½ ì €ì¥


def summarize_conversation(messages: list) -> str:
    """Summarize a list of messages"""
    # ìš”ì•½ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
    summary_prompt = """
    Please summarize the following conversation in 2-3 sentences,
    focusing on key information and context:
    
    {conversation}
    """

    # ëŒ€í™” ë‚´ìš© í¬ë§·íŒ…
    conversation = "\n".join([f"{msg.type}: {msg.content}" for msg in messages])

    # LLMìœ¼ë¡œ ìš”ì•½ ìƒì„± (ì‹¤ì œë¡œëŠ” ë³„ë„ì˜ ìš”ì•½ ëª¨ë¸ ì‚¬ìš© ê¶Œì¥)
    summary_response = llm.invoke(
        [
            {
                "role": "system",
                "content": summary_prompt.format(conversation=conversation),
            }
        ]
    )

    return summary_response.content


def chat_with_summarization(state: SummarizationState):
    """Chat with automatic summarization"""
    messages = state["messages"]

    # 10ê°œ ì´ìƒì˜ ë©”ì‹œì§€ê°€ ìˆìœ¼ë©´ ìš”ì•½
    if len(messages) > 10:
        # ì²˜ìŒ 5ê°œ ë©”ì‹œì§€ ìš”ì•½
        messages_to_summarize = messages[:5]
        summary = summarize_conversation(messages_to_summarize)

        # ìš”ì•½ì„ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ ì¶”ê°€í•˜ê³  ì˜¤ë˜ëœ ë©”ì‹œì§€ ì‚­ì œ
        new_messages = [
            SystemMessage(content=f"Previous conversation summary: {summary}")
        ] + messages[
            5:
        ]  # ìš”ì•½ëœ ë©”ì‹œì§€ëŠ” ì œê±°

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        return {"messages": new_messages, "summary": summary}

    # ì¼ë°˜ ì‘ë‹µ
    response = llm.invoke(messages)
    return {"messages": [response]}


print("âœ… ëŒ€í™” ìš”ì•½ ê¸°ëŠ¥ êµ¬í˜„ ì™„ë£Œ!")
print("\nğŸ’¡ ê¸´ ëŒ€í™”ë¥¼ ìë™ìœ¼ë¡œ ìš”ì•½í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.")

# %% [markdown]
# ---
#
# # Part 4: ì‹œë§¨í‹± ê²€ìƒ‰ (Semantic Search) ğŸ”
#
# ## 4.1 ì„ë² ë”© ê¸°ë°˜ ë©”ëª¨ë¦¬ ê²€ìƒ‰
#
# Storeì— ì‹œë§¨í‹± ê²€ìƒ‰ì„ í™œì„±í™”í•˜ë©´ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë©”ëª¨ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

# %%
from langchain_openai import OpenAIEmbeddings

# ì‹œë§¨í‹± ê²€ìƒ‰ì´ í™œì„±í™”ëœ Store ìƒì„±
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

semantic_store = InMemoryStore(
    index={
        "embed": embeddings,  # ì„ë² ë”© ëª¨ë¸
        "dims": 1536,  # ì„ë² ë”© ì°¨ì›
    }
)

# ë©”ëª¨ë¦¬ ì €ì¥
user_namespace = ("user_456", "memories")

# ë‹¤ì–‘í•œ ë©”ëª¨ë¦¬ ì €ì¥
memories_to_store = [
    {"id": "1", "text": "ë‚˜ëŠ” í”¼ìë¥¼ ì¢‹ì•„í•´"},
    {"id": "2", "text": "ë‚´ ì§ì—…ì€ ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ì•¼"},
    {"id": "3", "text": "íŒŒì´ì¬ê³¼ ë¨¸ì‹ ëŸ¬ë‹ì„ ì£¼ë¡œ ë‹¤ë¤„"},
    {"id": "4", "text": "ì£¼ë§ì—ëŠ” ë“±ì‚°ì„ ì¦ê²¨í•´"},
    {"id": "5", "text": "ì»¤í”¼ë³´ë‹¤ ì°¨ë¥¼ ì„ í˜¸í•´"},
]

for memory in memories_to_store:
    semantic_store.put(user_namespace, memory["id"], {"text": memory["text"]})

print("âœ… ì‹œë§¨í‹± ë©”ëª¨ë¦¬ ì €ì¥ ì™„ë£Œ!\n")

# ì‹œë§¨í‹± ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
queries = ["ìŒì‹ ì·¨í–¥", "í”„ë¡œê·¸ë˜ë°", "ì—¬ê°€ í™œë™"]

print("ğŸ” ì‹œë§¨í‹± ê²€ìƒ‰ ê²°ê³¼:\n")
for query in queries:
    # ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ë©”ëª¨ë¦¬ ê²€ìƒ‰
    results = semantic_store.search(
        user_namespace, query=query, limit=2  # ìƒìœ„ 2ê°œ ê²°ê³¼
    )

    print(f"Query: '{query}'")
    for item in results:
        print(f"  â†’ {item.value['text']}")
    print()


# %% [markdown]
# ## 4.2 ì‹œë§¨í‹± ë©”ëª¨ë¦¬ë¥¼ í™œìš©í•œ ëŒ€í™” ì‹œìŠ¤í…œ

# %%
def chat_with_semantic_memory(state: MessagesState, *, store: BaseStore):
    """Chat function with semantic memory search"""

    # ì‚¬ìš©ìì˜ ë§ˆì§€ë§‰ ë©”ì‹œì§€
    user_message = state["messages"][-1].content

    # ê´€ë ¨ ë©”ëª¨ë¦¬ ê²€ìƒ‰
    namespace = ("user_456", "memories")
    relevant_memories = store.search(namespace, query=user_message, limit=3)

    # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context = ""
    if relevant_memories:
        context = "ì‚¬ìš©ìì— ëŒ€í•œ ê´€ë ¨ ì •ë³´:\n"
        context += "\n".join([f"â€¢ {item.value['text']}" for item in relevant_memories])

    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_prompt = f"""
    You are a helpful assistant with access to user's personal information.
    Use the following context to provide personalized responses:
    
    {context}
    
    Respond naturally and incorporate relevant information when appropriate.
    """

    # LLM í˜¸ì¶œ
    messages = [{"role": "system", "content": system_prompt}] + state["messages"]

    response = llm.invoke(messages)

    return {"messages": [response]}


# ì‹œë§¨í‹± ë©”ëª¨ë¦¬ ê·¸ë˜í”„ ìƒì„±
semantic_builder = StateGraph(MessagesState)
semantic_builder.add_node("chat", chat_with_semantic_memory)
semantic_builder.add_edge(START, "chat")
semantic_builder.add_edge("chat", END)

semantic_graph = semantic_builder.compile(store=semantic_store)

# í…ŒìŠ¤íŠ¸
print("ğŸ’¬ ì‹œë§¨í‹± ë©”ëª¨ë¦¬ ê¸°ë°˜ ëŒ€í™” í…ŒìŠ¤íŠ¸:\n")

test_messages = [
    "ì˜¤ëŠ˜ ì ì‹¬ ë­ ë¨¹ì„ê¹Œ?",
    "ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ë¥¼ ì‹œì‘í•˜ë ¤ê³  í•˜ëŠ”ë° ì¡°ì–¸ ì¢€ í•´ì¤˜",
    "ì£¼ë§ ê³„íšì´ ìˆì–´?",
]

for msg in test_messages:
    print(f"ğŸ‘¤ User: {msg}")
    result = semantic_graph.invoke({"messages": [{"role": "user", "content": msg}]})
    print(f"ğŸ¤– Bot: {result['messages'][-1].content}\n")

# %% [markdown]
# ---
#
# # Part 5: í”„ë¡œë•ì…˜ ë°°í¬ ğŸš€
#
# ## 5.1 ë°ì´í„°ë² ì´ìŠ¤ Checkpointer ë¹„êµ

# %%
# í”„ë¡œë•ì…˜ Checkpointer ì˜µì…˜
production_options = {
    "PostgreSQL": {
        "package": "langgraph-checkpoint-postgres",
        "class": "PostgresSaver",
        "connection": "postgresql://user:pass@host:port/db",
        "features": ["ACID ì¤€ìˆ˜", "ë³µì¡í•œ ì¿¼ë¦¬ ì§€ì›", "ì—”í„°í”„ë¼ì´ì¦ˆ í‘œì¤€"],
        "setup": "checkpointer.setup()  # ì²« ì‹¤í–‰ ì‹œ",
    },
    "MongoDB": {
        "package": "langgraph-checkpoint-mongodb",
        "class": "MongoDBSaver",
        "connection": "mongodb://localhost:27017",
        "features": ["NoSQL ìœ ì—°ì„±", "ìˆ˜í‰ í™•ì¥ì„±", "JSON ë„¤ì´í‹°ë¸Œ"],
        "setup": "í´ëŸ¬ìŠ¤í„° ìƒì„± í•„ìš”",
    },
    "Redis": {
        "package": "langgraph-checkpoint-redis",
        "class": "RedisSaver",
        "connection": "redis://localhost:6379",
        "features": ["ì´ˆê³ ì† ë©”ëª¨ë¦¬ DB", "ìºì‹± ìµœì í™”", "Pub/Sub ì§€ì›"],
        "setup": "checkpointer.setup()  # ì²« ì‹¤í–‰ ì‹œ",
    },
}

print("ğŸ“Š í”„ë¡œë•ì…˜ Checkpointer ë¹„êµ:\n")
for db, info in production_options.items():
    print(f"### {db}")
    print(f"  íŒ¨í‚¤ì§€: {info['package']}")
    print(f"  í´ë˜ìŠ¤: {info['class']}")
    print(f"  ì—°ê²°: {info['connection']}")
    print(f"  íŠ¹ì§•: {', '.join(info['features'])}")
    print(f"  ì„¤ì •: {info['setup']}\n")


# %% [markdown]
# ## 5.2 í”„ë¡œë•ì…˜ Store êµ¬í˜„ ì˜ˆì œ

# %%
def create_production_setup():
    """Production setup example with both checkpointer and store"""

    print("ğŸ­ í”„ë¡œë•ì…˜ í™˜ê²½ ì„¤ì • ì˜ˆì œ:\n")

    # PostgreSQL ì˜ˆì œ
    postgres_example = """
from langgraph.checkpoint.postgres import PostgresSaver
from langgraph.store.postgres import PostgresStore

DB_URI = "postgresql://user:password@localhost:5432/langgraph_db"

# Context managerë¡œ ìë™ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬
with (
    PostgresStore.from_conn_string(DB_URI) as store,
    PostgresSaver.from_conn_string(DB_URI) as checkpointer,
):
    # ì²« ì‹¤í–‰ ì‹œ í…Œì´ë¸” ìƒì„±
    store.setup()
    checkpointer.setup()
    
    # ê·¸ë˜í”„ ì»´íŒŒì¼
    graph = builder.compile(
        checkpointer=checkpointer,  # ë‹¨ê¸° ë©”ëª¨ë¦¬
        store=store  # ì¥ê¸° ë©”ëª¨ë¦¬
    )
    
    # ê·¸ë˜í”„ ì‹¤í–‰
    result = graph.invoke(input_data, config)
    """

    print("### PostgreSQL ì„¤ì •:")
    print(postgres_example)

    # Redis ì˜ˆì œ
    redis_example = """
from langgraph.checkpoint.redis import RedisSaver
from langgraph.store.redis import RedisStore

REDIS_URI = "redis://localhost:6379"

# Redis ì—°ê²°
with (
    RedisStore.from_conn_string(REDIS_URI) as store,
    RedisSaver.from_conn_string(REDIS_URI) as checkpointer,
):
    store.setup()
    checkpointer.setup()
    
    graph = builder.compile(
        checkpointer=checkpointer,
        store=store
    )
    """

    print("\n### Redis ì„¤ì •:")
    print(redis_example)

    return "í”„ë¡œë•ì…˜ ì„¤ì • ì˜ˆì œ ì™„ë£Œ"


create_production_setup()

# %% [markdown]
# ## 5.3 ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

# %%
# ë©”ëª¨ë¦¬ ê´€ë¦¬ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤
best_practices = {
    "ì•„í‚¤í…ì²˜ ì„¤ê³„": [
        "ë‹¨ê¸°/ì¥ê¸° ë©”ëª¨ë¦¬ ëª…í™•íˆ êµ¬ë¶„",
        "ì ì ˆí•œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì „ëµ ìˆ˜ë¦½",
        "ë©”ëª¨ë¦¬ ê³„ì¸µ êµ¬ì¡° ì„¤ê³„",
    ],
    "ì„±ëŠ¥ ìµœì í™”": [
        "ë©”ì‹œì§€ íŠ¸ë¦¬ë°ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬",
        "ìºì‹± ì ê·¹ í™œìš©",
        "ì¸ë±ì‹±ìœ¼ë¡œ ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒ",
    ],
    "ë°ì´í„° ê´€ë¦¬": ["ì •ê¸°ì ì¸ ë©”ëª¨ë¦¬ ì •ë¦¬", "ë°±ì—… ì „ëµ ìˆ˜ë¦½", "ë¯¼ê° ì •ë³´ ì•”í˜¸í™”"],
    "ëª¨ë‹ˆí„°ë§": ["ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì ", "ì‘ë‹µ ì‹œê°„ ëª¨ë‹ˆí„°ë§", "ì—ëŸ¬ ë¡œê¹… ë° ì•Œë¦¼"],
    "í™•ì¥ì„±": ["ìˆ˜í‰ í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜", "ë¡œë“œ ë°¸ëŸ°ì‹± ê³ ë ¤", "ìƒ¤ë”© ì „ëµ ìˆ˜ë¦½"],
}

print("ğŸ“‹ ë©”ëª¨ë¦¬ ê´€ë¦¬ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤:\n")
for category, practices in best_practices.items():
    print(f"### {category}")
    for practice in practices:
        print(f"  âœ“ {practice}")
    print()
