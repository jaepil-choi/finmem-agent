{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1961db5f",
   "metadata": {},
   "source": [
    "# CRAG: Corrective RAG\n",
    "\n",
    "이번 튜토리얼은 **Corrective RAG (CRAG)** 전략을 사용하여 RAG 기반 시스템을 개선하는 방법을 다룹니다.\n",
    "\n",
    "CRAG는 검색된 문서들에 대한 자기 반성(self-reflection) 및 자기 평가(self-evaluation) 단계를 포함하여, 검색-생성 파이프라인을 정교하게 다루는 접근법입니다.\n",
    "\n",
    "![crag](./assets/langgraph-crag.png)\n",
    "\n",
    "---\n",
    "\n",
    "**CRAG란?**\n",
    "\n",
    "**Corrective-RAG (CRAG)**는 RAG 전략에서 **검색 과정에서 찾아온 문서를 평가하고, 지식을 정제(refine) 하는 단계를 추가한 방법론**입니다.\n",
    "\n",
    "CRAG의 핵심 아이디어 ([논문 링크](https://arxiv.org/pdf/2401.15884.pdf)):\n",
    "\n",
    "1. 검색된 문서 중 하나 이상이 관련성 임계값을 초과하면 생성 단계로 진행\n",
    "2. 생성 전에 지식 정제 단계를 수행\n",
    "3. 문서를 \"knowledge strips\"로 세분화하여 평가\n",
    "4. 모든 문서가 관련성 임계값 이하이면 웹 검색으로 보강\n",
    "5. 웹 검색 시 쿼리 재작성(Query-Rewrite)을 통해 검색 결과 최적화\n",
    "\n",
    "---\n",
    "\n",
    "**참고**\n",
    "\n",
    "- [LangGraph CRAG 튜토리얼 (공식 문서)](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_crag_local/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a170112a",
   "metadata": {},
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3375ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a92d07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith 추적을 설정합니다.\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"LangGraph-RAG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9d52b6",
   "metadata": {},
   "source": [
    "## PDF 기반 Retrieval Chain 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4443177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag.pdf import PDFRetrievalChain\n",
    "\n",
    "# PDF 문서를 로드합니다.\n",
    "pdf = PDFRetrievalChain([\"data/SPRI_AI_Brief_2023년12월호_F.pdf\"]).create_chain()\n",
    "\n",
    "# retriever와 chain을 생성합니다.\n",
    "pdf_retriever = pdf.retriever\n",
    "pdf_chain = pdf.chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae47f9ae",
   "metadata": {},
   "source": [
    "## 검색된 문서의 관련성 평가 (Retrieval Grader)\n",
    "\n",
    "검색된 문서가 질문과 관련이 있는지 평가하는 평가기를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f3e68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote.models import get_model_name, LLMs\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 모델 이름 가져오기\n",
    "MODEL_NAME = get_model_name(LLMs.GPT4o)\n",
    "\n",
    "\n",
    "# 관련성 평가를 위한 데이터 모델\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"검색된 문서의 관련성을 평가하는 이진 점수입니다.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"문서가 질문과 관련이 있으면 'yes', 없으면 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "\n",
    "# 구조화된 출력을 생성하는 LLM\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# 시스템 프롬프트 정의\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Retrieval 평가기 생성\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03b7b76",
   "metadata": {},
   "source": [
    "### 평가기 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44144d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 정의\n",
    "question = \"삼성전자가 개발한 생성AI 에 대해 설명하세요.\"\n",
    "\n",
    "# 문서 검색\n",
    "docs = pdf_retriever.invoke(question)\n",
    "\n",
    "# 검색된 문서 중 1번 index 문서의 관련성 평가\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95ae75e",
   "metadata": {},
   "source": [
    "## 답변 생성 체인 (RAG Chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03e727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# RAG 프롬프트 가져오기\n",
    "prompt = hub.pull(\"teddynote/rag-prompt\")\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(model_name=MODEL_NAME, temperature=0)\n",
    "\n",
    "\n",
    "# 문서 포맷팅 함수\n",
    "def format_docs(docs):\n",
    "    \"\"\"문서 리스트를 포맷팅된 문자열로 변환합니다.\"\"\"\n",
    "    return \"\\n\\n\".join(\n",
    "        [\n",
    "            f'<document><content>{doc.page_content}</content><source>{doc.metadata[\"source\"]}</source><page>{doc.metadata[\"page\"]+1}</page></document>'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "# RAG 체인 생성\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 체인 실행 테스트\n",
    "generation = rag_chain.invoke({\"context\": format_docs(docs), \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963f59f7",
   "metadata": {},
   "source": [
    "## 쿼리 재작성 (Question Re-writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eabae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM 설정\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "\n",
    "# Query Rewrite 시스템 프롬프트\n",
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \n",
    "for web search. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "\n",
    "# 프롬프트 정의\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Question Re-writer 체인 생성\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eb2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쿼리 재작성 테스트\n",
    "print(f'[원본 질문]: \"{question}\"')\n",
    "print(\"[쿼리 재작성]:\", question_rewriter.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4a72cc",
   "metadata": {},
   "source": [
    "## 웹 검색 도구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620d859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "\n",
    "# 웹 검색 도구 생성 (최대 3개 결과)\n",
    "web_search_tool = TavilySearch(max_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d7bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹 검색 테스트\n",
    "results = web_search_tool.invoke({\"query\": question})\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f30cb22",
   "metadata": {},
   "source": [
    "## State 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07cb207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "# 상태 정의 (TypedDict 기반 - LangGraph v1 호환)\n",
    "class GraphState(TypedDict):\n",
    "    question: Annotated[str, \"질문\"]\n",
    "    generation: Annotated[str, \"생성된 답변\"]\n",
    "    web_search: Annotated[str, \"웹 검색 필요 여부 (yes/no)\"]\n",
    "    documents: Annotated[List[str], \"검색된 문서 리스트\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423bdd4b",
   "metadata": {},
   "source": [
    "## 노드 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b89e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "def retrieve(state: GraphState):\n",
    "    \"\"\"문서를 검색하는 노드입니다.\"\"\"\n",
    "    print(\"\\n==== RETRIEVE ====\\n\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # 문서 검색 수행\n",
    "    documents = pdf_retriever.invoke(question)\n",
    "    return {\"documents\": documents}\n",
    "\n",
    "\n",
    "def generate(state: GraphState):\n",
    "    \"\"\"답변을 생성하는 노드입니다.\"\"\"\n",
    "    print(\"\\n==== GENERATE ====\\n\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG를 사용한 답변 생성\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"generation\": generation}\n",
    "\n",
    "\n",
    "def grade_documents(state: GraphState):\n",
    "    \"\"\"검색된 문서의 관련성을 평가하는 노드입니다.\"\"\"\n",
    "    print(\"\\n==== [CHECK DOCUMENT RELEVANCE TO QUESTION] ====\\n\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # 필터링된 문서 리스트\n",
    "    filtered_docs = []\n",
    "    relevant_doc_count = 0\n",
    "\n",
    "    for d in documents:\n",
    "        # Question-Document 관련성 평가\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "\n",
    "        if grade == \"yes\":\n",
    "            print(\"==== [GRADE: DOCUMENT RELEVANT] ====\")\n",
    "            filtered_docs.append(d)\n",
    "            relevant_doc_count += 1\n",
    "        else:\n",
    "            print(\"==== [GRADE: DOCUMENT NOT RELEVANT] ====\")\n",
    "            continue\n",
    "\n",
    "    # 관련 문서가 없으면 웹 검색 수행\n",
    "    web_search = \"Yes\" if relevant_doc_count == 0 else \"No\"\n",
    "    return {\"documents\": filtered_docs, \"web_search\": web_search}\n",
    "\n",
    "\n",
    "def query_rewrite(state: GraphState):\n",
    "    \"\"\"쿼리를 재작성하는 노드입니다.\"\"\"\n",
    "    print(\"\\n==== [REWRITE QUERY] ====\\n\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # 질문 재작성\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"question\": better_question}\n",
    "\n",
    "\n",
    "def web_search(state: GraphState):\n",
    "    \"\"\"웹 검색을 수행하는 노드입니다.\"\"\"\n",
    "    print(\"\\n==== [WEB SEARCH] ====\\n\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # 웹 검색 수행\n",
    "    docs = web_search_tool.invoke({\"query\": question})\n",
    "    \n",
    "    # 검색 결과를 문서 형식으로 변환\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    documents.append(web_results)\n",
    "\n",
    "    return {\"documents\": documents}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52091fa6",
   "metadata": {},
   "source": [
    "## 조건부 엣지 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dfc922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state: GraphState):\n",
    "    \"\"\"평가 결과에 따라 다음 단계를 결정하는 함수입니다.\"\"\"\n",
    "    print(\"==== [ASSESS GRADED DOCUMENTS] ====\")\n",
    "    web_search = state[\"web_search\"]\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        # 웹 검색이 필요한 경우\n",
    "        print(\n",
    "            \"==== [DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, QUERY REWRITE] ====\"\n",
    "        )\n",
    "        return \"query_rewrite\"\n",
    "    else:\n",
    "        # 관련 문서가 있으면 답변 생성\n",
    "        print(\"==== [DECISION: GENERATE] ====\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaadaa1e",
   "metadata": {},
   "source": [
    "## 그래프 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99977214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "# 그래프 상태 초기화\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# 노드 정의\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"grade_documents\", grade_documents)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"query_rewrite\", query_rewrite)\n",
    "workflow.add_node(\"web_search_node\", web_search)\n",
    "\n",
    "# 엣지 연결\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "\n",
    "# 문서 평가 후 조건부 엣지\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"query_rewrite\": \"query_rewrite\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"query_rewrite\", \"web_search_node\")\n",
    "workflow.add_edge(\"web_search_node\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c98c318",
   "metadata": {},
   "source": [
    "### 그래프 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71047d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "# 그래프 시각화\n",
    "visualize_graph(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4357c3d7",
   "metadata": {},
   "source": [
    "## 그래프 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a06ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import stream_graph, invoke_graph, random_uuid\n",
    "\n",
    "# config 설정\n",
    "config = RunnableConfig(recursion_limit=20, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "# 질문 입력 (문서에서 검색 가능한 질문)\n",
    "inputs = {\n",
    "    \"question\": \"삼성전자가 개발한 생성형 AI 의 이름은?\",\n",
    "}\n",
    "\n",
    "# 스트리밍 실행\n",
    "stream_graph(\n",
    "    app,\n",
    "    inputs,\n",
    "    config,\n",
    "    [\"retrieve\", \"grade_documents\", \"query_rewrite\", \"web_search_node\", \"generate\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28667d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 입력 (문서에 없는 정보 - 웹 검색 필요)\n",
    "config = RunnableConfig(recursion_limit=20, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "inputs = {\n",
    "    \"question\": \"2024년 노벨문학상 수상자의 이름은?\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e865dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행\n",
    "invoke_graph(app, inputs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d864b22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스트리밍 실행\n",
    "stream_graph(\n",
    "    app,\n",
    "    inputs,\n",
    "    config,\n",
    "    [\"retrieve\", \"grade_documents\", \"query_rewrite\", \"generate\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "이 튜토리얼에서는 **CRAG(Corrective RAG)** 전략을 구현했습니다.\n",
    "\n",
    "### 핵심 개념\n",
    "\n",
    "1. **문서 관련성 평가**: 검색된 각 문서의 질문에 대한 관련성을 평가합니다.\n",
    "2. **조건부 웹 검색**: 관련 문서가 없으면 쿼리를 재작성하고 웹 검색을 수행합니다.\n",
    "3. **자기 수정**: 검색 결과를 평가하고 필요시 보완하는 자기 수정 메커니즘입니다.\n",
    "\n",
    "### 다음 단계\n",
    "\n",
    "다음 튜토리얼에서는 **Self-RAG**를 구현하여 답변의 환각(hallucination)을 검증하는 방법을 학습합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
