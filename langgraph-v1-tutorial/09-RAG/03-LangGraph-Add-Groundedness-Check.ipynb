{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fa6fb7f",
   "metadata": {},
   "source": [
    "# 관련성 체크 추가\n",
    "\n",
    "이번 튜토리얼에서는 Naive RAG에 **관련성 체크(Groundedness Check)** 단계를 추가합니다.\n",
    "\n",
    "**학습 목표**\n",
    "\n",
    "- 검색된 문서와 질문의 관련성을 평가하는 방법을 학습합니다.\n",
    "- 조건부 엣지를 활용하여 관련성에 따른 분기 처리를 구현합니다.\n",
    "- 재귀 상태 방지를 위한 `recursion_limit` 설정 방법을 익힙니다.\n",
    "\n",
    "**참고**\n",
    "\n",
    "- 이전 튜토리얼에서 확장된 내용이므로, 겹치는 부분은 간략히 설명합니다.\n",
    "\n",
    "![langgraph-add-relevance-check](assets/langgraph-add-relevance-check.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c872b",
   "metadata": {},
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d5c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b0043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith 추적을 설정합니다.\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"LangGraph-RAG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06468c1c",
   "metadata": {},
   "source": [
    "## PDF 기반 Retrieval Chain 생성\n",
    "\n",
    "PDF 문서를 기반으로 Retrieval Chain을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f905df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag.pdf import PDFRetrievalChain\n",
    "\n",
    "# PDF 문서를 로드합니다.\n",
    "pdf = PDFRetrievalChain([\"data/SPRI_AI_Brief_2023년12월호_F.pdf\"]).create_chain()\n",
    "\n",
    "# retriever와 chain을 생성합니다.\n",
    "pdf_retriever = pdf.retriever\n",
    "pdf_chain = pdf.chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d047f938",
   "metadata": {},
   "source": [
    "## State 정의\n",
    "\n",
    "`State`는 그래프의 노드 간에 공유되는 상태를 정의합니다.\n",
    "\n",
    "이번에는 **관련성(relevance)** 체크 결과를 저장하는 필드를 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19a3df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# GraphState 상태 정의 (TypedDict 기반 - LangGraph v1 호환)\n",
    "class GraphState(TypedDict):\n",
    "    question: Annotated[str, \"Question\"]  # 사용자 질문\n",
    "    context: Annotated[str, \"Context\"]  # 검색된 문서\n",
    "    answer: Annotated[str, \"Answer\"]  # 생성된 답변\n",
    "    messages: Annotated[list, add_messages]  # 대화 히스토리 (누적)\n",
    "    relevance: Annotated[str, \"Relevance\"]  # 관련성 체크 결과 (yes/no)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56d4095",
   "metadata": {},
   "source": [
    "## 노드(Node) 정의\n",
    "\n",
    "기존 노드에 **관련성 체크 노드**를 추가합니다.\n",
    "\n",
    "**노드 목록**\n",
    "\n",
    "- `retrieve_document`: 문서를 검색합니다.\n",
    "- `relevance_check`: 검색된 문서와 질문의 관련성을 평가합니다.\n",
    "- `llm_answer`: 검색된 문서를 기반으로 답변을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef0c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote.evaluator import GroundednessChecker\n",
    "from langchain_teddynote.messages import messages_to_history\n",
    "from rag.utils import format_docs\n",
    "\n",
    "\n",
    "def retrieve_document(state: GraphState) -> GraphState:\n",
    "    \"\"\"문서를 검색하는 노드입니다.\n",
    "    \n",
    "    사용자 질문을 기반으로 관련 문서를 검색하고 포맷팅합니다.\n",
    "    \"\"\"\n",
    "    # 질문을 상태에서 가져옵니다.\n",
    "    latest_question = state[\"question\"]\n",
    "\n",
    "    # 문서에서 검색하여 관련성 있는 문서를 찾습니다.\n",
    "    retrieved_docs = pdf_retriever.invoke(latest_question)\n",
    "\n",
    "    # 검색된 문서를 형식화합니다. (프롬프트 입력용)\n",
    "    retrieved_docs = format_docs(retrieved_docs)\n",
    "\n",
    "    # 검색된 문서를 context 키에 저장합니다.\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def llm_answer(state: GraphState) -> GraphState:\n",
    "    \"\"\"답변을 생성하는 노드입니다.\n",
    "    \n",
    "    검색된 문서와 대화 기록을 기반으로 답변을 생성합니다.\n",
    "    \"\"\"\n",
    "    # 질문을 상태에서 가져옵니다.\n",
    "    latest_question = state[\"question\"]\n",
    "\n",
    "    # 검색된 문서를 상태에서 가져옵니다.\n",
    "    context = state[\"context\"]\n",
    "\n",
    "    # 체인을 호출하여 답변을 생성합니다.\n",
    "    response = pdf_chain.invoke(\n",
    "        {\n",
    "            \"question\": latest_question,\n",
    "            \"context\": context,\n",
    "            \"chat_history\": messages_to_history(state[\"messages\"]),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # 생성된 답변과 메시지를 상태에 저장합니다.\n",
    "    return {\n",
    "        \"answer\": response,\n",
    "        \"messages\": [(\"user\", latest_question), (\"assistant\", response)],\n",
    "    }\n",
    "\n",
    "\n",
    "def relevance_check(state: GraphState) -> GraphState:\n",
    "    \"\"\"관련성을 체크하는 노드입니다.\n",
    "    \n",
    "    검색된 문서가 질문과 관련이 있는지 평가합니다.\n",
    "    \"\"\"\n",
    "    # 관련성 평가기를 생성합니다.\n",
    "    question_retrieval_relevant = GroundednessChecker(\n",
    "        llm=ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0), \n",
    "        target=\"question-retrieval\"\n",
    "    ).create()\n",
    "\n",
    "    # 관련성 체크를 실행합니다. (\"yes\" 또는 \"no\")\n",
    "    response = question_retrieval_relevant.invoke(\n",
    "        {\"question\": state[\"question\"], \"context\": state[\"context\"]}\n",
    "    )\n",
    "\n",
    "    print(\"==== [RELEVANCE CHECK] ====\")\n",
    "    print(response.score)\n",
    "\n",
    "    # 관련성 결과를 상태에 저장합니다.\n",
    "    return {\"relevance\": response.score}\n",
    "\n",
    "\n",
    "def is_relevant(state: GraphState) -> str:\n",
    "    \"\"\"조건부 엣지에서 사용되는 라우팅 함수입니다.\n",
    "    \n",
    "    관련성 여부에 따라 다음 노드를 결정합니다.\n",
    "    \"\"\"\n",
    "    if state[\"relevance\"] == \"yes\":\n",
    "        return \"relevant\"\n",
    "    else:\n",
    "        return \"not relevant\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f7785d",
   "metadata": {},
   "source": [
    "## 그래프 생성\n",
    "\n",
    "노드를 추가하고 **조건부 엣지**를 사용하여 관련성에 따른 분기 처리를 구현합니다.\n",
    "\n",
    "- 관련성이 있으면(`relevant`): 답변을 생성합니다.\n",
    "- 관련성이 없으면(`not relevant`): 다시 검색합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6015807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 그래프 정의\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# 노드 추가\n",
    "workflow.add_node(\"retrieve\", retrieve_document)\n",
    "workflow.add_node(\"relevance_check\", relevance_check)  # 관련성 체크 노드 추가\n",
    "workflow.add_node(\"llm_answer\", llm_answer)\n",
    "\n",
    "# 엣지 추가\n",
    "workflow.add_edge(\"retrieve\", \"relevance_check\")  # 검색 -> 관련성 체크\n",
    "\n",
    "# 조건부 엣지 추가 (관련성에 따른 분기)\n",
    "workflow.add_conditional_edges(\n",
    "    \"relevance_check\",  # 관련성 체크 노드에서 분기\n",
    "    is_relevant,  # 라우팅 함수\n",
    "    {\n",
    "        \"relevant\": \"llm_answer\",  # 관련성이 있으면 답변 생성\n",
    "        \"not relevant\": \"retrieve\",  # 관련성이 없으면 재검색\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"llm_answer\", END)  # 답변 -> 종료\n",
    "\n",
    "# 그래프 진입점 설정\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "\n",
    "# 체크포인터 설정 (대화 기록 저장)\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 그래프 컴파일\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a15c32",
   "metadata": {},
   "source": [
    "### 그래프 시각화\n",
    "\n",
    "컴파일한 그래프를 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e09251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "# 그래프 시각화\n",
    "visualize_graph(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110daa16",
   "metadata": {},
   "source": [
    "## 그래프 실행\n",
    "\n",
    "그래프를 실행하여 관련성 체크가 포함된 RAG 파이프라인을 테스트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2698eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import stream_graph, invoke_graph, random_uuid\n",
    "\n",
    "# config 설정 (재귀 최대 횟수, thread_id)\n",
    "config = RunnableConfig(recursion_limit=20, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "# 질문 입력 (관련성 있는 질문)\n",
    "inputs = GraphState(question=\"앤스로픽에 투자한 기업과 투자금액을 알려주세요.\")\n",
    "\n",
    "# 그래프 실행\n",
    "invoke_graph(app, inputs, config, [\"relevance_check\", \"llm_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbd17ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 스트리밍 출력\n",
    "stream_graph(app, inputs, config, [\"relevance_check\", \"llm_answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "result-check",
   "metadata": {},
   "source": [
    "### 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16ba031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 상태 조회\n",
    "outputs = app.get_state(config).values\n",
    "\n",
    "print(f'Question: {outputs[\"question\"]}')\n",
    "print(\"===\" * 20)\n",
    "print(f'Answer:\\n{outputs[\"answer\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b734deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관련성 체크 결과 확인\n",
    "print(f'Relevance: {outputs[\"relevance\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af077a6",
   "metadata": {},
   "source": [
    "## 재귀 상태 처리\n",
    "\n",
    "검색 결과의 `relevance_check`가 실패할 경우, 동일한 쿼리가 반복적으로 검색되어 **재귀 상태**에 빠질 수 있습니다.\n",
    "\n",
    "이를 방지하기 위해:\n",
    "\n",
    "1. `recursion_limit`을 설정하여 최대 재귀 횟수를 제한합니다.\n",
    "2. `GraphRecursionError`를 처리하여 무한 루프를 방지합니다.\n",
    "\n",
    "다음 튜토리얼에서는 **웹 검색**을 추가하여 이 문제를 해결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12129e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.errors import GraphRecursionError\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# config 설정 (재귀 최대 횟수 제한)\n",
    "config = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "# 질문 입력 (관련성 없는 질문 - 재귀 상태 유발)\n",
    "inputs = GraphState(question=\"테디노트의 랭체인 튜토리얼에 대한 정보를 알려주세요.\")\n",
    "\n",
    "try:\n",
    "    # 그래프 실행\n",
    "    stream_graph(app, inputs, config, [\"retrieve\", \"relevance_check\", \"llm_answer\"])\n",
    "except GraphRecursionError as recursion_error:\n",
    "    print(f\"GraphRecursionError: {recursion_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "이 튜토리얼에서는 Naive RAG에 **관련성 체크** 단계를 추가했습니다.\n",
    "\n",
    "### 핵심 개념\n",
    "\n",
    "1. **GroundednessChecker**: 검색된 문서와 질문의 관련성을 평가합니다.\n",
    "2. **조건부 엣지**: 관련성 결과에 따라 분기 처리를 수행합니다.\n",
    "3. **재귀 상태 방지**: `recursion_limit`과 `GraphRecursionError` 처리로 무한 루프를 방지합니다.\n",
    "\n",
    "### 다음 단계\n",
    "\n",
    "다음 튜토리얼에서는 관련성이 없을 경우 **웹 검색(Web Search)**을 수행하여 더 나은 답변을 생성하는 방법을 학습합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
